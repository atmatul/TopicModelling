
@article{ ISI:000446302900012,
Author = {Posada, Jorge and Zorrilla, Mikel and Dominguez, Ana and Simoes, Bruno
   and Eisert, Peter and Stricker, Didier and Rambach, Jason and Doellner,
   Juergen and Guevara, Miguel},
Title = {{Graphics and Media Technologies for Operators in Industry 4.0}},
Journal = {{IEEE COMPUTER GRAPHICS AND APPLICATIONS}},
Year = {{2018}},
Volume = {{38}},
Number = {{5}},
Pages = {{119-132}},
Month = {{SEP-OCT}},
Abstract = {{Visual computing technologies have an important role in manufacturing
   and production, particularly in new Industry 4.0 scenarios with
   intelligent machines, human-robot collaboration and learning factories.
   In this article, we explore challenges and examples on how the fusion of
   graphics, vision and media technologies can enhance the role of
   operators in this new context.}},
DOI = {{10.1109/MCG.2018.053491736}},
ISSN = {{0272-1716}},
EISSN = {{1558-1756}},
Unique-ID = {{ISI:000446302900012}},
}

@article{ ISI:000444581200005,
Author = {Rasmussen, Troels A. and Merritt, Timothy},
Title = {{ProjecTables: Augmented CNC tools for sustainable creative practices}},
Journal = {{INTERNATIONAL JOURNAL OF ARCHITECTURAL COMPUTING}},
Year = {{2018}},
Volume = {{16}},
Number = {{3, SI}},
Pages = {{227-242}},
Month = {{SEP}},
Abstract = {{Computer numerical control (CNC) cutting machines have become essential
   tools for designers and architects enabling rapid prototyping, model
   building, and production of high-quality components. Designers often cut
   from new materials, discarding the irregularly shaped remains. We
   introduce ProjecTables, a visual augmented reality system for
   interactive packing of model parts onto sheet materials. ProjecTables
   enables designers to (re)use scrap materials for computer numerical
   control cutting that would have been previously thrown away, at the same
   time supporting esthetic choices related to wood grain, avoiding surface
   blemishes, and other relevant material properties. We conducted
   evaluations of ProjecTables with design students from Aarhus School of
   Architecture, demonstrating that participants could quickly and easily
   place and orient model parts reducing material waste. Contextual
   interviews and ideation sessions led to a deeper understanding of
   current work practices and sustainability issues with computer numerical
   control cutting machines and identified useful features for interactive
   packing to reduce waste while supporting esthetic concerns for
   exhibition quality design projects.}},
DOI = {{10.1177/1478077118792356}},
ISSN = {{1478-0771}},
EISSN = {{2048-3988}},
Unique-ID = {{ISI:000444581200005}},
}

@article{ ISI:000443615900036,
Author = {Dai, David and Horvath, Nicholas and Varner, Jeffrey},
Title = {{Dynamic Sequence Specific Constraint-Based Modeling of Cell-Free Protein
   Synthesis}},
Journal = {{PROCESSES}},
Year = {{2018}},
Volume = {{6}},
Number = {{8}},
Month = {{AUG}},
Abstract = {{Cell-free protein expression has emerged as an important approach in
   systems and synthetic biology, and a promising technology for
   personalized point of care medicine. Cell-free systems derived from
   crude whole cell extracts have shown remarkable utility as a protein
   synthesis technology. However, if cell-free platforms for on-demand
   biomanufacturing are to become a reality, the performance limits of
   these systems must be defined and optimized. Toward this goal, we
   modeled E. coli cell-free protein expression using a sequence specific
   dynamic constraint-based approach in which metabolite measurements were
   directly incorporated into the flux estimation problem. A cell-free
   metabolic network was constructed by removing growth associated
   reactions from the iAF1260 reconstruction of K-12 MG1655 E. coli.
   Sequence specific descriptions of transcription and translation
   processes were then added to this metabolic network to describe protein
   production. A linear programming problem was then solved over short time
   intervals to estimate metabolic fluxes through the augmented cell-free
   network, subject to material balances, time rate of change and
   metabolite measurement constraints. The approach captured the biphasic
   cell-free production of a model protein, chloramphenicol
   acetyltransferase. Flux variability analysis suggested that cell-free
   metabolism was potentially robust; for example, the rate of protein
   production could be met by flux through the glycolytic, pentose
   phosphate, or the Entner-Doudoroff pathways. Variation of the metabolite
   constraints revealed central carbon metabolites, specifically upper
   glycolysis, tricarboxylic acid (TCA) cycle, and pentose phosphate, to be
   the most effective at training a predictive model, while energy and
   amino acid measurements were less effective. Irrespective of the
   measurement set, the metabolic fluxes (for the most part) remained
   unidentifiable. These findings suggested dynamic constraint-based
   modeling could aid in the design of cell-free protein expression
   experiments for metabolite prediction, but the flux estimation problem
   remains challenging. Furthermore, while we modeled the cell-free
   production of only a single protein in this study, the sequence specific
   dynamic constraint-based modeling approach presented here could be
   extended to multi-protein synthetic circuits, RNA circuits or even small
   molecule production.}},
DOI = {{10.3390/pr6080132}},
Article-Number = {{132}},
ISSN = {{2227-9717}},
ORCID-Numbers = {{Varner, Jeffrey/0000-0002-2558-7026}},
Unique-ID = {{ISI:000443615900036}},
}

@article{ ISI:000446134900040,
Author = {Kamble, Sachin S. and Gunasekaran, Angappa and Gawankar, Shradha A.},
Title = {{Sustainable Industry 4.0 framework: A systematic literature review
   identifying the current trends and future perspectives}},
Journal = {{PROCESS SAFETY AND ENVIRONMENTAL PROTECTION}},
Year = {{2018}},
Volume = {{117}},
Pages = {{408-425}},
Month = {{JUL}},
Abstract = {{Industry 4.0 and its other synonyms like Smart Manufacturing, Smart
   Production or Internet of Things, have been identified as major
   contributors in the context of digital and automated manufacturing
   environment. The term industry 4.0 comprises a variety of technologies
   to enable the development of the value chain resulting in reduced
   manufacturing lead times, and improved product quality and
   organizational performance. Industry 4.0 has attracted much attention in
   the recent literature, however there are very few systematic and
   extensive review of research that captures the dynamic nature of this
   topic. The rapidly growing interest from both academics and
   practitioners in Industry 4.0 has urged the need for review of
   up-to-date research and development to develop a new agenda. Selected 85
   papers were classified in five research categories namely conceptual
   papers on Industry 4.0, human-machine interactions, machine-equipment
   interactions, technologies of Industry 4.0 and sustainability. The
   review primarily attempted to seek answers to the following two
   questions: (1) What are different research approaches used to study
   Industry 4.0? and (2) What is the current status of research in the
   domains of Industry 4.0?. We propose a sustainable Industry 4.0
   framework based on the findings of the review with three critical
   components viz., Industry 4.0 technologies, process integration and
   sustainable outcomes. Finally, the scope of future research is discussed
   in detail. (C) 2018 Institution of Chemical Engineers. Published by
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.psep.2018.05.009}},
ISSN = {{0957-5820}},
EISSN = {{1744-3598}},
Unique-ID = {{ISI:000446134900040}},
}

@article{ ISI:000439955800023,
Author = {Harrington, Cuan M. and Kavanagh, Dara O. and Ballester, Gemma Wright
   and Ballester, Athena Wright and Dicker, Patrick and Traynor, Oscar and
   Hill, Arnold and Tierney, Sean},
Title = {{360 degrees Operative Videos: A Randomised Cross-Over Study Evaluating
   Attentiveness and Information Retention}},
Journal = {{JOURNAL OF SURGICAL EDUCATION}},
Year = {{2018}},
Volume = {{75}},
Number = {{4}},
Pages = {{993-1000}},
Month = {{JUL-AUG}},
Abstract = {{OBJECTIVE: Although two-dimensional (2D) and three-dimensional videos
   have traditionally provided foundations for reviewing operative
   procedures, the recent 360 degrees format may provide new dimensions to
   surgical education. This study sought to describe the production of a
   high quality 360 degrees video for an index-operation (augmented with
   educational material), while evaluating for variances in attentiveness,
   information retention, and appraisal compared to 2D.
   DESIGN: A 6-camera synchronised array (GoPro Omni, {[}California, United
   States]) was suspended inverted and recorded an elective laparoscopic
   cholecystectomy in 2016. A single-blinded randomised cross-over study
   was performed to evaluate this video in 360 degrees vs 2D formats. Group
   A experienced the 360 degrees video using Samsung (Suwon, South-Korea)
   GearVR virtual-reality headsets, followed by the 2D experience on a
   75-inch television. Group B were reversed. Each video was probed at
   designated time points for engagement levels and task-unrelated images
   or thoughts. Alternating question banks were administered following each
   video experience. Feedback was obtained via a short survey at study
   completion.
   SETTING: The New Academic and Education Building (NAEB) in Dublin, Royal
   College of Surgeons in Ireland, July 2017.
   PARTICIPANTS: Preclinical undergraduate students from a medical
   university in Ireland.
   RESULTS: Forty students participated with a mean age of 23.2 +/- 4.5
   years and equal sex involvement. The 360 degrees video demonstrated
   significantly higher engagement (p < 0.01) throughout the experience and
   lower task unrelated images or thoughts (p < 0.01). Significant
   variances in information retention between the 2 groups were absent (p =
   0.143) but most (65\%) reported the 360 degrees video as their learning
   platform of choice. Mean appraisal levels for the 360 degrees platform
   were positive with mean responses of > 8/10 for the platform for
   learning, immersion, and entertainment.
   CONCLUSIONS: This study describes the successful development and
   evaluation of a 360 degrees operative video. This new video format
   demonstrated significant engagement and attentiveness benefits compared
   to traditional 2D formats. This requires further evaluation in the field
   of technology enhanced learning. (C) 2017 Association of Program
   Directors in Surgery. Published by Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.jsurg.2017.10.010}},
ISSN = {{1931-7204}},
EISSN = {{1878-7452}},
Unique-ID = {{ISI:000439955800023}},
}

@article{ ISI:000444155200014,
Author = {Kivrak, Serkan and Arslan, Gokhan},
Title = {{Augmented Reality Technology Applications in Construction Project
   Activities}},
Journal = {{JOURNAL OF POLYTECHNIC-POLITEKNIK DERGISI}},
Year = {{2018}},
Volume = {{21}},
Number = {{2}},
Pages = {{379-385}},
Month = {{JUN}},
Abstract = {{Augmented reality, which brings a new perspective into information
   technologies, can be defined in the simplest form as augmenting the real
   world with information from the virtual world. Augmented reality is one
   of the innovative technologies that will provide significant benefits to
   construction project applications in the future. In this study, an
   augmented reality system is developed for improving construction project
   activities. This system shows the workers, equipment operators,
   engineers and managers how to perform the tasks of the specific job,
   step by step, with relevant supplemental information. Using smart glass
   in the system, the users will be able to reach the training and building
   methods about the relevant project activities. By this way, construction
   failures and spending money and time to learn the correct methodology
   for the execution of the activity will be avoided. The system is tested
   using the brick wall production phases. It has been proposed that the
   system can improve the quality of construction activities and thus,
   provide significant contributions to the construction industry.}},
DOI = {{10.2339/politeknik.385916}},
ISSN = {{1302-0900}},
EISSN = {{2147-9429}},
Unique-ID = {{ISI:000444155200014}},
}

@article{ ISI:000431880000013,
Author = {Zhang, Wenjun and Wang, Zhifeng and Xu, Jian},
Title = {{Research on a surface-relief optical waveguide augmented reality display
   device}},
Journal = {{APPLIED OPTICS}},
Year = {{2018}},
Volume = {{57}},
Number = {{14}},
Pages = {{3720-3729}},
Month = {{MAY 10}},
Abstract = {{Recently, an optical waveguide display device that has light weight,
   high transparency, and full color has become more and more popular in
   the wearable augmented reality display application. But existing
   waveguide display devices are less than satisfactory because of cost,
   safety, and mass production. Therefore, a type of surface-relief optical
   waveguide display device is proposed in this paper. First, the
   geometrical relationship of a waveguide display device structure is
   confirmed according to the design method of the optical waveguide
   display device. Then, the influence of the waveguide structure for the
   image quality is analyzed, and the rationality of the surfac-erelief
   waveguide scheme is verified by simulation. Finally, the prototype of
   the surface-relief optical waveguide display device with polycarbonate
   materials, field of view of 38 degrees, thickness of 4.5 mm, and
   transmittance of about 80\% is fabricated and demonstrated. (C) 2018
   Optical Society of America.}},
DOI = {{10.1364/AO.57.003720}},
ISSN = {{1559-128X}},
EISSN = {{2155-3165}},
Unique-ID = {{ISI:000431880000013}},
}

@article{ ISI:000435800200002,
Author = {Yoshida, Takuji and Tokuyama, Kazutatsu and Takai, Yuichi and Tsukuda,
   Daisuke and Kaneko, Tsuyoshi and Suzuki, Nobuhiro and Anzai, Takafumi
   and Yoshikaie, Akira and Akutsu, Katsuyuki and Machida, Akio},
Title = {{A plastic holographic waveguide combiner for light-weight and
   highly-transparent augmented reality glasses}},
Journal = {{JOURNAL OF THE SOCIETY FOR INFORMATION DISPLAY}},
Year = {{2018}},
Volume = {{26}},
Number = {{5}},
Pages = {{280-286}},
Month = {{MAY}},
Note = {{Display Week, Los Angeles, CA, MAY 20-25, 2018}},
Organization = {{Soc Informat Display}},
Abstract = {{There is a high demand for light-weight, stylishly designed augmented
   reality (AR) glasses with natural see-through capabilities for the
   wide-spread distribution of novel wearable device to general consumers.
   We have successfully developed a unique production process of a
   holographic waveguide combiner that enables us to laminate holographic
   optical elements (HOEs) onto a plastic substrate with optical grade
   quality. The plastic substrate waveguide combiner has a number of
   advantages over conventional glass substrate combiners; the plastic
   substrate makes AR glasses lighter in weight and unbreakable. With the
   lamination process of HOEs, we can apply them to a various designs to
   satisfy general customers' wide range of preferences for the style. We
   also potentially made it possible for the holographic waveguide combiner
   to be produced in larger volumes at lower costs by using our novel
   roll-to-roll hologram recording and laminating process. In this paper,
   we present our approach of the plastic substrate HOE production process
   for AR glasses.}},
DOI = {{10.1002/jsid.659}},
ISSN = {{1071-0922}},
EISSN = {{1938-3657}},
Unique-ID = {{ISI:000435800200002}},
}

@article{ ISI:000431432000006,
Author = {Abidi, Mustufa H. and Al-Ahmari, Abdulrahman M. and Ahmad, Ali and
   Darmoul, Saber and Ameen, Wadea},
Title = {{Semi-Immersive Virtual Turbine Engine Simulation System}},
Journal = {{INTERNATIONAL JOURNAL OF TURBO \& JET-ENGINES}},
Year = {{2018}},
Volume = {{35}},
Number = {{2}},
Pages = {{149-160}},
Month = {{MAY}},
Abstract = {{The design and verification of assembly operations is essential for
   planning product production operations. Recently, virtual prototyping
   has witnessed tremendous progress, and has reached a stage where current
   environments enable rich and multi-modal interaction between designers
   and models through stereoscopic visuals, surround sound, and haptic
   feedback. The benefits of building and using Virtual Reality (VR) models
   in assembly process verification are discussed in this paper. In this
   paper, we present the virtual assembly (VA) of an aircraft turbine
   engine. The assembly parts and sequences are explained using a virtual
   reality design system. The system enables stereoscopic visuals, surround
   sounds, and ample and intuitive interaction with developed models. A
   special software architecture is suggested to describe the assembly
   parts and assembly sequence in VR. A collision detection mechanism is
   employed that provides visual feedback to check the interference between
   components. The system is tested for virtual prototype and assembly
   sequencing of a turbine engine. We show that the developed system is
   comprehensive in terms of VR feedback mechanisms, which include visual,
   auditory, tactile, as well as force feedback. The system is shown to be
   effective and efficient for validating the design of assembly, part
   design, and operations planning.}},
DOI = {{10.1515/tjj-2017-0004}},
ISSN = {{0334-0082}},
EISSN = {{2191-0332}},
Unique-ID = {{ISI:000431432000006}},
}

@article{ ISI:000429568800010,
Author = {Rao, Sriganesh K. and Prasad, Ramjee},
Title = {{Impact of 5G Technologies on Industry 4.0}},
Journal = {{WIRELESS PERSONAL COMMUNICATIONS}},
Year = {{2018}},
Volume = {{100}},
Number = {{1, SI}},
Pages = {{145-159}},
Month = {{MAY}},
Note = {{19th Strategic Workshop (SW), St Julians, MALTA, MAY 29-31, 2017}},
Abstract = {{Manufacturing has evolved over the course of centuries from the days of
   handmade goods to the adoption of water-and steam-powered machines, the
   invention of mass production, the introduction of electronic automation,
   and now beyond. Today, the benchmark for companies to keep up with, is
   Industry 4.0. Here, Manufacturing systems go beyond simple connection,
   to also communicate, analyse and use collected information to drive
   further intelligent actions. It represents an integration of IoT,
   analytics, additive manufacturing, robotics, artificial intelligence,
   advanced materials, and augmented reality. The paper looks at the
   evolution of the Industrial revolution and the technologies that have
   impacted their growth. The proposed features of 5G technologies are
   listed and described how these features impact the Industries of the
   future, leading to Industries 4.0. 5G promises to be a key enabler for
   Factories of the Future, providing unified communication platform needed
   to disrupt with new business models and to overcome the shortcomings of
   current communication technologies.}},
DOI = {{10.1007/s11277-018-5615-7}},
ISSN = {{0929-6212}},
EISSN = {{1572-834X}},
Unique-ID = {{ISI:000429568800010}},
}

@article{ ISI:000429674800002,
Author = {Ye, Shulong and Mo, Wei and Lv, Yonghu and Li, Xia and Kwok, Chi Tat and
   Yu, Peng},
Title = {{Metal Injection Molding of Thin-Walled Titanium Glasses Arms: A Case
   Study}},
Journal = {{JOM}},
Year = {{2018}},
Volume = {{70}},
Number = {{5}},
Pages = {{616-620}},
Month = {{MAY}},
Note = {{Meeting on Powder Metallurgy of Non-Ferrous Metals, San Diego, CA, FEB
   28, 2017}},
Abstract = {{Commercially pure titanium (CP Ti) and Ti-6Al-4V arms for a new brand of
   augmented reality smart glasses, which are over 170 mm in length, with
   thin wall structures and extremely complex surfaces, have been
   successfully fabricated via metal injection molding. After sintering,
   both the metal injection-molded (MIMed) CP Ti and Ti-6Al-4V can reach
   relative densities of over 95\% with an oxygen content similar to 2200
   ppm, thus imparting mechanical properties comparable to cast alloys. The
   ductility of the MIMed CP Ti and Ti-6Al-4V are about 15\% and 8\%,
   respectively. This is a good example of applying metal injection molding
   to mass production of precise Ti alloy parts with complicated shapes.}},
DOI = {{10.1007/s11837-018-2788-1}},
ISSN = {{1047-4838}},
EISSN = {{1543-1851}},
Unique-ID = {{ISI:000429674800002}},
}

@article{ ISI:000428990200062,
Author = {Wei, Lidong and Li, Yacan and Jing, Juanjuan and Feng, Lei and Zhou,
   Jinsong},
Title = {{Design and fabrication of a compact off-axis see-through head-mounted
   display using a freeform surface}},
Journal = {{OPTICS EXPRESS}},
Year = {{2018}},
Volume = {{26}},
Number = {{7}},
Pages = {{8550-8565}},
Month = {{APR 2}},
Abstract = {{Head-mounted display (HMD) has been widely used in many fields, and most
   existing HMDs are complex and typically non-aesthetically pleasing. In
   this paper, a novel compact, lightweight and wearable off-axis HMD with
   freeform surface is reported. It is challenging to achieve large field
   of view (FOV) and maintain compact structure simultaneously for this
   type system. In this design, the compact off-axis HMD consists of a
   tilted ellipsoid combiner and a four pieces relay lenses. It offers a
   diagonal FOV of 30 degrees, and an exit pupil diameter of 7 mm. No
   diffractive surfaces are used, thus avoiding the effect of stray light
   and ghost image in previous designs. The x-y polynomial freeform surface
   is adopted in the relay lens for improving the image quality and
   minimizing the structure size. Analytical expressions to determine the
   initial structure of HMD has been given, while structure constrains,
   optimization strategy and tolerance analysis are also described in
   details. The optical system is easy to manufacture by ordinary method
   which is beneficial for mass production. Further, a prototype of this
   compact HMD is successfully implemented with good imaging performance.
   The compact structure of HMD makes it well suited for integrating a
   normal glass, significantly advancing the application of HMD in people's
   daily life. (c) 2018 Optical Society of America under the terms of the
   OSA Open Access Publishing Agreement}},
DOI = {{10.1364/OE.26.008550}},
ISSN = {{1094-4087}},
Unique-ID = {{ISI:000428990200062}},
}

@article{ ISI:000435061400003,
Author = {Holm, Magnus},
Title = {{The future shop-floor operators, demands, requirements and
   interpretations}},
Journal = {{JOURNAL OF MANUFACTURING SYSTEMS}},
Year = {{2018}},
Volume = {{47}},
Pages = {{35-42}},
Month = {{APR}},
Abstract = {{The evolution of the manufacturing industry reveals continuous progress
   and development throughout the years. This evolution not only includes
   production methodologies and the production equipment, it also includes
   the working environment of the shop-floor operators. The demands faced
   by the shop-floor operators have developed from strictly controlled,
   simple and monotonic tasks to self-controlled team work requiring a
   holistic approach that aims at continuous improvements and achieving a
   high degree of flexibility, adaptability and initiative.
   This paper describes the evolution of the shop-floor operator, according
   to the research literature and interviews with manufacturing managers
   and human resources specialists. In addition, the paper presents the
   response of future Swedish shop-floor operators, today's high-school
   students, to a description of their possible future work as shop-floor
   operators. The Swedish manufacturing industry competes, to a large
   extent, on and responds to the international market. The findings made
   in this paper are thus also interesting for other industries and
   countries acting on the international market. (C) 2018 The Society of
   Manufacturing Engineers. Published by Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.jmsy.2018.03.004}},
ISSN = {{0278-6125}},
EISSN = {{1878-6642}},
ORCID-Numbers = {{Holm, Magnus/0000-0002-1699-3778}},
Unique-ID = {{ISI:000435061400003}},
}

@article{ ISI:000427682500019,
Author = {MacQuarrie, Andrew and Steed, Anthony},
Title = {{The Effect of Transition Type in Multi-View 360 degrees Media}},
Journal = {{IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS}},
Year = {{2018}},
Volume = {{24}},
Number = {{4}},
Pages = {{1564-1573}},
Month = {{APR}},
Note = {{25th IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE
   VR), Reutlingen, GERMANY, MAR 18-22, 2018}},
Organization = {{IEEE}},
Abstract = {{360 degrees images and video have become extremely popular formats for
   immersive displays, due in large part to the technical ease of content
   production. While many experiences use a single camera viewpoint, an
   increasing number of experiences use multiple camera locations. In such
   multi-view 360 degrees media (MV360M) systems, a visual effect is
   required when the user transitions from one camera location to another.
   This effect can take several forms, such as a cut or an image-based
   warp, and the choice of effect may impact many aspects of the
   experience, including issues related to enjoyment and scene
   understanding. To investigate the effect of transition types on
   immersive MV360M experiences, a repeated-measures experiment was
   conducted with 31 participants. Wearing a head-mounted display,
   participants explored four static scenes, for which multiple 360 degrees
   images and a reconstructed 3D model were available. Three transition
   types were examined: teleport, a linear move through a 3D model of the
   scene, and an image-based transition using a Mobius transformation. The
   metrics investigated included spatial awareness, users' movement
   profiles, transition preference and the subjective feeling of moving
   through the space. Results indicate that there was no significant
   difference between transition types in terms of spatial awareness, while
   significant differences were found for users' movement profiles, with
   participants taking 1.6 seconds longer to select their next location
   following a teleport transition. The model and Mobius transitions were
   significantly better in terms of creating the feeling of moving through
   the space. Preference was also significantly different, with model and
   teleport transitions being preferred over Mobius transitions. Our
   results indicate that trade-offs between transitions will require
   content creators to think carefully about what aspects they consider to
   be most important when producing MV360M experiences.}},
DOI = {{10.1109/TVCG.2018.2793561}},
ISSN = {{1077-2626}},
EISSN = {{1941-0506}},
ORCID-Numbers = {{MacQuarrie, Andrew/0000-0003-1028-2710}},
Unique-ID = {{ISI:000427682500019}},
}

@article{ ISI:000434142400003,
Author = {Zhang, Lei and Ou, Fang and Chong, Wing Cheung and Chen, Yijing and Li,
   Qiming},
Title = {{Wafer-scale monolithic hybrid integration of Si-based IC and III-V
   epi-layersA mass manufacturable approach for active matrix micro-LED
   micro-displays}},
Journal = {{JOURNAL OF THE SOCIETY FOR INFORMATION DISPLAY}},
Year = {{2018}},
Volume = {{26}},
Number = {{3}},
Pages = {{137-145}},
Month = {{MAR}},
Abstract = {{Hybridization of silicon integrated circuits (ICs) with compound
   semiconductor device arrays are crucial for making functional hybrid
   chips, which are found to have enormous applications in many areas.
   Although widely used in manufacturing hybrid chips, the flip-chip
   technology suffers from several limitations that are difficult to
   overcome, especially when the demand is raised to make functional hybrid
   chips with higher device array density without sacrificing the chip
   footprint. To address those issues, Beida Jade Bird Display Limited has
   developed its unique wafer-level monolithic hybrid integration
   technology and demonstrated its advantages in making large-scale hybrid
   integration of functional device arrays on Si IC wafers. Active matrix
   micro-light-emitting diode micro-displays with a resolution of 5000+
   pixel per inch were successfully fabricated using Beida Jade Bird
   Display Limited's monolithic hybrid integration technology. The general
   fabrication method is described, and the result is presented in this
   paper. The fabricated monochromatic micro-light-emitting diode
   micro-displays exhibit improved device performance than do other
   micro-display technologies and have great potentials in applications
   such as portable projectors and near-to-eye projection for augmented
   reality. More importantly, the wafer-scale monolithic hybrid integration
   technology offers a clear path for low-cost mass production of hybrid
   optoelectronic IC chips.}},
DOI = {{10.1002/jsid.649}},
ISSN = {{1071-0922}},
EISSN = {{1938-3657}},
Unique-ID = {{ISI:000434142400003}},
}

@article{ ISI:000430282000019,
Author = {Veselovsky, Mikhail Yakovlevich and Pogodina, Tatiana Vitalievna and
   Ilyukhina, Raisa Vasilyevna and Sigunova, Tatyana Anatolyevna and
   Kuzovleva, Nina Fedorovna},
Title = {{FINANCIAL AND ECONOMIC MECHANISMS OF PROMOTING INNOVATIVE ACTIVITY IN
   THE CONTEXT OF THE DIGITAL ECONOMY FORMATION}},
Journal = {{ENTREPRENEURSHIP AND SUSTAINABILITY ISSUES}},
Year = {{2018}},
Volume = {{5}},
Number = {{3}},
Pages = {{672-681}},
Month = {{MAR}},
Abstract = {{The paper analyzes some fmancial, tax, information, communication,
   infrastructural, technological and organizational mechanisms of
   innovative activity promotion in conditions of transition to a digital
   economy. End-to-end technologies including ``Big Data{''}, ``New
   Production Technologies{''}, ``Quantum Technologies{''}, ``Technologies
   of Virtual and Augmented Realities{''}, the possibilities of their
   application in various sectors of the national economy were singled out
   and analyzed. The role of end-to-end technologies in the development of
   the Russian economy and promotion of innovative activities of companies
   was studied. A comparative analysis of the main indicators of
   informatization of the society of Russia and some leading foreign
   countries for the period of 2005-2015 was carried out. The conclusions
   were made about an insufficient use of the Internet in Russia, primarily
   in rural areas, which hindered the social progress of Russian society.
   The leading role of digital (information) technologies in solving social
   problems, including education, social services and healthcare, was
   defined. The necessity of development of electronic services in the
   sphere of education and health was proved. Ways of cluster development
   based on the example of the Kaluga Region in the development of digital
   technologies were studied. The influence of development institutions on
   stimulating innovation activity in Russia was analyzed.}},
DOI = {{10.9770/jesi.2018.5.3(19)}},
ISSN = {{2345-0282}},
ResearcherID-Numbers = {{Pogodina, Tatiana/L-9855-2018}},
Unique-ID = {{ISI:000430282000019}},
}

@article{ ISI:000426247600036,
Author = {Wang, Sihong and Xu, Jie and Wang, Weichen and Wang, Ging-Ji Nathan and
   Rastak, Reza and Molina-Lopez, Francisco and Chung, Jong Won and Niu,
   Simiao and Feig, Vivian R. and Lopez, Jeffery and Lei, Ting and Kwon,
   Soon-Ki and Kim, Yeongin and Foudeh, Amir M. and Ehrlich, Anatol and
   Gasperini, Andrea and Yun, Youngjun and Murmann, Boris and Tok, Jeffery
   B. -H. and Bao, Zhenan},
Title = {{Skin electronics from scalable fabrication of an intrinsically
   stretchable transistor array}},
Journal = {{NATURE}},
Year = {{2018}},
Volume = {{555}},
Number = {{7694}},
Pages = {{83+}},
Month = {{MAR 1}},
Abstract = {{Skin-like electronics that can adhere seamlessly to human skin or within
   the body are highly desirable for applications such as health
   monitoring(1,2), medical treatment(3,4), medical implants(5) and
   biological studies(6,7), and for technologies that include human-machine
   interfaces, soft robotics and augmented reality(8,9). Rendering such
   electronics soft and stretchable-like human skin-would make them more
   comfortable to wear, and, through increased contact area, would greatly
   enhance the fidelity of signals acquired from the skin. Structural
   engineering of rigid inorganic and organic devices has enabled
   circuit-level stretchability, but this requires sophisticated
   fabrication techniques and usually suffers from reduced densities of
   devices within an array(2,10-12). We reasoned that the desired
   parameters, such as higher mechanical deformability and robustness,
   improved skin compatibility and higher device density, could be provided
   by using intrinsically stretchable polymer materials instead. However,
   the production of intrinsically stretchable materials and devices is
   still largely in its infancy(13-15): such materials have been
   reported(11,16-19), but functional, intrinsically stretchable
   electronics have yet to be demonstrated owing to the lack of a scalable
   fabrication technology. Here we describe a fabrication process that
   enables high yield and uniformity from a variety of intrinsically
   stretchable electronic polymers. We demonstrate an intrinsically
   stretchable polymer transistor array with an unprecedented device
   density of 347 transistors per square centimetre. The transistors have
   an average charge-carrier mobility comparable to that of amorphous
   silicon, varying only slightly (within one order of magnitude) when
   subjected to 100 per cent strain for 1,000 cycles, without
   current-voltage hysteresis. Our transistor arrays thus constitute
   intrinsically stretchable skin electronics, and include an active matrix
   for sensory arrays, as well as analogue and digital circuit elements.
   Our process offers a general platform for incorporating other
   intrinsically stretchable polymer materials, enabling the fabrication of
   next-generation stretchable skin electronic devices.}},
DOI = {{10.1038/nature25494}},
ISSN = {{0028-0836}},
EISSN = {{1476-4687}},
ResearcherID-Numbers = {{Niu, Simiao/D-3019-2012
   }},
ORCID-Numbers = {{Niu, Simiao/0000-0003-1973-2204
   Murmann, Boris/0000-0003-3417-8782
   Molina-Lopez, Francisco/0000-0002-4329-4059
   Lopez, Jeffrey/0000-0002-6425-5550}},
Unique-ID = {{ISI:000426247600036}},
}

@article{ ISI:000425764800004,
Author = {Esanu, Octavian},
Title = {{Realism Today?}},
Journal = {{ARTMARGINS}},
Year = {{2018}},
Volume = {{7}},
Number = {{1}},
Pages = {{58-82}},
Month = {{FEB}},
Abstract = {{For this roundtable we invited several respondents to reflect upon both
   the history and the present of artistic realism. We ask how its various
   revivals might be regarded as part of a long trajectory of Western art
   and aesthetics, and how such revivals might be triggered by discourses
   outside of contemporary art. If a new aesthetics of realism were
   possible today, how would it differ from its multiple historical
   antecedents? Is realism in its various modes an obsolete artistic form
   or style of the past (like baroque painting or modernist collage) that
   is as such incompatible with the modes of production and the augmented
   social reality of late capitalism? We are very grateful to Dave Beech,
   Christoph Cox, Sami Khatib, John Roberts and Marina Vishmidt for
   accepting to participate in this roundtable held over electronic mail.}},
DOI = {{10.1162/ARTM\_a\_00200}},
ISSN = {{2162-2574}},
EISSN = {{2162-2582}},
Unique-ID = {{ISI:000425764800004}},
}

@article{ ISI:000424264600017,
Author = {Alejandro Betancur, J. and Villa-Espinal, Jesus and Osorio-Gomez,
   Gilberto and Cuellar, Sergio and Suarez, Daniel},
Title = {{Research topics and implementation trends on automotive head-up display
   systems}},
Journal = {{INTERNATIONAL JOURNAL OF INTERACTIVE DESIGN AND MANUFACTURING - IJIDEM}},
Year = {{2018}},
Volume = {{12}},
Number = {{1}},
Pages = {{199-214}},
Month = {{FEB}},
Abstract = {{For about 5 years, production of automobiles equipped with head-up
   display (HUD) systems has continuously grown and this trend will remain
   for at least three years more from 2014 {[}7, 19]. Therefore, looking
   for clarifying how to orientate future efforts in developing these
   systems, a systematic analysis approach has been implemented for
   identifying best design practises, common characteristics, gaps,
   implementation trends and research topics on automotive HUD systems. The
   proposed approach is conducted on two areas, firstly exploring the
   current scientific literature to find the most relevant research topics
   and understanding how these are evolving. Secondly, a competitive
   intelligence analysis was conducted compiling patents related to
   automotive HUD systems. This analysis was specially oriented towards
   determining, currently and in the near future, basic product design
   implementation trends in automotive HUD systems. Finally, the results
   obtained from both scientific and technological points of view were
   compared and commented, looking for determining common, converging or
   diverging, evolution parameters in automotive HUD systems. In this way,
   the results exposed the distraction as an outstanding research topic for
   these systems, becoming even more crucial if they are mixed with
   augmented reality projections, advanced driver assistance systems (ADAS)
   or infotainment systems.}},
DOI = {{10.1007/s12008-016-0350-3}},
ISSN = {{1955-2513}},
EISSN = {{1955-2505}},
Unique-ID = {{ISI:000424264600017}},
}

@article{ ISI:000445651000038,
Author = {Mourtzis, D. and Angelopoulos, J. and Boli, N.},
Title = {{Maintenance assistance application of Engineering to Order manufacturing
   equipment: A Product Service System (PSS) approach}},
Journal = {{IFAC PAPERSONLINE}},
Year = {{2018}},
Volume = {{51}},
Number = {{11}},
Pages = {{217-222}},
Note = {{16th IFAC Symposium on Information Control Problems in Manufacturing
   (INCOM), Bergamo, ITALY, JUN 11-13, 2018}},
Organization = {{Int Federat Automat Control, Coordinating Comm 5 on Mfg \& Logist Syst;
   Int Federat Automat Control, Tech Comm 5 1 Mfg Plant Control; Int
   Federat Automat Control, Tech Comm 5 2 Mfg Modelling Management \&
   Control; Int Federat Automat Control, Tech Comm 5 3 Enterprise Integrat
   \& Networking; Int Federat Automat Control, Tech Comm 5 4 Large Scale
   Complex Syst; Int Federat Automat Control, Tech Comm 1 3 Discrete Event
   \& Hybrid Syst; Int Federat Automat Control, Tech Comm 4 2 Mechatron
   Syst; Int Federat Automat Control, Tech Comm 4 3 Robot; Int Federat
   Automat Control, Tech Comm 9 2 Social Impact Automat; IEEE, Italy Sect;
   IEEE, Italy Sect Instrumentat \& Measurement Chapter; IEEE, Italy Sect
   Reliabil Chapter; IEEE, Italy Sect Technol Management Chapter; IEEE,
   Italy Sect Control Syst Chapter; Int Federat Informat Proc; Int Federat
   Operat Res Soc; Italian Assoc Ind Syst Engn Professors; GDR MACS Natl
   Council Sci Res, Res Grp Modelling Anal \& Control Dynam Syst; Assoc
   Italiana Informatica Calcolo Automatico}},
Abstract = {{Following nowadays shift to Servitization and Digitalization, which is
   aligned with technological advances in mobile technologies and mixed
   reality, this paper introduces an assistance application for the
   preventive and unscheduled maintenance of manufacturing equipment,
   following a Product-Service System (PSS) approach Maintenance is a
   demanding set of tasks performed on industrial equipment and it is
   considered as a core activity throughout products' lifecycle. The main
   purpose of this work is to provide a tool which will improve the
   Business to Business (B2B) and internal communication with the use of
   smart devices, and also will lead to time and cost reduction during the
   maintenance procedures. In particular, an application utilizing AR
   technology is developed, enabling malfunction detection and reporting,
   required tasks definition and communication between all the involved
   actors. The developed application is tested in a mold making SME that is
   moving towards digitalization of its production. The initial results
   gave a reduction of the iterations with the customer, and also
   improvement of the maintenance lifecycle in terms of time. (C) 2018,
   IFAC (International Federation of Automatic Control) Hosting by Elsevier
   Ltd. All rights reserved.}},
DOI = {{10.1016/j.ifacol.2018.08.263}},
ISSN = {{2405-8963}},
Unique-ID = {{ISI:000445651000038}},
}

@article{ ISI:000446980800003,
Author = {Grandinetti, Justin and Ecenbarger, Charles},
Title = {{Imagine Pokemon in the ``Real{''} world: a Deleuzian approach to Pokemon
   GO and augmented reality}},
Journal = {{CRITICAL STUDIES IN MEDIA COMMUNICATION}},
Year = {{2018}},
Volume = {{35}},
Number = {{5}},
Pages = {{440-454}},
Abstract = {{Discussions of the augmented reality (AR) game Pokemon GO often
   reinforce the demarcation between virtual game spaces and ``real
   world{''} physical spaces. De Souza e Silva and Sutko's (2011.
   Theorizing locative technologies through philosophies of the virtual.
   Communication Theory, 21(1), 23-42.) work contests such dichotomies,
   noting the imbrication of the material and the virtual inherent in
   location-based applications. While this framework provides a starting
   point for productive examination of mobile media from a Deleuzian
   philosophical position, the growing popularity of and discourse about AR
   necessitates renewed attention to these technologies and practices.
   In theorizing a more comprehensive approach to augmented reality, we
   draw upon Wiley's (2005. Spatial materialism: Grossberg's Deleuzean
   cultural studies. Cultural Studies, 19(1), 63-99) articulation of a
   Deleuzian spatial materialism that emphasizes the imbrication of local
   and global forces, as well as technology, social relations, etc. to
   provide productive examinations of the construction of space and power
   relations. In the following paper, we offer our own contributions to
   this Deleuzian approach to AR by examining news media articles in the
   months following its release in order to better understand the popular
   positioning of the game in public discourses. Specifically, we contrast
   popular discussions of Pokemon GO with a more productive Deleuzian
   perspective, with attention to how the game is part of the production of
   space, subjectivity, and virtual potentiality.}},
DOI = {{10.1080/15295036.2018.1512751}},
ISSN = {{1529-5036}},
EISSN = {{1479-5809}},
Unique-ID = {{ISI:000446980800003}},
}

@article{ ISI:000446213600010,
Author = {Van De Sand, Ron and Schulz, Sebastian and Ritzmann, Kay and
   Reiff-Stephan, Jorg},
Title = {{Networking physical and virtual entities in CPPS - Augmented reality as
   a human-machine interface}},
Journal = {{ATP EDITION}},
Year = {{2018}},
Number = {{9}},
Pages = {{36-43}},
Abstract = {{In the future, conventional manufacturing strategies will increasingly
   be replaced by complex cyber-physical product ion systems (CPPS). Fully
   connected value-adding networks will emerge with a high information
   density, confronting employees with significantly increased amount of
   data. Therefore, the human-machine interface (HMI) represents an
   important aspect of the production process, for which new technologies
   such as augmented reality are highly promising. Such applications
   require a continuous communication from field level device to the
   appliance. This article describes how existing communications standards
   can be deployed and depicts an exemplary implementation. Furthermore, it
   proposes a communication architecture which enables interoperable
   communication between physical and virtual entities based on the
   Asset-Administration Shell (AAS).}},
ISSN = {{2190-4111}},
EISSN = {{2364-3137}},
Unique-ID = {{ISI:000446213600010}},
}

@inproceedings{ ISI:000445499800084,
Author = {Gupta, Ravi Kumar and Ucler, Caglar and Bernard, Alain},
Book-Group-Author = {{IEEE}},
Title = {{Extension of the Virtual Customer Inspection for Distant Collaboration
   in NPD A Proposal and Assessment of Challenges}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING, TECHNOLOGY AND
   INNOVATION (ICE/ITMC)}},
Series = {{International ICE Conference on Engineering Technology and Innovation}},
Year = {{2018}},
Note = {{IEEE International Conference on Engineering, Technology and Innovation
   (ICE/ITMC), Stuttgart, GERMANY, JUN 17-20, 2018}},
Organization = {{IEEE; Inst Strateg Innovat \& Technol Management; Baden Wuttemberg
   Connected; IEEE Technol \& Engn Management Soc; STW}},
Abstract = {{The usage of holographic virtual customer inspections for gathering
   feedback during the production in the aviation industry was successfully
   demonstrated in Airbus, which implied the assessment of the requirements
   spanning the Kano dimensions and conjoint analysis of satisfaction and
   importance. A further extension is proposed here as a research in
   progress to enclose early phases in New Product Development throughout
   the manufacturing. Consequently, collaboration achievement is targeted
   here by the virtual inspection of digital mock-ups, semi-/ and finished
   products to enable the circulation of knowledge and exhibiting design
   iterations in set based models. Nevertheless, challenges are associated
   to the virtual inspection, which are derived from technological
   constraints or based on the nature of distant collaboration. An
   assessment of these challenges is made by means of a hierarchical
   aggregation to discuss conceptually the applicability of the extension,
   highlighting future research areas for this field as well.}},
ISSN = {{2334-315X}},
ISBN = {{978-1-5386-1469-3}},
Unique-ID = {{ISI:000445499800084}},
}

@inproceedings{ ISI:000444770700041,
Author = {Seitz, Andreas and Henze, Dominic and Nickles, Jochen and Sauer, Markus
   and Bruegge, Bernd},
Book-Group-Author = {{IEEE}},
Title = {{Augmenting the Industrial Internet of Things with Emojis}},
Booktitle = {{2018 THIRD INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING
   (FMEC)}},
Year = {{2018}},
Pages = {{240-245}},
Note = {{3rd International Conference on Fog and Mobile Edge Computing (FMEC),
   Barcelona, SPAIN, APR 23-26, 2018}},
Organization = {{IEEE Spain Sect; Univ Politecnica Valencia; Jordan Univ Sci \& Technol;
   Univ Politecnica Catalunya; Centro Nacl Supercomputac, Barcelona
   Supercomputing Ctr; Staffordshire Univ; Open Fog Consortium; Inst
   Investigac para gest integrada zonas costeras}},
Abstract = {{Technologies such as Augmented Reality (AR) and Fog Computing permeate
   more and more areas of our daily lives. These technologies are used in
   various domains such as eHealth, Gaming and Smart Cities. However,
   within the Industrial Internet of Things (IIoT), these technologies are
   slowly finding their way into the market, although they can be drivers
   of resource efficient and sustainable production economies. By combining
   these technologies with shared knowledge resources, such as Emojis, new
   interactions within the industrial domain can be created. These simplify
   the analysis of conditions of industrial machines and allow the
   derivation of preventive maintenance measures. In recent years, an
   increasing number of IoT devices has been observed in the industrial
   environment. However, the large number of sensors and actuators in
   industrial plants also pose challenges for employees. Augmented Reality
   enables new interaction scenarios to facilitate the daily work of
   employees by presenting machine states in a new way. Emojis and graphs
   are options for visualizing these states. Downtimes can be reduced by
   viewing and analyzing the data. The saving of seconds or minutes has a
   real impact on the business and is of great interest. In this paper, we
   describe the approach of Augmenting IIoT devices with Emojis to
   visualize states and conditions of production lines. We present a
   prototype that we have implemented, our experiences with it as well as
   the challenges we have uncovered.}},
ISBN = {{978-1-5386-5896-3}},
Unique-ID = {{ISI:000444770700041}},
}

@article{ ISI:000443884800004,
Author = {Hannola, Lea and Richter, Alexander and Richter, Shahper and Stocker,
   Alexander},
Title = {{Empowering production workers with digitally facilitated knowledge
   processes - a conceptual framework}},
Journal = {{INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH}},
Year = {{2018}},
Volume = {{56}},
Number = {{14}},
Pages = {{4729-4743}},
Abstract = {{Recent digital advancements, including social software, mobile
   technologies and augmented reality, offer promising opportunities to
   empower knowledge workers in their production environment by leveraging
   their knowledge processes, decision-making skills and social interaction
   practices. This paper proposes a conceptual framework for empowering
   workers in industrial production environments with digitally facilitated
   knowledge management processes. The framework explores four concrete
   facets of digital advancements that apply to a wide range of knowledge
   processes and production strategies in manufacturing companies. Each of
   these advancements are capable of supporting one specific facet of the
   individual knowledge management processes of workers; knowledge
   transfer, discovery, acquisition and sharing. The study contributes to
   the production research community by aligning emerging digital
   technologies and current trends in advanced manufacturing environments
   to benefit workers and improve job satisfaction, efficiency and
   productivity. The paper also contains suggestions about developing
   innovative solutions for production environments that support workers
   with digital technologies for flexible production.}},
DOI = {{10.1080/00207543.2018.1445877}},
ISSN = {{0020-7543}},
EISSN = {{1366-588X}},
Unique-ID = {{ISI:000443884800004}},
}

@article{ ISI:000443741700006,
Author = {Beltran-Pellicer, Pablo},
Title = {{About monster trucks, measurement, angles and STEM}},
Journal = {{EDMA 0-6-EDUCACION MATEMATICA EN LA INFANCIA}},
Year = {{2018}},
Volume = {{7}},
Number = {{1}},
Pages = {{99-108}},
Abstract = {{This time it's the turn of a cartoon series in which mathematics are
   present, but within what is known as STEM. We introduce Blaze and the
   Monster Machines, in which some trucks, with the help of two human
   characters and a helmet of augmented reality, solve problems with the
   help of mathematics, science and technology. We describe roughly this
   production and we focus on the most explicit mathematical contents:
   measurement throughout the first season, where extensive and intensive
   magnitudes appear; and the angles.}},
ISSN = {{2254-8351}},
Unique-ID = {{ISI:000443741700006}},
}

@article{ ISI:000439460500003,
Author = {Pantano, Eleonora and Priporas, Constantinos Vasilios and Dennis,
   Charles},
Title = {{A new approach to retailing for successful competition in the new smart
   scenario}},
Journal = {{INTERNATIONAL JOURNAL OF RETAIL \& DISTRIBUTION MANAGEMENT}},
Year = {{2018}},
Volume = {{46}},
Number = {{3}},
Pages = {{264-282}},
Abstract = {{Purpose This study develops the idea of smart retailing, exemplified in
   innovative, technology-enriched retail services as part of
   service-oriented strategies. In particular, the purpose of this paper is
   to provide a new integrated framework to understand the emerging retail
   scenario based on the smart usage of technologies to improve retail
   service and develop innovation management strategies. This framework
   will provide a comprehensive understanding the basic forms of smart
   retailing as the current competitive scenario.
   Design/methodology/approach As a viewpoint, this paper employs an
   interdisciplinary approach, drawing upon the actual challenges in
   retailing, to propose a new perspective, the smart retailing one, to
   describe the new competitive scenario and formulates an emerging
   research agenda.
   Findings The present paper contributes to research on innovation and
   technology management for retailing by examining the key dimensions of
   smart retailing, which aims to enhancing retail service quality and
   retailers' performance.
   Originality/value The paper clearly explains how current retailing is
   moving to a smart perspective, and how retail management should be
   adapted to successfully perform in the current service-dominant logic
   scenario, as consequence of the increasing consumer involvement in
   service co-production and the rapid growth of digital technologies.}},
DOI = {{10.1108/IJRDM-04-2017-0080}},
ISSN = {{0959-0552}},
EISSN = {{1758-6690}},
Unique-ID = {{ISI:000439460500003}},
}

@inproceedings{ ISI:000437351700337,
Author = {Chang, Sheng-Hsiung and Cho, Ta-Hsiung and Chen, Yen-Chun and Chen,
   Yu-Sheng and Li, Yu and Lin, Jun-Hao},
Editor = {{Lam, ADKT and Meen, TH and Prior, SD}},
Title = {{A Study of Innovative 3D Imaging Device Using Zoom Technology}},
Booktitle = {{PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM
   INNOVATION 2018 ( IEEE ICASI 2018 )}},
Year = {{2018}},
Pages = {{1264-1267}},
Note = {{4th IEEE International Conference on Applied System Invention (IEEE
   ICASI), Tokyo, JAPAN, APR 13-17, 2018}},
Organization = {{IEEE; IEEE Tainan Sec Sensors Council; Taiwanese Inst Knowledge Innovat}},
Abstract = {{This study has completed the design and production of an innovative 3D
   display device system, which can be applied to augmented reality
   technologies. To complete the installation, perform the following steps:
   A. multiple plane images generated by the image output unit, the time
   each plane image produces is different. And the plane images are
   respectively the planes of different depth positions in a complete
   stereoscopic image. B. by the imaging module position changes, resulting
   in different object distance, so different depth positions corresponding
   to the foregoing planar image are imaged. So as to form the complete
   three-dimensional image by combining the aforementioned planar images by
   means of visual residue.}},
ISBN = {{978-1-5386-4342-6}},
Unique-ID = {{ISI:000437351700337}},
}

@article{ ISI:000438864500003,
Author = {Lorenzo Lledo, Gonzalo and Scagliarini Galiano, Christina},
Title = {{Bibliometric review of augmented reality in education}},
Journal = {{REVISTA GENERAL DE INFORMACION Y DOCUMENTACION}},
Year = {{2018}},
Volume = {{28}},
Number = {{1}},
Pages = {{45-60}},
Abstract = {{Education is one of the basic support of today's societies. There are
   many tools to improve the quality of educational processes. One of the
   new instruments being applied in recent years is augmented reality.
   Therefore, the aim of this research was to obtain a review of the state
   of scientific production on augmented reality in Education. To do this,
   it has been worked with the advanced search tab of the Web of Science.
   After that, it was achieved a sample of 347 articles that were analyzed
   according to a series of bibliometric indicators. The results indicate
   that the vast majority of journals are included in the Emerging Citation
   Index; however, the authors often publish in JCR journals (q3). In the
   same way, authors tend to cite more often those articles that come from
   years with little scientific production. In the same way, Spain is the
   largest producer of articles and has a high expansion rate due to its
   low isolation rate. Finally, the 2015-2017 period has been the highest
   year's production. Future research will consider analyzing which topics
   have been studied on and the systems applied.}},
DOI = {{10.5209/RGID.60805}},
ISSN = {{1132-1873}},
EISSN = {{1988-2858}},
Unique-ID = {{ISI:000438864500003}},
}

@inproceedings{ ISI:000437126800059,
Author = {Palmarini, Riccardo and del Amo, Inigo Fernandez and Bertolino,
   Guglielmo and Dini, Gino and Erkoyuncu, John Ahmet and Roy, Rajkumar and
   Farnsworth, Michael},
Editor = {{Laroche, F and Bernard, A}},
Title = {{Designing an AR interface to improve trust in Human-Robots collaboration}},
Booktitle = {{28TH CIRP DESIGN CONFERENCE 2018}},
Series = {{Procedia CIRP}},
Year = {{2018}},
Volume = {{70}},
Pages = {{350-355}},
Note = {{28th CIRP Design Conference, Nantes, FRANCE, MAY 23-25, 2018}},
Organization = {{CIRP}},
Abstract = {{In a global, e-commerce marketplace, product customisation is driven
   towards manufacturing flexibility. Conventional caged robots are
   designed for high volume and low mix production cannot always comply
   with the increasing low volume and high customisation requirements. In
   this scenario, the interest in collaborative robots is growing. A
   critical aspect of Human-Robot Collaboration (HRC) is human trust in
   robots. This research focuses on increasing the human confidence and
   trust in robots by designing an Augmented Reality (AR) interface for
   HRC. The variable affecting the trust involved in HRC have been
   estimated. These have been utilised for designing the AR-HRC. The
   proposed design aims to provide situational awareness and spatial
   dialog. The AR-HRC developed has been tested on 15 participants which
   have performed a ``pick-and place{''} task. The results show that the
   utilisation of AR in the proposed scenario positively affects the human
   trust in robot. The human-robot collaboration enhanced by AR are more
   natural and effective. The trust has been measured through an empirical
   psychometric method also presented in this paper. (C) 2018 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.procir.2018.01.009}},
ISSN = {{2212-8271}},
ORCID-Numbers = {{Fernandez del Amo Blanco, Inigo Gregorio/0000-0002-4838-1477}},
Unique-ID = {{ISI:000437126800059}},
}

@inproceedings{ ISI:000437126800062,
Author = {Mourtzis, Dimitris and Zogopoulos, Vasilios and Katagis, Ioannis and
   Lagios, Panagiotis},
Editor = {{Laroche, F and Bernard, A}},
Title = {{Augmented Reality based Visualization of CAM Instructions towards
   Industry 4.0 paradigm: a CNC Bending Machine case study}},
Booktitle = {{28TH CIRP DESIGN CONFERENCE 2018}},
Series = {{Procedia CIRP}},
Year = {{2018}},
Volume = {{70}},
Pages = {{368-373}},
Note = {{28th CIRP Design Conference, Nantes, FRANCE, MAY 23-25, 2018}},
Organization = {{CIRP}},
Abstract = {{Skilled shop-floor technicians are playing an important role in modem
   Industry 4.0 manufacturing environments, especially in small and
   customized manufacturing systems. Moving towards Industry 4.0 business
   models, it is essential to develop advanced solutions that will
   reinforce the position of technicians in manufacturing, by implementing
   key enabling technologies. Augmented Reality (AR) has arisen as a key
   enabling technology, which will enable the transfer of information from
   digitalized design systems and databases towards human operators,
   especially including production and maintenance information. Reinforced
   by the development of advanced communication technologies that support
   high speed data transfer, such as 5G, and networks that combine low
   latency with increased availability, such as tactile internet, AR
   proposes a way for agile information distribution and increased
   shop-floor status awareness. This study presents a mobile application
   for visualizing Computer Aided Manufacturing (CAM) instructions for
   bending processes using Augmented Reality. The application integrates
   step-by-step process instructions, highly usable menus and advanced
   visualization that includes safety zones, indications, and text
   instructions for the operators. The developed framework is applied and
   validated in a CNC bending machine in a real world scenario provided by
   a CNC machines manufacturer. (C) 2018 The Authors. Published by Elsevier
   B.V.}},
DOI = {{10.1016/j.procir.2018.02.045}},
ISSN = {{2212-8271}},
Unique-ID = {{ISI:000437126800062}},
}

@article{ ISI:000434945800001,
Author = {Fernandez-Carames, Tiago M. and Fraga-Lamas, Paula},
Title = {{A Review on Human-Centered IoT-Connected Smart Labels for the Industry
   4.0}},
Journal = {{IEEE ACCESS}},
Year = {{2018}},
Volume = {{6}},
Pages = {{25939-25957}},
Abstract = {{One of the challenges of Industry 4.0 is the creation of vertical
   networks that connect smart production systems with design teams,
   suppliers, and the front office. To achieve such a vision, information
   has to be collected from machines and products throughout a smart
   factory. Smart factories are defined as flexible and fully connected
   factories that are able to make use of constant streams of data from
   operations and production systems. In such scenarios, the arguably most
   popular way for identifying and tracking objects is by adding labels or
   tags, which have evolved remarkably over the last years: from pure
   hand-written labels to barcodes, QR codes, and RFID tags. The latest
   trend in this evolution is smart labels which are not only mere
   identifiers with some kind of internal storage, but also sophisticated
   context-aware tags with embedded modules that make use of wireless
   communications, energy efficient displays, and sensors. Therefore, smart
   labels go beyond identification and are able to detect and react to the
   surrounding environment. Moreover, when the industrial Internet of
   Things paradigm is applied to smart labels attached to objects, they can
   be identified remotely and discovered by other Industry 4.0 systems,
   what allows such systems to react in the presence of smart labels, thus
   triggering specific events or performing a number of actions on them.
   The amount of possible interactions is endless and creates unprecedented
   industrial scenarios, where items can talk to each other and with tools,
   machines, remote computers, or workers. This paper, after reviewing the
   basics of Industry 4.0 and smart labels, details the latest technologies
   used by them, their applications, the most relevant academic and
   commercial implementations, and their internal architecture and design
   requirements, providing researchers with the necessary foundations for
   developing the next generation of Industry 4.0 human-centered smart
   label applications.}},
DOI = {{10.1109/ACCESS.2018.2833501}},
ISSN = {{2169-3536}},
ORCID-Numbers = {{Fernandez-Carames, Tiago M./0000-0003-2179-5917
   Fraga-Lamas, Paula/0000-0002-4991-6808}},
Unique-ID = {{ISI:000434945800001}},
}

@inproceedings{ ISI:000434866100057,
Author = {Chung, Szu-Ming and Lin, Hui-Guan and Tsou, Tsai-Ling and Wu, Chun-Tsai
   and Huang, Chun-Hsiung},
Book-Group-Author = {{IEEE}},
Title = {{Experiencing Musical Rhythm through Interactive Installation and AR/VR
   Game Development}},
Booktitle = {{PROCEEDINGS OF 2018 IEEE GLOBAL ENGINEERING EDUCATION CONFERENCE
   (EDUCON) - EMERGING TRENDS AND CHALLENGES OF ENGINEERING EDUCATION}},
Series = {{IEEE Global Engineering Education Conference}},
Year = {{2018}},
Pages = {{384-388}},
Note = {{IEEE Global Engineering Education Conference (EDUCON) - Emerging Trends
   and Challenges of Engineering Education, Santa Cruz de Tenerife, SPAIN,
   APR 17-20, 2018}},
Organization = {{IEEE; Coplaca; Fuentealta; Soc Desarrollo Ayuntamiento Tenerife; Grupo
   Visual Canarias; MathWorks; Cypress; Pentec Blackboard; UNIR iTED}},
Abstract = {{to better perceive and internalize rhythmic feeling and understand its
   relation to musical ideas, and furthermore create music coping with
   visual production, this game development includes 3 stages of training,
   thinking/designing and creating, The stage I is to realize and feel the
   rhythm and pulsation through body movements with a device on foot
   stepping boards with a game interface on computer. On Stage II and Ill,
   a simple AR/VR simulation system offers basic ideas of rhythmic pattern
   related to melodic line through creating virtual instruments and
   improvising music on them.}},
ISSN = {{2165-9567}},
ISBN = {{978-1-5386-2957-4}},
Unique-ID = {{ISI:000434866100057}},
}

@inproceedings{ ISI:000435011300022,
Author = {Zajc, Luka Cehovin and Rezelj, Anze and Skocaj, Danijel},
Editor = {{Lepuschitz, W and Merdan, M and Koppensteiner, G and Balogh, R and Obdrzalek, D}},
Title = {{Open-Source Robotic Manipulator and Sensory Platform}},
Booktitle = {{ROBOTICS IN EDUCATION: LATEST RESULTS AND DEVELOPMENTS}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2018}},
Volume = {{630}},
Pages = {{250-256}},
Note = {{8th International Conference on Robotics in Education (RiE), Sofia,
   BULGARIA, APR 26-28, 2017}},
Organization = {{SAP Labs Bulgaria; Avitel; Sofia Tech Park}},
Abstract = {{We present an open-source robotic platform for educational use that
   integrates multiple levels of interaction through the use of additional
   vision sensor. The environment can be used in virtual, augmentedreality
   and real-robot modes, enabling smooth transition from a virtual robot
   manipulator to a real one. We describe the main aspects of our platform
   that ensure low production costs and encourage openness of both its
   hardware and software. The main goal of our work was to create a viable
   low-cost robotic manipulator platform alternative for the university
   level courses in intelligent robotics, however, the application domain
   is very broad.}},
DOI = {{10.1007/978-3-319-62875-2\_22}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-3-319-62875-2; 978-3-319-62874-5}},
Unique-ID = {{ISI:000435011300022}},
}

@article{ ISI:000432407500005,
Author = {Sun, Jianing and Gao, Minglei and Wang, Qifeng and Jiang, Minjie and
   Zhang, Xuan and Schmitt, Robert},
Title = {{SMART SERVICES FOR ENHANCING PERSONAL COMPETENCE IN INDUSTRIE 4.0
   DIGITAL FACTORY}},
Journal = {{LOGFORUM}},
Year = {{2018}},
Volume = {{14}},
Number = {{1}},
Pages = {{51-57}},
Abstract = {{Background: Adaptive digitalization and networking of machines, working
   parts, employees and other entities on the plant floor are core of
   realizing industry 4.0, so that information and instruction will be
   available everywhere and all the time in the production process. Thus,
   smart devices, especially smart wearables, will play a very important
   role to help workers being integrated in the in the future manufacturing
   environment, as information need to be transferred faster and with the
   right level of detailing with respect to the individual need of workers,
   factory managers etc.
   Methods: The implementation of an indoor localization system using
   Bluetooth beacons in the shop floor as part of an enterprise IoT
   platform was introduced. This sensor network is aimed to implement
   tracing and tracking of workers and working parts in the future smart
   factory, as well as the to the networking of the smart wearables with
   existing manufacturing machines. The investigated problem was the
   inaccuracy and the instability of the sensor signals by such Bluetooth
   sensor networks. To solve the problem, various algorithms were
   investigated.
   Results and conclusions: The possible solution of given problem was
   solved by finding an algorithm improving the communication between
   devices. Together with the location information from Beacon network and
   orientation information from the compass sensor, it is able to determine
   the machine in the near, which the employee with the Smart Glasses is
   currently pointing to.}},
DOI = {{10.17270/J.LOG.2018.239}},
ISSN = {{1895-2038}},
EISSN = {{1734-459X}},
Unique-ID = {{ISI:000432407500005}},
}

@article{ ISI:000431806000006,
Author = {Eve, Stuart},
Title = {{Losing our Senses, an Exploration of 3D Object Scanning}},
Journal = {{OPEN ARCHAEOLOGY}},
Year = {{2018}},
Volume = {{4}},
Number = {{1}},
Pages = {{114-122}},
Month = {{JAN}},
Abstract = {{3D scanning and photogrammetry of archaeological objects are now
   becoming commonplace. Virtual 3D scans are in many cases replacing the
   drawn record and are leading to objects being more easily accessed,
   shared and analysed. However, the wholesale production of 3D virtual
   replicas of artefacts is not always supported by adequate information
   regarding the multi-sensory nature of artefacts. The visual and
   geometric aspects are well represented, but the sounds and smells of the
   artefacts are lost. This paper explores the possible consequences of
   this and provides some indications of how we may remedy the situation,
   before our 3D archives become senseless.}},
DOI = {{10.1515/opar-2018-0007}},
ISSN = {{2300-6560}},
Unique-ID = {{ISI:000431806000006}},
}

@article{ ISI:000428859200036,
Author = {Wang, X. and Ong, S. K. and Nee, A. Y. C.},
Title = {{A comprehensive survey of ubiquitous manufacturing research}},
Journal = {{INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH}},
Year = {{2018}},
Volume = {{56}},
Number = {{1-2, SI}},
Pages = {{604-628}},
Abstract = {{In the past 10 years, ubiquitous manufacturing (UM) has received a
   growing amount of attention among researchers in the manufacturing
   community because ubiquitous computing technologies (UCTs) can be
   applied to address a wide range of issues in the manufacturing industry,
   e.g. manufacturing processes and equipment, manufacturing management and
   planning. However, to the best of the authors' knowledge, there is a
   lack of comprehensive and critical review from a holistic view of the
   state-of-the-art UM and its systems. This paper aims to provide a
   concise overview of the technical features, characteristics and broad
   range of applications of UM systems published between 1997 and 2017.
   Among these selected articles, more than 70\% of them were published
   between 2012 and 2017, and they are considered as recent pertinent works
   which will be discussed in detail. The unique aspects of this paper lie
   in that this paper summarises and analyses a broad range of the
   state-of-the-art implementation of UM systems from a holistic and
   comprehensive view of manufacturing technology, including UM for
   manufacturing processes, manufacturing control systems, logistics,
   remanufacturing, cloud manufacturing, production scheduling, production
   quality control and evaluation, etc. In addition, the current limitation
   factors and future trends of UM development will also be discussed.}},
DOI = {{10.1080/00207543.2017.1413259}},
ISSN = {{0020-7543}},
EISSN = {{1366-588X}},
Unique-ID = {{ISI:000428859200036}},
}

@article{ ISI:000428622700007,
Author = {Gottlieb, Owen},
Title = {{Time travel, labour history, and the null curriculum: new design
   knowledge for mobile augmented reality history games}},
Journal = {{INTERNATIONAL JOURNAL OF HERITAGE STUDIES}},
Year = {{2018}},
Volume = {{24}},
Number = {{3}},
Pages = {{287-299}},
Abstract = {{This paper presents a case study drawn from design-based research (DBR)
   on a mobile, place-based augmented reality history game. Using DBR
   methods, the game was developed by the author as a history learning
   intervention for fifth to seventh graders. The game is built upon
   historical narratives of disenfranchised populations that are seldom
   taught, those typically relegated to the `null curriculum'. These
   narratives include the stories of women immigrant labour leaders in the
   early twentieth century, more than a decade before suffrage. The project
   understands the purpose of history education as the preparation of
   informed citizens. In paying particular attention to historical themes
   that endure over time, the game aims to draw connections between
   historical and contemporary narratives of diverse and disenfranchised
   populations. The study discusses new design knowledge for addressing
   such narratives. Self-reflexivity, the technique of revealing the means
   of production of the game technology itself can be used to spotlight
   contemporary issues of disenfranchisement. Supra-reveals, historical
   thematic foreshadowing, can help establish key links between themes of
   disenfranchisement of diverse groups in the past and those in the
   present. These techniques used together, and the subsequent curriculum,
   brought focus to teaching issues of diversity and disenfranchisement
   typically written out of curriculum.}},
DOI = {{10.1080/13527258.2017.1325768}},
ISSN = {{1352-7258}},
EISSN = {{1470-3610}},
Unique-ID = {{ISI:000428622700007}},
}

@article{ ISI:000425075400044,
Author = {Gupta, Ravi Kumar and Belkadi, Farouk and Buergy, Christian and Bitte,
   Frank and Da Cunha, Catherine and Buergin, Jens and Lanza, Gisela and
   Bernard, Alain},
Title = {{Gathering, evaluating and managing customer feedback during aircraft
   production}},
Journal = {{COMPUTERS \& INDUSTRIAL ENGINEERING}},
Year = {{2018}},
Volume = {{115}},
Pages = {{559-572}},
Month = {{JAN}},
Abstract = {{This paper proposes a systematic approach for gathering requirements
   during production through customers' remote access to the partially and
   fully assembled aircraft and its modules. The paper also proposes an
   evaluation and management of these recorded requirements and their
   utilization in the development of an aircraft. Modular product
   architecture is used for the modular organization of the product,
   product-service, and production system for the gathering, evaluation and
   management of feedback for product development perspectives. A mobile
   and wearable augmented reality system is used to virtually walk through
   the partially or fully manufactured product and to compare the status of
   the production with the product model to be produced. Change requests
   are captured as customer feedback. The knowledge thus acquired can be
   overlaid (augmented) on the real product, i.e. the aircraft. This
   approach is able to record the dynamic requirements of targeted
   customers. These changes can be carried out in the current version of
   the aircraft, and also incorporated into future versions. The
   implementation using case studies is presented for gathering feedback
   during assembly as well as for evaluating and managing the recorded
   feedback for exemplary modules (cabin and galley) of an aircraft. The
   use of the evaluation results in the development of an aircraft is also
   presented in the paper.}},
DOI = {{10.1016/j.cie.2017.12.012}},
ISSN = {{0360-8352}},
EISSN = {{1879-0550}},
ResearcherID-Numbers = {{Gupta, Ravi Kumar/D-7466-2011
   }},
ORCID-Numbers = {{Gupta, Ravi Kumar/0000-0003-4419-8111
   BERNARD, Alain/0000-0002-7037-2980}},
Unique-ID = {{ISI:000425075400044}},
}

@article{ ISI:000419114100039,
Author = {Uva, Antonio E. and Gattullo, Michele and Manghisi, Vito M. and
   Spagnulo, Daniele and Cascella, Giuseppe L. and Fiorentino, Michele},
Title = {{Evaluating the effectiveness of spatial augmented reality in smart
   manufacturing: a solution for manual working stations}},
Journal = {{INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY}},
Year = {{2018}},
Volume = {{94}},
Number = {{1-4}},
Pages = {{509-521}},
Month = {{JAN}},
Abstract = {{Augmented reality (AR) is a key technology for the development of smart
   manufacturing. One of the main advantages of AR is that it can help
   workers to accomplish several tasks, making it possible the shift from
   mass production to mass customization. However, it is still not clear
   how these promises can be fulfilled in an industrial scenario. In
   particular, the question about which display solutions fit better the
   industrial constraints remains open. Based on the literature overview,
   laboratory experiments, and feedbacks from industrial companies, we
   supported the use of spatial augmented reality (SAR), designing a
   prototype intended to be used for manual working stations of the future
   smart factories. This work presents the evaluation of the effectiveness
   of conveying technical instructions with this SAR prototype as compared
   to paper manual. We run a within-subjects experiment with 16
   participants to measure user task performance (completion times and
   error rates) and to collect subjective evaluation. We projected
   technical information on a motorbike engine during a seven-task
   maintenance procedure. Our results proved that SAR technology improves
   the operators' performance with respect to a paper manual and that users
   well accept it. We found that SAR is more effective for difficult tasks
   than for simple ones and that the main advantage of SAR is related more
   to the reduction of error rates than to completion times. These results
   confirm the goodness of our design choices; then our prototype can be a
   valid candidate solution for a smart manufacturing application.}},
DOI = {{10.1007/s00170-017-0846-4}},
ISSN = {{0268-3768}},
EISSN = {{1433-3015}},
ORCID-Numbers = {{Manghisi, Vito Modesto/0000-0002-5293-9955}},
Unique-ID = {{ISI:000419114100039}},
}

@article{ ISI:000417367400002,
Author = {Bayon, Fernando and Cuenca, Jaime and Antonio Caride, Jose},
Title = {{REIMAGINING THE CITY. YOUTH LEISURE PRACTICES AND THE PRODUCTION OF
   PUBLIC URBAN SPACE}},
Journal = {{OBETS-REVISTA DE CIENCIAS SOCIALES}},
Year = {{2017}},
Volume = {{12}},
Number = {{1, 1}},
Pages = {{21-41}},
Month = {{NOV}},
Abstract = {{After reviewing some of the most recent discursive transformations in
   the understanding of urban space, this theoretical article analyses
   three youth leisure practices, which were selected because of their
   special link with the city plot: skateboarding, graffiti and the
   augmented reality game Pokemon Go. We intend to contribute to the
   understanding of the role of contemporary forms of youth leisure, and
   the their own types of experience, in the restructuring of the urban
   imaginary and the production of the public space nowadays.}},
DOI = {{10.14198/OBETS2017.12.1.10}},
ISSN = {{1989-1385}},
ORCID-Numbers = {{Caride Gomez, Jose Antonio/0000-0002-8651-4859}},
Unique-ID = {{ISI:000417367400002}},
}

@article{ ISI:000414896200217,
Author = {Dallasega, Patrick and Rauch, Erwin},
Title = {{Sustainable Construction Supply Chains through Synchronized Production
   Planning and Control in Engineer-to-Order Enterprises}},
Journal = {{SUSTAINABILITY}},
Year = {{2017}},
Volume = {{9}},
Number = {{10}},
Month = {{OCT}},
Abstract = {{Sustainability in the supply chain is becoming more and more important
   for industrial enterprises in different sectors. This research article
   focuses on construction supply chains (CSCs) in the Engineer-to-Order
   (ETO) industry, where every product is almost unique based on specific
   customer needs and requirements. The development of methods and
   approaches for more sustainable supply chain management in construction
   is becoming even more important. Engineering, fabrication of parts and
   their installation on-site are not always well synchronized in ETO
   supply chains. The results of such supply chains are long lead times,
   inefficient material transport and high and uncontrolled levels of
   work-in-progress (WIP). This article describes a conceptual approach to
   synchronize demand on-site with supply in manufacturing using the
   CONstant Work In Progress (ConWIP) concept from Lean Management to
   achieve Just-in-Time (JIT) supply. As a result, sustainable supply
   chains in ETO enterprises, with optimizations from an economic,
   ecological and social point of view, can be designed. The approach has
   been validated in an industrial case study.}},
DOI = {{10.3390/su9101888}},
Article-Number = {{1888}},
ISSN = {{2071-1050}},
ORCID-Numbers = {{Rauch, Erwin/0000-0002-2033-4265
   Dallasega, Patrick/0000-0001-6120-8620}},
Unique-ID = {{ISI:000414896200217}},
}

@article{ ISI:000407222000001,
Author = {Mohammadi, Babak and Saeedi, Marjan and Haghpanah, Vahid},
Title = {{Smart article: application of intelligent platforms in next generation
   biomedical publications}},
Journal = {{JOURNAL OF DIABETES AND METABOLIC DISORDERS}},
Year = {{2017}},
Volume = {{16}},
Month = {{AUG 3}},
Abstract = {{Production of scientific data has been accelerated exponentially though
   ease of access to the required knowledge is still challenging. Hence,
   the emergence of new frameworks to allow more efficient storage of
   information would be beneficial. Attaining intelligent platforms enable
   the smart article to serve as a forum for exchanging idea among experts
   of academic disciplines for a rapid and efficient scientific discourse.}},
DOI = {{10.1186/s40200-017-0314-6}},
Article-Number = {{31}},
ISSN = {{2251-6581}},
Unique-ID = {{ISI:000407222000001}},
}

@article{ ISI:000412612100026,
Author = {Mandolini, Marco and Brunzini, Agnese and Germani, Michele},
Title = {{A collaborative web-based platform for the prescription of Custom-Made
   Insoles}},
Journal = {{ADVANCED ENGINEERING INFORMATICS}},
Year = {{2017}},
Volume = {{33}},
Pages = {{360-373}},
Month = {{AUG}},
Abstract = {{Many foot pathologies are prevented or treated with Custom Made Insoles
   (CMIs). Although a strong computerization has characterized the shoe
   development process during the last decade, the CMI sector still lacks a
   software platform integrating the design and diagnosis tools used by the
   stakeholders of this area. Moreover, the prescription of CMIs is only
   based on the experience of skilled podiatrists rather than on a common
   and shared knowledge (e.g. guidelines, best practices, rules, etc.).
   This paper presents a multi-users and knowledge-based platform, called
   Smart Prescription Platform (SPP), covering the whole CMI development
   phases, from foot diagnosis to the production, involving clinicians,
   patients, manufacturers and controllers. The web-based platform is fully
   integrated with the technologies available in the orthopaedic sector,
   which are 3D/4D scanners, baropodometric platforms, footwear virtual
   catalogues, plantar pressure simulators, Augmented Reality devices and
   3D CAD systems. The use of standard file formats (e.g..stl,.bmp,.xml)
   allows an electronic dataflow among the tools. The main module of the
   platform, called Prescription System (PS), is used for prescribing
   custom-made insoles for patients with different health conditions,
   satisfying the needs of all actors and optimizing the data exchange. PS
   is a knowledge-based prescription system integrating the best practices
   related to the prescription of CMIs. The PS output is a XML file
   representing the electronic order, used to exchange data with the other
   tools of the SPP.
   The proposed platform has been tested with a twofold aim: to validate
   the usability of the Prescription System and the inter-operability of
   the platform tools. The positive results gathered during the validation,
   led the experts to start using the web platform for their daily work.
   (C) 2016 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.aei.2016.10.004}},
ISSN = {{1474-0346}},
EISSN = {{1873-5320}},
ORCID-Numbers = {{Mandolini, Marco/0000-0003-0962-5982
   Germani, Michele/0000-0003-1988-8620}},
Unique-ID = {{ISI:000412612100026}},
}

@article{ ISI:000425022100017,
Author = {Roman Gravan, Pedro},
Title = {{The design, production, evaluation and use of augmented reality in
   education}},
Journal = {{PIXEL-BIT- REVISTA DE MEDIOS Y EDUCACION}},
Year = {{2017}},
Number = {{51}},
Pages = {{243-244}},
Month = {{JUL}},
ISSN = {{1133-8482}},
EISSN = {{2171-7966}},
Unique-ID = {{ISI:000425022100017}},
}

@article{ ISI:000404590000006,
Author = {Fombona, Javier and Pascual-Sevillano, Maria-Angeles and
   Gonzalez-Videgaray, MariCarmen},
Title = {{M-learning and Augmented Reality: A Review of the Scientific Literature
   on the WoS Repository}},
Journal = {{COMUNICAR}},
Year = {{2017}},
Number = {{52}},
Pages = {{63-71}},
Month = {{JUL 1}},
Abstract = {{Augmented reality emerges as a tool, on which it is necessary to examine
   its real educational value. This paper shows the results of a
   bibliometric analysis performed on documents collected from the Web of
   Science repository, an Internet service that concentrates bibliographic
   information from more than 7,000 institutions. Our analysis included an
   overall universe of 12,000 indexed journals and 148,000 conference
   proceedings. From those, we selected a sample targeting the terms
   ``mobile-learning{''} or ``m-learning{''} and ``augmented reality{''} as
   descriptors or components of titles of scientific works. The analysis on
   journals (n=741) and in conference proceedings (n= 913) reveals a
   differentiated perspective in each area in the last two years. A
   qualitative analysis of 67 scientific productions addressing these
   subjects complements the research. This highlights five themes:
   conceptualization of the phenomenon, development of new methodologies,
   motivation, spatial delocalization, and implementation in subject-matter
   areas. The research highlights logical changes, such as greater and
   differentiated access to information; transcendent innovations, such as
   increasing informal and ludic activities, insertion into virtual
   environments, membership of specific groups, and networks of friendly
   interaction, along creation of new scales of values. These elements are
   now beginning to constitute fundamental parts of teaching methodologies.
   Education appears to be subsidiary to technical advances, thus imposing
   a drastic methodological change.}},
DOI = {{10.3916/C52-2017-06}},
ISSN = {{1134-3478}},
EISSN = {{1988-3293}},
Unique-ID = {{ISI:000404590000006}},
}

@article{ ISI:000402564400002,
Author = {Oshiro, Yukio and Ohkohchi, Nobuhiro},
Title = {{Three-Dimensional Liver Surgery Simulation: Computer-Assisted Surgical
   Planning with Three-Dimensional Simulation Software and
   Three-Dimensional Printing}},
Journal = {{TISSUE ENGINEERING PART A}},
Year = {{2017}},
Volume = {{23}},
Number = {{11-12}},
Pages = {{474-480}},
Month = {{JUN}},
Abstract = {{To perform accurate hepatectomy without injury, it is necessary to
   understand the anatomical relationship among the branches of Glisson's
   sheath, hepatic veins, and tumor. In Japan, three-dimensional (3D)
   preoperative simulation for liver surgery is becoming increasingly
   common, and liver 3D modeling and 3D hepatectomy simulation by 3D
   analysis software for liver surgery have been covered by universal
   healthcare insurance since 2012. Herein, we review the history of
   virtual hepatectomy using computer-assisted surgery (CAS) and our
   research to date, and we discuss the future prospects of CAS. We have
   used the SYNAPSE VINCENT medical imaging system (Fujifilm Medical,
   Tokyo, Japan) for 3D visualization and virtual resection of the liver
   since 2010. We developed a novel fusion imaging technique combining 3D
   computed tomography (CT) with magnetic resonance imaging (MRI). The
   fusion image enables us to easily visualize anatomic relationships among
   the hepatic arteries, portal veins, bile duct, and tumor in the hepatic
   hilum. In 2013, we developed an original software, called Liversim,
   which enables real-time deformation of the liver using physical
   simulation, and a randomized control trial has recently been conducted
   to evaluate the use of Liversim and SYNAPSE VINCENT for preoperative
   simulation and planning. Furthermore, we developed a novel hollow
   3D-printed liver model whose surface is covered with frames. This model
   is useful for safe liver resection, has better visibility, and the
   production cost is reduced to one-third of a previous model.
   Preoperative simulation and navigation with CAS in liver resection are
   expected to help planning and conducting a surgery and surgical
   education. Thus, a novel CAS system will contribute to not only the
   performance of reliable hepatectomy but also to surgical education.}},
DOI = {{10.1089/ten.tea.2016.0528}},
ISSN = {{1937-3341}},
EISSN = {{1937-335X}},
Unique-ID = {{ISI:000402564400002}},
}

@article{ ISI:000401817300011,
Author = {Mourtzis, Dimitris and Vlachou, Aikaterini and Zogopoulos, Vasilios},
Title = {{Cloud-Based Augmented Reality Remote Maintenance Through Shop-Floor
   Monitoring: A Product-Service System Approach}},
Journal = {{JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE
   ASME}},
Year = {{2017}},
Volume = {{139}},
Number = {{6}},
Month = {{JUN}},
Abstract = {{Maintenance and its cost continue, over the years, drawing the attention
   of production management, since the unplanned failures decrease the
   reliability of the system and the return of investments. Maintenance
   services of manufactured products are among the most common services in
   the industry; they account for more than half of the total costs and
   influence the environmental impact of the product. In order for
   manufacturers to increase their productivity, by performing accurate and
   quick maintenance, advanced monitoring systems should be considered in
   order to easily detect machine tool failures before they occur. Toward
   that end, a cloud-based platform for condition-based preventive
   maintenance, supported by a shop-floor monitoring service and an
   augmented reality (AR) application, is proposed as a product-service
   system (CARM(2) -PSS). The proposed AR maintenance service consists of
   algorithms of automated generation of assembly sequences, part movement
   scripts, and improved interface that aim to maximize existing knowledge
   usage while creating vivid AR service instructions. Moreover, the
   proposed monitoring system is supported by a wireless sensor network
   (WSN), and is deployed on a Cloud environment together with the AR tool.
   The monitoring system monitors the status of the machine tools,
   calculates their remaining operating time between failures (ROTBF), and
   identifies the available windows of the machine tools in order to
   perform the AR remote maintenance. In order to validate the proposed
   methodology and calculate its impact, it is applied in a real-life case
   study of a white-goods industry.}},
DOI = {{10.1115/1.4035721}},
Article-Number = {{061011}},
ISSN = {{1087-1357}},
EISSN = {{1528-8935}},
Unique-ID = {{ISI:000401817300011}},
}

@article{ ISI:000398223000001,
Author = {Yang, Tingting and Xie, Dan and Li, Zhihong and Zhu, Hongwei},
Title = {{Recent advances in wearable tactile sensors: Materials, sensing
   mechanisms, and device performance}},
Journal = {{MATERIALS SCIENCE \& ENGINEERING R-REPORTS}},
Year = {{2017}},
Volume = {{115}},
Pages = {{1-37}},
Month = {{MAY}},
Abstract = {{Tactile sensors, most commonly referred as strain and pressure sensors,
   can collect mechanical property data of the human body and local
   environment, to provide valuable insights into the human health status
   or artificial intelligence systems. The introduction of a high level of
   wearability (bendability and stretchability) to tactile sensors can
   dramatically enhance their interfaces with the contact objects,
   providing chronically reliable functions. Therefore, the developed
   wearable tactile sensors are capable of conformably covering arbitrary
   curved surface over their stiff counterparts without incurring damage,
   emerging as a promising development direction toward the Internet of
   Things (IoT) applications. Fundamental parameters of the wearable
   tactile sensors such as sensitivity and stretchability have experienced
   unprecedented advancement, owing to the progress of device fabrication
   techniques and material structural engineering. Moreover, novel smart
   materials and mechanically durable sensor design concepts endow these
   sensors with multi-functionality integration (e.g., simultaneous force,
   temperature and humidity detection, simultaneous pressure and strain
   discrimination) and stirring properties (e.g., biocompatibility,
   biodegradability, self-healing, self-powering and visualization),
   further broadening the application scope of current wearable tactile
   sensors. Besides, it is desirable that a tactile sensor is compatible
   with a printing process that presents a new era of feasible wearable
   technology due to its large-area and high-throughput production
   capability. In addition to the development of sensors, packaging, and
   integration of the rest of the tactile device system (data memory,
   signal conversion, power supply, wireless transmission, feedback
   actuator, etc.) to build a wearable platform also emerge as major
   research frontiers in recent years. This review attempts to summarize
   the current state-of-the-art wearable tactile sensors concerning basic
   concepts, functional materials, sensing mechanism, promising
   applications, performance optimization strategies, multifunctional
   sensing, and system integration. Finally, the discussion will be
   presented regarding potential challenges, pathways, and opportunities.
   (C) 2017 Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.mser.2017.02.001}},
ISSN = {{0927-796X}},
EISSN = {{1879-212X}},
ResearcherID-Numbers = {{Zhu, Hongwei/B-5240-2009
   Zhu, Hongwei/C-4655-2008
   Yang, Tingting/M-1550-2017}},
ORCID-Numbers = {{Zhu, Hongwei/0000-0001-6484-3371
   Zhu, Hongwei/0000-0001-6484-3371
   Yang, Tingting/0000-0001-6773-8438}},
Unique-ID = {{ISI:000398223000001}},
}

@article{ ISI:000404720000008,
Author = {Rametta, Gaetano},
Title = {{Temporariness}},
Journal = {{FILOSOFIA POLITICA}},
Year = {{2017}},
Volume = {{31}},
Number = {{1}},
Pages = {{81-91}},
Month = {{APR}},
Abstract = {{The essay aims to show that globalization calls for a new relationship
   between political philosophy and objective reality. Through the use of
   concepts taken from French contemporary philosophy, from Guattari to
   Stiegler, the author criticizes the confusion between Deleuze's concept
   of << event >> as a virtual production of sense and the modern theory of
   << augmented reality >>. In the last section of his paper, he explains
   his idea of << Con-temporaneity >> as a shared experience of common
   temporariness, and also suggests some possible developments of political
   philosophy beyond the tradition of the << history of concepts >>.}},
DOI = {{10.1416/85956}},
ISSN = {{0394-7297}},
Unique-ID = {{ISI:000404720000008}},
}

@article{ ISI:000417308900001,
Author = {Cabero-Almenara, Julio and Llorente-Cejudo, Carmen and Jesus
   Gutierrez-Castillo, Juan},
Title = {{Evaluation by and from users: learning objects with Augmented Reality}},
Journal = {{RED-REVISTA DE EDUCACION A DISTANCIA}},
Year = {{2017}},
Number = {{53}},
Month = {{MAR 31}},
Abstract = {{With the objective of knowing the assessments that the students, who had
   used learning objects in augmented reality, made of them, an
   ``ex-post-facto{''} study was designed in which 429 students
   participated in the subjects of ``Educational Technology{''} and ``ICT
   applied to Education{''} attended the Primary and Childhood Education of
   the Faculty of Education Sciences of the University of Seville.
   In order to know the assessments of the subjects, an ``ad hoc{''}
   questionnaire was designed with a Likert type construction that sought
   to gather information on three dimensions: technical and aesthetic
   aspects of the object produced in RA, ease of use, and a guide developed
   to facilitate the understanding of the Performance of the object by
   students.
   The positive evaluations made by the students, among others, allow us to
   point out that these resources can be valid for their incorporation into
   the teaching-learning processes.}},
DOI = {{10.6018/red/53/4}},
Article-Number = {{4}},
ISSN = {{1578-7680}},
Unique-ID = {{ISI:000417308900001}},
}

@article{ ISI:000396101100003,
Author = {Doshi, Ashish and Smith, Ross T. and Thomas, Bruce H. and Bouras, Con},
Title = {{Use of projector based augmented reality to improve manual spot-welding
   precision and accuracy for automotive manufacturing}},
Journal = {{INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY}},
Year = {{2017}},
Volume = {{89}},
Number = {{5-8}},
Pages = {{1279-1293}},
Month = {{MAR}},
Abstract = {{This paper presents the use of a projector-based spatial augmented
   reality system in an industrial quality assurance setting to highlight
   spot-weld locations on vehicle panels for manual welding operators. The
   aim of this work is to improve the precision and accuracy of manual
   spot-weld placements with the aid of visual cues as a proactive step by
   the automotive manufacturer to enhance product quality. The prototype
   system was deployed at General Motors (GM) Holden plant in Elizabeth,
   Australia on the production line building Holden Cruze vehicles.
   Production trials were conducted and techniques developed to analyse and
   validate the precision and accuracy of spot-welds both with and without
   the visual cues. A reduction of 52 \% of the standard deviation of
   manual spot-weld placement was observed when using augmented reality
   visual cues. The average standard deviation with-AR assistance (19
   panels and 114 spot-welds) was calculated at 1.94 mm compared to
   without-AR (45 panels and 270 spot-welds) at 4.08 mm. All welds were
   within the required specification and panels evaluated in this study
   were used as the final product made available to consumers. The visual
   cues enabled operators to spot-weld at a higher degree of precision and
   accuracy.}},
DOI = {{10.1007/s00170-016-9164-5}},
ISSN = {{0268-3768}},
EISSN = {{1433-3015}},
ORCID-Numbers = {{Thomas, Bruce/0000-0002-9148-085X
   Smith, Ross/0000-0002-9044-9199}},
Unique-ID = {{ISI:000396101100003}},
}

@article{ ISI:000396989100005,
Author = {Salinas, Patricia and Pulido, Ricardo},
Title = {{Understanding the Conics through Augmented Reality}},
Journal = {{EURASIA JOURNAL OF MATHEMATICS SCIENCE AND TECHNOLOGY EDUCATION}},
Year = {{2017}},
Volume = {{13}},
Number = {{2, SI}},
Pages = {{341-354}},
Month = {{FEB}},
Abstract = {{This paper discusses the production of a digital environment to foster
   the learning of conics through augmented reality. The name conic refers
   to curves obtained by the intersection of a plane with a right circular
   conical surface. The environment gives students the opportunity to
   interact with the cone and the plane as virtual objects in real time and
   real place. They can perceive their own creation of the different
   curves: parabola, circle, ellipse and hyperbola. A dynamical animation
   to visualize the focus and directrix of the parabola is presented by
   introducing the Dandelin Spheres into the virtual environment. Besides
   the motivational element it offers, the purpose is to promote an active
   learning through the affordances of augmented reality technology.
   Anxiety towards mathematics could be tackled if students comprehend the
   mathematical knowledge. The integration of digital technology in the
   learning process helps this strengthening the development of spatial
   ability in students.}},
DOI = {{10.12973/eurasia.2017.00620a}},
ISSN = {{1305-8215}},
EISSN = {{1305-8223}},
Unique-ID = {{ISI:000396989100005}},
}

@inproceedings{ ISI:000443416600044,
Author = {Postranecky, Michal and Svitek, Miroslav},
Editor = {{Ruzicka, J}},
Title = {{Smart City Near to 4.0-an Adoption of Industry 4.0 Conceptual Model}},
Booktitle = {{2017 SMART CITY SYMPOSIUM PRAGUE (SCSP)}},
Year = {{2017}},
Note = {{Smart City Symposium Prague (SCSP), Prague, CZECH REPUBLIC, MAY 25-26,
   2017}},
Organization = {{CTU Prague, Fac Transportat Sci}},
Abstract = {{The paper is introducing an adoption of Industry 4.0 Concept on Smart
   City theoretic model. Cities are upgraded with latest computing and ICT
   technologies throughout all systems and infrastructure. New data are
   collected in big amounts and ability to use them is changing how city
   subsystems can communicate together, to make cities work better and
   serve better to their users.
   Smart Cities are convoluted Cyber Physical Model Systems with gradually
   growing network of all of its parts including human social networks.
   Cities are under continuous development, in relation to attractiveness
   of city structure, based on all activities and transactions conducted in
   city area and related surrounding, newly also through connected virtual
   world. Industry 4.0 Concept is one of segments of city's recent or near
   future upgrade. Integration of advanced computing technology and
   Information Computing Technology throughout whole production enterprise
   enable to share data, information, and instructions between all agents
   during all phases of product lifecycle, a product partially
   participating as a vehicle of product development instructions. Industry
   4.0 concept includes six principles, which are compared to Smart City
   near to 4.0 model. Triangle Rule Diagram is introduced to investigate
   relationships between all main domains in city live - Client, Enterprise
   and Facilitator at concept of Smart City near to 4.0, where integration
   of computing technologies is embedded in all of these domains and inside
   all city systems and processes connecting them together. Services become
   a predominantly main city's product as outcome of City Enterprise.
   Ability to carry portion of instruction about product development is
   part of new Smart city near 4.0 concept, as well as during post-product
   development phases.}},
ISBN = {{978-1-5386-3825-5}},
Unique-ID = {{ISI:000443416600044}},
}

@inproceedings{ ISI:000443416600043,
Author = {Postranecky, Michal and Svitek, Miroslav},
Editor = {{Ruzicka, J}},
Title = {{Assessment Method to Measure Smartness of Cities}},
Booktitle = {{2017 SMART CITY SYMPOSIUM PRAGUE (SCSP)}},
Year = {{2017}},
Note = {{Smart City Symposium Prague (SCSP), Prague, CZECH REPUBLIC, MAY 25-26,
   2017}},
Organization = {{CTU Prague, Fac Transportat Sci}},
Abstract = {{The paper is introducing an adoption of Industry 4.0 Concept on Smart
   City theoretic model. Cities are upgraded with latest computing and ICT
   technologies throughout all systems and infrastructure. New data are
   collected in big amounts and ability to use them is changing how city
   subsystems can communicate together, to make cities work better and
   serve better to their users.
   Smart Cities are convoluted Cyber Physical Model Systems with gradually
   growing network of all of its parts including human social networks.
   Cities are under continuous development, in relation to attractiveness
   of city structure, based on all activities and transactions conducted in
   city area and related surrounding, newly also through connected virtual
   world. Industry 4.0 Concept is one of segments of city's recent or near
   future upgrade. Integration of advanced computing technology and
   Information Computing Technology (ICT) throughout whole production
   enterprise enable to share data, information, and instructions between
   all agents during all phases of product life-cycle, a product partially
   participating as a vehicle of product development instructions. Industry
   4.0 concept includes six principles, which are compared to Smart City
   near to 4.0 model. Triangle Rule Diagram is introduced to investigate
   relationships between all main domains in city live - Client, Enterprise
   and Facilitator at concept of Smart City near to 4.0, where integration
   of computing technologies is embedded in all of these domains and inside
   all city systems and processes connecting them together. Services become
   a predominantly main city's product as outcome of City Enterprise.
   Ability to carry portion of instruction about Product development is
   part of new Smart city near 4.0 concept, as well as during post-product
   development phases.}},
ISBN = {{978-1-5386-3825-5}},
Unique-ID = {{ISI:000443416600043}},
}

@inproceedings{ ISI:000443108700025,
Author = {Zamora, Mauricio and Caldwell, Eldon and Garcia-Rodriguez, Jose and
   Azorin-Lopez, Jorge and Cazorla, Miguel},
Editor = {{Rojas, I and Joya, G and Catala, A}},
Title = {{Machine Learning Improves Human-Robot Interaction in Productive
   Environments: A Review}},
Booktitle = {{ADVANCES IN COMPUTATIONAL INTELLIGENCE, IWANN 2017, PT II}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2017}},
Volume = {{10306}},
Number = {{II}},
Pages = {{283-293}},
Note = {{14th International Work-Conference on Artificial Neural Networks
   (IWANN), Cadiz, SPAIN, JUN 14-16, 2017}},
Organization = {{Univ Granada; Univ Malaga; Polytechn Univ Catalonia}},
Abstract = {{In the new generation of industries, including all the advances
   introduced by Industry 4.0, human robot interaction (HRI), by means of
   automatic learning and computer vision, become an important element to
   accomplish. HRI allows to create collaborative environments between
   people and robots, avoiding the latter generating a risk of occupational
   safety. In addition to the automatic systems, the interaction by mean of
   automated learning processes provides necessary information to increase
   productivity and minimize delivery response times by helping to optimize
   complex production planning processes. In this paper, it is presented a
   review of the technologies necessary to be considered as basic elements
   in all processes of industry 4.0 as a crucial linking element between
   humans, robots, intelligent and traditional machines.}},
DOI = {{10.1007/978-3-319-59147-6\_25}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-59147-6; 978-3-319-59146-9}},
ORCID-Numbers = {{Cazorla, Miguel/0000-0001-6805-3633}},
Unique-ID = {{ISI:000443108700025}},
}

@inproceedings{ ISI:000440850000015,
Author = {Lithoxoidou, Evdoxia Eirini and Doumpoulakis, Stefanos and Tsakiris,
   Athanasios and Krinidis, Stelios and Ioannidis, Dimosthenis and Votis,
   Konstantinos and Tzovaras, Dimitrios},
Editor = {{Kompatsiaris, I and Cave, J and Satsiou, A and Carle, G and Passani, A and Kontopoulos, E and Diplaris, S and McMillan, D}},
Title = {{Improvement of the Workers' Satisfaction and Collaborative Spirit
   Through Gamification}},
Booktitle = {{INTERNET SCIENCE}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2017}},
Volume = {{10673}},
Pages = {{184-191}},
Note = {{4th International Conference on Internet Science (INSCI), Thessaloniki,
   GREECE, NOV 22-24, 2017}},
Abstract = {{Supporting the use of technology into industrial environments is an
   issue of mass appeal within the Industry 4.0 initiative, with a lot of
   promising research especially into interaction, production and training
   sections. In this paper, a Social Collaboration platform is introduced
   which creates an online community for workers as well as an Augmented
   Reality (AR) tool for production and training purposes both of which
   constitute gamified applications on which a customizable Gamification
   platform is applied according to impending needs. These tools have been
   implemented in order to become of daily use to employees in factories
   and incentivize them to promote collaboration, engagement, participation
   and work satisfaction. Every promoted industrial behavior can be
   described and awarded based on the offered rule engine. Thus, two
   gamified processes are offered regarding Social Collaboration and AR
   training to employees of industrial environments, so that an inference
   is drawn concerning participation, satisfaction and self-fulfillment.
   The use of the platforms is illustrated in this paper by two examples
   consisting one use case for a section in social collaboration and a
   second use case of training through AR.}},
DOI = {{10.1007/978-3-319-70284-1\_15}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-70284-1; 978-3-319-70283-4}},
Unique-ID = {{ISI:000440850000015}},
}

@inproceedings{ ISI:000440843200024,
Author = {Zimmer, Christian and Drochtert, Daniel and Geiger, Christian and Brink,
   Michael and Muetze, Rolf},
Book-Group-Author = {{Assoc Comp Machinery}},
Title = {{Mobile Previsualization using Augmented Reality - A Use Case from Film
   Production}},
Booktitle = {{SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS \& INTERACTIVE APPLICATIONS}},
Year = {{2017}},
Note = {{ACM-SIGGRAPH Asia Computer Animation Festival Conference / SIGGRAPH Asia
   Courses Conference / SIGGRAPH Asia Emerging Technologies Conference /
   Symposium on Mobile Graphics and Interactive Applications, Los Angeles,
   CA, JUL 30-AUG 08, 2017}},
Organization = {{ACM SIGGRPAH Asia; SIGGRAPH Asia}},
Abstract = {{We present a mobile augmented reality application for the planning and
   pre-visualisation of film productions. The tool was developed in an
   iterative design process in the collaboration between a VFX studio and a
   mixed reality research lab. This paper explains the specification of the
   requirements, the interaction design of pre-visualization techniques,
   and details about the implementation on a mobile device.}},
DOI = {{10.1145/3132787.3132805}},
ISBN = {{978-1-4503-5410-3}},
Unique-ID = {{ISI:000440843200024}},
}

@inproceedings{ ISI:000440461200028,
Author = {Sanna, Andrea and Lamberti, Fabrizio and De Pace, Francesco and
   Iacoviello, Roberto and Sunna, Paola},
Editor = {{DePaolis, LT and Bourdot, P and Mongelli, A}},
Title = {{ARSSET: Augmented Reality Support on SET}},
Booktitle = {{AUGMENTED REALITY, VIRTUAL REALITY, AND COMPUTER GRAPHICS, AVR 2017, PT
   I}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2017}},
Volume = {{10324}},
Pages = {{356-376}},
Note = {{4th International Conference on Augmented Reality, Virtual Reality, and
   Computer Graphics (SALENTO AVR), Ugento, ITALY, JUN 12-15, 2017}},
Abstract = {{The preparation of a set for a television production is a complex work;
   usually, several objects have to be manually placed in the environment
   and the configuration might be changed many times before finding the
   final set up. This configuration phase can be expensive and time
   consuming when large and heavy objects have to be moved. In order to
   tackle this issue, virtual sets allow the director of production to
   create virtual scenes before placing real objects. This paper proposes
   an alternative approach based on augmented reality technologies: objects
   of the scene are computer generated assets, which can be placed and
   manipulated in a real environment. With respect virtual sets, the
   proposed solution allows the director to move in a real scene enriched
   by computer-generated objects to be placed in the environment. The user
   wears an AR headset and manipulates objects by a tablet. The proposed
   system was evaluated by a group of 9 testers, which had to create an
   augmented TV set. Subjective and objective parameters have been used to
   assess the system usability.}},
DOI = {{10.1007/978-3-319-60922-5\_28}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-60922-5; 978-3-319-60921-8}},
ORCID-Numbers = {{SANNA, Andrea/0000-0001-7916-1699}},
Unique-ID = {{ISI:000440461200028}},
}

@inproceedings{ ISI:000440461200030,
Author = {Pierdicca, Roberto and Frontoni, Emanuele and Pollini, Rama and Trani,
   Matteo and Verdini, Lorenzo},
Editor = {{DePaolis, LT and Bourdot, P and Mongelli, A}},
Title = {{The Use of Augmented Reality Glasses for the Application in Industry 4.0}},
Booktitle = {{AUGMENTED REALITY, VIRTUAL REALITY, AND COMPUTER GRAPHICS, AVR 2017, PT
   I}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2017}},
Volume = {{10324}},
Pages = {{389-401}},
Note = {{4th International Conference on Augmented Reality, Virtual Reality, and
   Computer Graphics (SALENTO AVR), Ugento, ITALY, JUN 12-15, 2017}},
Abstract = {{In nowadays Industrial environment, the fast changes of machine
   components and the growing need of specialised worker claims an
   evolution. In the towards of this direction, the Industry 4.0 paradigm
   seems to play a pivotal role, because is aimed at making industrial
   production entirely automated and interconnected. Augmented Reality (AR)
   is one of the nine pillar of the new Industry environments and is still
   considered and is a real solution for several purposes, first of all
   production environments. In this article we propose a case study of a
   training-on-the-job application through the use of glasses for AR, using
   Unity framework and Vuforia libraries. The goal is to develop an AR
   android application that allows to assist the operator during the
   assembly phase of an object composed of numerous components that must be
   assembled in a precise order and together with a final verification
   measurements on some parts of the final object. This work poses
   considerable attention to the usability of the HDM device and the
   readability of the information. The application has been validated after
   a number of practical tests carried out by specialized technicians who
   normally perform this type of assembly. The description of the applied
   procedure and the assessment are presented.}},
DOI = {{10.1007/978-3-319-60922-5\_30}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-60922-5; 978-3-319-60921-8}},
ORCID-Numbers = {{Frontoni, Emanuele/0000-0002-8893-9244
   Pierdicca, Roberto/0000-0002-9160-834X}},
Unique-ID = {{ISI:000440461200030}},
}

@inproceedings{ ISI:000435259700014,
Author = {Wiesner, Christian A. and Ruf, Mike and Sirim, Demet and Klinker, Gudrun},
Editor = {{Broll, W and Regenbrecht, H and Swan, JE}},
Title = {{3D-FRC: Depiction of the future road course in the Head-Up-Display}},
Booktitle = {{PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND
   AUGMENTED REALITY (ISMAR)}},
Year = {{2017}},
Pages = {{136-143}},
Note = {{16th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR), Nantes, FRANCE, OCT 09-13, 2017}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{The introduction of Head-Up-Displays (HUDs) have opened up avenues for a
   whole range of novel AR applications. However, until these applications
   become available for the mass market a number of problems need to be
   tackled. For example, the field of view (FoV) of current HUDs is
   extremely limited, and real world tracking and 3D reconstruction are
   still not precise enough to show driving information embedded into wide
   areas of complex traffic environment. It is not possible to show true
   AR-visualisations in the display areas provided by the current FoVs. In
   this paper, we investigate how an AR-like visualisation approach in
   current HUDs (with a limited FoV) can support drivers in foreseeing the
   future road course. This visualisation uses the already established
   concept of an electronic horizon. By complying with automotive
   standards, our application can be easily adapted for series production.
   With this visualisation we performed a user study, investigating the
   effect on drivers' gaze behaviour. For this reason the test subjects
   were equipped with an eye tracking system. The results showed a decrease
   in both, the number of gazes as well as total glance time on the head
   unit and the instrument cluster. We also investigated the test subjects'
   braking behaviour around sharp bends of the road which showed an overall
   improvement when the visualisation was enabled. Furthermore it showed an
   increase of the mean glance duration in the area of the HUD. Note that
   the eye tracking system is not capable of distinguishing between glances
   at the visualisation in the HUD and the users' glance at objects behind
   the visualisation -overlapping with the HUD. This would require tracking
   the test persons' depth of focus. The study showed that developers need
   to be concerned about not displaying excessively in the HUD, so as not
   to distract drivers. It furthermore showed that AR-like visualisations
   have the potential to decrease the time the driver is not looking at the
   road creating a safer driving experience.}},
DOI = {{10.1109/ISMAR.2017.30}},
ISBN = {{978-1-5386-2943-7}},
Unique-ID = {{ISI:000435259700014}},
}

@inproceedings{ ISI:000428267800061,
Author = {Schlagowski, R. and Merkel, L. and Meitinger, C.},
Book-Group-Author = {{IEEE}},
Title = {{Design of an Assistant System for Industrial Maintenance Tasks and
   Implementation of a Prototype Using Augmented Reality}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND
   ENGINEERING MANAGEMENT (IEEM)}},
Series = {{International Conference on Industrial Engineering and Engineering
   Management IEEM}},
Year = {{2017}},
Pages = {{294-298}},
Note = {{IEEE International Conference on Industrial Engineering and Engineering
   Management (IEEE IEEM), Singapore, SINGAPORE, DEC 10-13, 2017}},
Organization = {{IEEE; IEEE Singapore Sect; IEEE TEMS Singapore Chapter; IEEE TEMS Hong
   Kong Chapter}},
Abstract = {{As the complexity of work tasks rises for maintenance workers in modern
   production facilities, new technologies will be required to support and
   integrate the service worker of tomorrow. This paper gives an insight
   into an ongoing research project examining the potential of smart
   glasses used as a component of assistant systems for workers performing
   maintenance tasks in an industry 4.0 context. A human centered design
   process is used to identify the needs of workers and to specify
   requirements for the assistant system being developed. Thereby, the
   maintenance of a CNC lathe is used as an example and assistant functions
   were developed for one specific maintenance task. The architecture of
   the assistant system proposed in this paper is based on an analysis of
   the work system including the tasks of the maintenance worker. Finally,
   the implementation of a first prototype, using state-of-the-art
   augmented reality smart glasses, is described.}},
ISSN = {{2157-3611}},
ISBN = {{978-1-5386-0948-4}},
Unique-ID = {{ISI:000428267800061}},
}

@inproceedings{ ISI:000427222200142,
Author = {Lanka, Surekha and Ehsan, Sidra and Ehsan, Aisha},
Book-Group-Author = {{IEEE}},
Title = {{A Review of research on Emerging technologies of the Internet of Things
   and Augmented Reality}},
Booktitle = {{2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE,
   ANALYTICS AND CLOUD) (I-SMAC)}},
Year = {{2017}},
Pages = {{770-774}},
Note = {{International Conference on I-SMAC (IoT in Social, Mobile, Analytics and
   Cloud) (I-SMAC), Palladam, INDIA, FEB 10-11, 2017}},
Organization = {{IEEE; Electron Devices Soc; SCAD Inst Technol}},
Abstract = {{The Internet of Things (IoT) is the way of changing the style we
   communicate with the world. Which can make an abstract idea where the
   object in our environment, through some introduced properties, develops
   into smarter and begin independently communicating with each other and
   persons, through networks maintained by interfaces. On the other phase
   Augmented reality (AR) blurs the line between our real world and the
   internet. Still smart watches, smart phones, home security systems are
   well developed simply called Embracing technology. Businesses are just
   looking into the value and are beginning to equipment production of
   embedded sensors. Enormous data will be produced by these devices.
   Currently, IoT and AR technologies already exist and available services
   can be found. If IoT and AR combines, a revolution will create beyond
   smart phone automate business processes in ways never possible before.
   This paper describes the architecture, technology networks, applications
   of IoT and Augmented reality systems. However, there is so much
   additional to come in IoT and AR technologies, which is why it is so
   important to grasp what can be provided through these technologies and
   how these technologies work.}},
ISBN = {{978-1-5090-3243-3}},
ORCID-Numbers = {{lanka, surekha/0000-0003-2829-0049}},
Unique-ID = {{ISI:000427222200142}},
}

@inproceedings{ ISI:000427262400115,
Author = {Zaldivar-Colado, Ulises and Garbaya, Samir and Tamayo-Serrano, Paul and
   Zaldivar-Colado, Xiomara and Blazevic, Pierre},
Editor = {{Howard, A and Suzuki, K and Zollo, L}},
Title = {{A Mixed Reality for Virtual Assembly}},
Booktitle = {{2017 26TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE
   COMMUNICATION (RO-MAN)}},
Series = {{IEEE RO-MAN}},
Year = {{2017}},
Pages = {{739-744}},
Note = {{26th IEEE International Symposium on Robot and Human Interactive
   Communication (RO-MAN), Lisbon, PORTUGAL, AUG 28-SEP 01, 2017}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Robot \& Automat Soc; Robot Soc
   Japan; Korean Robot Soc; Univ Coimbra, Inst Syst \& Robot}},
Abstract = {{Mixed reality (MR) is a hybrid reality where real and virtual objects
   are merged to produce an enriched interactive environment. Virtual
   Reality (VR) has been used in the simulation of production processes
   such as the product assembly and the execution of industrial tasks.
   Augmented reality (AR) has been widely used as an instructional tool to
   help the user to perform the task in real world conditions. Most of
   these works were focused on solving technical problems, specific to the
   type of application but they did not take advantage of the achievements
   realized in both VR and AR technologies. This paper presents a mixed
   reality system that integrates virtual assembly environment with
   augmented reality. This approach is mainly based on the development of a
   hybrid tacking system for the synchronization of the virtual and the
   real hand of the user. The evaluation of this Mixed Reality approach
   showed a statistically significant improvement of the user performance
   in the assembly task execution, compared to the task realized in virtual
   environment.}},
ISSN = {{1944-9445}},
ISBN = {{978-1-5386-3518-6}},
Unique-ID = {{ISI:000427262400115}},
}

@inproceedings{ ISI:000426884800073,
Author = {Rasmussen, Troels A. and Merritt, Timothy R.},
Editor = {{Janssen, P and Loh, P and Raonic, A and Schnabel, MA}},
Title = {{PROJECTABLES Augmented CNC Tools for Sustainable Creative Practices}},
Booktitle = {{PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON COMPUTER-AIDED
   ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2017): PROTOCOLS, FLOWS
   AND GLITCHES}},
Year = {{2017}},
Pages = {{757-766}},
Note = {{22nd CAADRIA Annual International Conference on Computer-Aided
   Architectural Design Research in Asia (CAADRIA), Xian Jiaotong Liverpool
   Univ, Dept Architecture, Suzhou, PEOPLES R CHINA, APR 05-08, 2017}},
Organization = {{Assoc Comp Aided Architectural Design Res Asia}},
Abstract = {{CNC cutting machines have become essential tools for designers and
   architects enabling rapid prototyping, model-building and production of
   high quality components. Designers often cut from new materials,
   discarding the irregularly shaped remains. We introduce ProjecTables, a
   visual augmented reality system for interactive packing of model parts
   onto sheet materials. ProjecTables enables designers to (re) use scrap
   materials for CNC cutting that would have been previously thrown away,
   at the same time supporting aesthetic choices related to wood grain,
   avoiding surface blemishes, and other relevant material properties. We
   conducted evaluations of ProjecTables with design students from Aarhus
   School of Architecture, demonstrating that participants could quickly
   and easily place and orient model parts reducing material waste.
   Contextual interviews and ideation sessions led to a deeper
   understanding of current work practices and sustainability issues with
   CNC cutting-machines, and identified useful features for interactive
   packing to reduce waste while supporting aesthetic concerns for
   exhibition quality design projects.}},
ISBN = {{978-988-19026-8-9}},
Unique-ID = {{ISI:000426884800073}},
}

@inproceedings{ ISI:000426448300157,
Author = {Dvorak, Pavel and Josth, Radovan and Delponte, Elisabetta},
Book-Group-Author = {{IEEE}},
Title = {{Object state recognition for automatic AR-based maintenance guidance}},
Booktitle = {{2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS (CVPRW)}},
Series = {{IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops}},
Year = {{2017}},
Pages = {{1244-1250}},
Note = {{30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Workshops (CVPRW), Honolulu, HI, JUL 21-26, 2017}},
Organization = {{IEEE; IEEE Comp Soc; CVF}},
Abstract = {{This paper describes a component of an Augmented Reality (AR) based
   system focused on supporting workers in manufacturing and maintenance
   industry. Particularly, it describes a component responsible for
   verification of performed steps. Correct handling is crucial in both
   manufacturing and maintenance industries and deviations may cause
   problems in later stages of the production and assembly. The primary aim
   of such support systems is making the training of new employees faster
   and more efficient and reducing the error rate. We present a method for
   automatically recognizing an object's state with the objective of
   verifying a set of tasks performed by a user. The novelty of our
   approach is that the system can automatically recognize the state of the
   object and provide immediate feedback to the operator using an AR
   visualization enabling fully automatic step-by-step instructions.}},
DOI = {{10.1109/CVPRW.2017.164}},
ISSN = {{2160-7508}},
ISBN = {{978-1-5386-0733-6}},
Unique-ID = {{ISI:000426448300157}},
}

@inproceedings{ ISI:000426448300214,
Author = {Sabater, N. and Boisson, G. and Vandame, B. and Kerbiriou, P. and Babon,
   F. and Hog, M. and Gendrot, R. and Langlois, T. and Bureller, O. and
   Schubert, A. and Allie, V.},
Book-Group-Author = {{IEEE}},
Title = {{Dataset and Pipeline for Multi-View Light-Field Video}},
Booktitle = {{2017 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   WORKSHOPS (CVPRW)}},
Series = {{IEEE Computer Society Conference on Computer Vision and Pattern
   Recognition Workshops}},
Year = {{2017}},
Pages = {{1743-1753}},
Note = {{30th IEEE/CVF Conference on Computer Vision and Pattern Recognition
   Workshops (CVPRW), Honolulu, HI, JUL 21-26, 2017}},
Organization = {{IEEE; IEEE Comp Soc; CVF}},
Abstract = {{The quantity and diversity of data in Light-Field videos makes this
   content valuable for many applications such as mixed and augmented
   reality or post-production in the movie industry. Some of such
   applications require a large parallax between the different views of the
   Light-Field, making the multi-view capture a better option than
   plenoptic cameras. In this paper we propose a dataset and a complete
   pipeline for Light-Field video. The proposed algorithms are specially
   tailored to process sparse and wide-baseline multi-view videos captured
   with a camera rig. Our pipeline includes algorithms such as geometric
   calibration, color homogenization, view pseudo-rectification and depth
   estimation. Such elemental algorithms are well known by the
   state-of-the-art but they must achieve high accuracy to guarantee the
   success of other algorithms using our data. Along this paper, we publish
   our Light-Field video dataset that we believe may be of special interest
   for the community {[}1]. We provide the original sequences, the
   calibration parameters and the pseudo-rectified views. Finally, we
   propose a depth-based rendering algorithm for Dynamic Perspective
   Rendering.}},
DOI = {{10.1109/CVPRW.2017.221}},
ISSN = {{2160-7508}},
ISBN = {{978-1-5386-0733-6}},
Unique-ID = {{ISI:000426448300214}},
}

@inproceedings{ ISI:000425896400040,
Author = {Perea, Patrick and Morand, Denis and Nigay, Laurence},
Editor = {{Broll, W and Regenbrecht, H and Swan, JE and Bruder, G and Servieres, M and Sugimoto, M}},
Title = {{Halo3D: a Technique for Visualizing Off-Screen Points of Interest in
   Mobile Augmented Reality}},
Booktitle = {{ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)}},
Year = {{2017}},
Pages = {{170-175}},
Note = {{16th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR), Nantes, FRANCE, OCT 09-13, 2017}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{When working with mobile Augmented Reality (AR) applications, users need
   to he aware of relevant points of interest (POIs) that are located
   oft-screen. These POIs belong to the context since they are not
   observable in the 3D first-person AR view on screen. The context in
   mobile AR can include a large number of POIs including locally dense
   clusters as in mobile AR applications for production plant machine
   maintenance. Existing solutions display 3D arrows or an area on the
   edges of the screen to represent the POIs of the context. These
   techniques display the direction but not the distance of each POI. We
   present IIalo3D, a visualization technique that conveys the 3D direction
   and distance of off-screen POIs while avoiding overlap and clutter in a
   high POI -density AR environment.}},
DOI = {{10.1109/ISMAR-Adjunct.2017.58}},
ISBN = {{978-0-7695-6327-5}},
Unique-ID = {{ISI:000425896400040}},
}

@inproceedings{ ISI:000425896400052,
Author = {Okamoto, Takurou and Uranishi, Yuki and Mashita, Tomohiro and Ratsamee,
   Photchara and Kiyokawa, Kiyoshi and Takemura, Haruo},
Editor = {{Broll, W and Regenbrecht, H and Swan, JE and Bruder, G and Servieres, M and Sugimoto, M}},
Title = {{Realtime Generation of Caustic Images Using a Deep Neural Network}},
Booktitle = {{ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)}},
Year = {{2017}},
Pages = {{214-215}},
Note = {{16th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR), Nantes, FRANCE, OCT 09-13, 2017}},
Organization = {{IEEE; IEEE Comp Soc}},
Abstract = {{We propose a method for generating caustic images in real time using a
   deep/ convolutional neural network (CNN). To do so, training images are
   first rendered using photon mapping, and the CNN learns the
   correspondences between the depth images and caustic images. After
   learning, the CNN generates a caustic image from a depth image within 55
   milliseconds. In addition, the similarity between the generated caustic
   images and the ground truth shows that our method is very promising for
   the generation of caustic images for a number of known objects, though
   the method does not handle objects in which ground truth is not already
   known. This method can play an important role in scenes used for stage
   video production and interactive art in the future.}},
DOI = {{10.1109/ISMAR-Adjunct.2017.70}},
ISBN = {{978-0-7695-6327-5}},
Unique-ID = {{ISI:000425896400052}},
}

@inproceedings{ ISI:000419072100151,
Author = {de Giorgio, Andrea and Romero, Mario and Onori, Mauro and Wang, Lihui},
Editor = {{Pellicciari, M and Peruzzini, M}},
Title = {{Human-machine collaboration in virtual reality for adaptive production
   engineering}},
Booktitle = {{27TH INTERNATIONAL CONFERENCE ON FLEXIBLE AUTOMATION AND INTELLIGENT
   MANUFACTURING, FAIM2017}},
Series = {{Procedia Manufacturing}},
Year = {{2017}},
Volume = {{11}},
Pages = {{1279-1287}},
Note = {{27th International Conference on Flexible Automation and Intelligent
   Manufacturing (FAIM), Modena, ITALY, JUN 27-30, 2017}},
Abstract = {{This paper outlines the main steps towards an open and adaptive
   simulation method for human-robot collaboration (HRC) in production
   engineering supported by virtual reality (VR). The work is based on the
   latest software developments in the gaming industry, in addition to the
   already commercially available hardware that is robust and reliable.
   This allows to overcome VR limitations of the industrial software
   provided by manufacturing machine producers and it is based on an
   open-source community programming approach and also leads to significant
   advantages such as interfacing with the latest developed hardware for
   realistic user experience in immersive VR, as well as the possibility to
   share adaptive algorithms. A practical implementation in Unity is
   provided as a functional prototype for feasibility tests. However, at
   the time of this paper, no controlled human-subject studies on the
   implementation have been noted, in fact, this is solely provided to show
   preliminary proof of concept. Future work will formally address the
   questions that are raised in this first run. (c) 2017 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.promfg.2017.07.255}},
ISSN = {{2351-9789}},
ResearcherID-Numbers = {{Wang, Lihui/O-3907-2014
   }},
ORCID-Numbers = {{Wang, Lihui/0000-0001-8679-8049
   de Giorgio, Andrea/0000-0001-6064-5634
   Romero, Mario/0000-0003-4616-189X}},
Unique-ID = {{ISI:000419072100151}},
}

@inproceedings{ ISI:000423243500065,
Author = {Aschenbrenner, Doris and Maltry, Nicolas and Schilling, Klaus and
   Verlinden, Jouke},
Book-Group-Author = {{ASME}},
Title = {{AN EXPLORATION STUDY FOR AUGMENTED AND VIRTUAL REALITY ENHANCING
   SITUATION AWARENESS FOR PLANT TELEANALYSIS}},
Booktitle = {{PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL
   CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE,
   2017, VOL 1}},
Series = {{Proceedings of the ASME Design Engineering Technical Conferences}},
Year = {{2017}},
Note = {{ASME International Design Engineering Technical Conferences / Computers
   and Information in Engineering Conference (IDETC/CIE 2017), Cleveland,
   OH, AUG 06-09, 2017}},
Organization = {{ASME, Design Engn Div; ASME, Comp \& Informat Engn Div}},
Abstract = {{This work wants to investigate which visualization method is able to
   support remote teleanalysis of industrial plants best regarding
   comprehension, usability and situation awareness. The application goal
   is the remote optimization of an industrial plant and the examined
   scenario was generated out of a large data set of a real production
   entity. The plant consists of an industrial manipulator, a.molding
   machine and a montage system. Prior studies on the same plant with video
   based visualization explored by remote experts showed a large potential
   for optimization, but indicated a higher demand for situation awareness.
   In order to test the influence of the visualization method, a user study
   has been carried out with 60 student participants with six different
   visualization methods, including various VR and AR implementations.
   Overall, our used AR environment performed significantly better than the
   used VR and video implementations, but the VR implementation surpasses
   AR regarding situation awareness.}},
Article-Number = {{V001T02A065}},
ISSN = {{2159-7383}},
ISBN = {{978-0-7918-5811-0}},
Unique-ID = {{ISI:000423243500065}},
}

@inproceedings{ ISI:000423244700038,
Author = {Matteucci, Marco and Raponi, Damiano and Mengoni, Maura and Peruzzini,
   Margherita},
Book-Group-Author = {{ASME}},
Title = {{TANGIBLE AUGMENTED REALITY MODEL TO SUPPORT MANUAL ASSEMBLY}},
Booktitle = {{PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL
   CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE,
   2017, VOL 9}},
Series = {{Proceedings of the ASME Design Engineering Technical Conferences}},
Year = {{2017}},
Note = {{ASME International Design Engineering Technical Conferences / Computers
   and Information in Engineering Conference (IDETC/CIE 2017), Cleveland,
   OH, AUG 06-09, 2017}},
Organization = {{ASME, Design Engn Div; ASME, Comp \& Informat Engn Div}},
Abstract = {{Manual work is a cornerstone of manufacturing, also for factories of
   Industry 4.0 era. Use cases of manual work regard the production of
   single item, customized assemblies, small batches. Several injuries can
   be caused or aggravated by manual handling activities at work. Moreover,
   the efficiency of the whole process can benefit from correct body
   posture, parts' visibility and accessibility. Finally, manual work is
   strongly human-centered and its performance is affected by the
   expertise, the level of knowledge, attitudes and belief of workers. In
   this. complex context where multiple factors such as Efficiency, Work
   Performance, Ergonomics and Safety relate each other to achieve a
   satisfactory smart industry, the paper proposes an innovative Tangible
   Augmented Reality platform to train and assist workers during the manual
   handling and assembly tasks necessary to produce consumer goods with
   high aesthetic qualities. The proposed platform is the result of the
   application of a multipath methodology to link health and safety
   elements, typologies of injuries, ergonomics factors and relative
   qualitative and quantitative assessment methods and ergonomics analysis
   tools. The TAR platform allows the worker to consult the assembly
   instructions in a simple and user friendly way and to be informed by
   potential risk of injuries by a real-time alert. Based on video mapping
   techniques, the TAR system superimposes the necessary digital contents
   on the physical model of the product while the operator is building it.}},
Article-Number = {{UNSP V009T07A038}},
ISSN = {{2159-7383}},
ISBN = {{978-0-7918-5823-3}},
Unique-ID = {{ISI:000423244700038}},
}

@inproceedings{ ISI:000413668602026,
Author = {Pecina, Pavel and Sladek, Petr},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{FOURTH INDUSTRIAL REVOLUTION AND TECHNICAL EDUCATION}},
Booktitle = {{INTED2017: 11TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT
   CONFERENCE}},
Series = {{INTED Proceedings}},
Year = {{2017}},
Pages = {{2089-2093}},
Note = {{11th International Conference on Technology, Education and Development
   (INTED), Valencia, SPAIN, MAR 06-08, 2017}},
Abstract = {{The insufficiency in the number of skilled technicians becomes the main
   problem of many (not only industrial) companies in the Czech Republic
   and other EU countries. The seriousness of the situation is proved by
   the tendency to invest funds in the material equipment of schools,
   technical education and solutions that link theory with practice. It is
   necessary to realize that the future professionals are being prepared
   for the positions in fast-changing area of industry. The change is
   enhanced by the rapid evolution of technologies, i.e. the so-called
   Fourth Industrial Revolution (Industry 4.0). This concept was officially
   introduced at the 2013 Hannover Fair. The Fourth Industrial Revolution
   is a term describing cyber - physical systems, which bring radical
   changes in the production process.
   The overall development in the EU countries in recent years has shown
   that the working competences in many professions vary in comparison with
   the past. Current trends in the development of technologies tend to
   downsize or revise certain working specializations. Certain new
   specializations have been created in some areas with growing demand for
   skilled professionals, mainly in connection with IT systems. An example
   might be the development in car-repairs, where the competencies in
   electronics are becoming essential, especially with respect to the
   electro-mobility.
   This development leads to the corresponding changes in the system of
   technical vocational education at the national and international level.
   This article describes the main areas of impact of the innovation
   process on technical vocational education. The main sub-themes addressed
   are the following:
   Analysis of the competencies and skills of workers and technicians in
   smart factories.
   Induced changes in curriculum, introducing of new courses in vocational
   training.
   Induced changes in training of teachers of vocational subjects.
   Impact of robotics, automation and 3D technologies on technical
   training.
   Internet, virtual and augmented reality.
   The paper brings some results of the research that was focused on the
   readiness of the Czech vocational subject teachers for the upcoming the
   Fourth Industrial Revolution.}},
ISSN = {{2340-1079}},
ISBN = {{978-84-617-8491-2}},
ResearcherID-Numbers = {{Sladek, Petr/M-5496-2013}},
Unique-ID = {{ISI:000413668602026}},
}

@article{ ISI:000412761900004,
Author = {Tezel, Algan and Aziz, Zeeshan},
Title = {{FROM CONVENTIONAL TO IT BASED VISUAL MANAGEMENT: A CONCEPTUAL DISCUSSION
   FOR LEAN CONSTRUCTION}},
Journal = {{JOURNAL OF INFORMATION TECHNOLOGY IN CONSTRUCTION}},
Year = {{2017}},
Volume = {{22}},
Pages = {{220-246}},
Abstract = {{Lean construction and construction automation are two of the important
   efforts to improve the performance of the construction industry.
   However, apart from a small number of scholarly articles and
   implementation prototypes, the lean and digital construction movements
   seem to be largely running independent of each other. This paper aims at
   exploring those connections between Visual Management (VM), a
   fundamental information management strategy in lean construction, and
   emerging technologies, demonstrating the synergy between the two
   concepts over potential implementation scenarios and establishing their
   conceptual connections in construction. Consequently, the hypothesis of
   the paper is there is a significant synergy between emerging
   technologies (construction automation) and visual/sensory information
   management strategies (Visual Management) in lean construction. The
   hypothesis is explored by (i) discussing how emerging technologies can
   support conventional VM tools and techniques and (ii) presenting a
   conceptual architecture to integrate emerging technologies, such as the
   Internet of Things, Augmented Reality, context aware and mobile
   computing, the use of drones and quadcopters, auto identification
   (AutoID) systems and laser scanning, to support lean construction and VM
   on construction sites. Futuristic scenarios for the implementation of
   the context-aware VM in application areas such as production control,
   production levelling, quality control, project planning and control,
   plant maintenance and safety control are examined from a lean
   construction perspective, alongside the presentation of a higher-level
   implementation architecture to integrate various VM and emerging
   technology components to support the implementation in a holistic
   picture. The use of such scenario based approach was found useful in
   summarising the technology components, their interconnections and
   possible implementation areas in relation with VM. This paper
   demonstrates how the integration of conventional and IT based visual
   management approaches is within reach and holds the potential to enhance
   the construction and maintenance phase of complex, large-scale
   construction projects by reviewing the synergies between operational VM
   concepts and IT.}},
ISSN = {{1874-4753}},
ResearcherID-Numbers = {{Campos Bravo Thomaz, Mariana/S-6035-2017}},
Unique-ID = {{ISI:000412761900004}},
}

@inproceedings{ ISI:000412248900067,
Author = {Klimant, Philipp and Kollatsch, Christian and Schumann, Marco},
Book-Group-Author = {{ASME}},
Title = {{AUGMENTED REALITY SOLUTIONS IN MECHANICAL ENGINEERING}},
Booktitle = {{PROCEEDINGS OF THE ASME 12TH INTERNATIONAL MANUFACTURING SCIENCE AND
   ENGINEERING CONFERENCE - 2017, VOL 3}},
Year = {{2017}},
Note = {{12th ASME International Manufacturing Science and Engineering
   Conference, Los Angeles, CA, JUN 04-08, 2017}},
Organization = {{ASME, Mfg Engn Div}},
Abstract = {{Augmented reality is currently riding a wave of success in the consumer
   sector. In manufacturing, in spite of the global hype surrounding
   Industry 4.0 and the ever growing demand for more personalized and more
   complex products, there are currently only a handful of viable augmented
   reality applications that have actually made their way onto the
   production line. But why is this, and what applications genuinely bring
   added value? These are the questions that will be considered in this
   paper, presenting four examples of augmented reality concepts that have
   made their way from research into manufacturing. The augmented reality
   examples range from process support on a machine and support for a
   process chain, to use in education and training and even marketing
   applications.}},
Article-Number = {{UNSP V003T04A067}},
ISBN = {{978-0-7918-5074-9}},
Unique-ID = {{ISI:000412248900067}},
}

@article{ ISI:000413715600012,
Author = {Buglak, S. S. and Latypova, A. R. and Lenkevich, A. S. and Ocheretyanyi,
   K. A. and Skomorokh, M. M.},
Title = {{THE IMAGE OF THE OTHER IN COMPUTER GAMES}},
Journal = {{VESTNIK SANKT-PETERBURGSKOGO UNIVERSITETA-FILOSOFIYA I KONFLIKTOLOGIYA}},
Year = {{2017}},
Volume = {{33}},
Number = {{2}},
Pages = {{242-253}},
Abstract = {{The article covers one of the topics explored by the researchers of the
   Laboratory of Computer Games Research -the image of the Other (Alien,
   Different, Enemy, etc.) in computer games. Being a new form of
   aesthetic, cultural, social, and communicative experience, computer
   games are beginning to influence our everyday practices. Many of the
   processes in social life (production, labour, education, rest,
   communication) become mediated and playful. Game mechanics are used in
   non-game contexts (this process is called ``gamification{''}), and due
   to this procedure, the experience of computer games is transmitted to
   the areas that are considered to entirely lack playfulness: war, pain,
   violence, corporeal feelings. All in all, nowadays many social
   relationships are formed by the game. For instance, the space of MMORPG
   often becomes a laboratory, where social skills are perfected, the first
   encounter with the other occurs, and the contours of new
   intersubjectivity are set. In games humans are even more unprotected
   than on the stage, in a reality-show, or on the battlefield because they
   cannot hide themselves behind the mask and have to open their face in
   front of the other to make the game happen. To begin the game, we let
   the Other (even if objectified in the form of rules) occupy our being.
   The article considers the examples of how the image of the Other is
   constructed in games, how the game space, the media field of the game,
   engenders certain ethical norms and ways of gaming behaviour. The way we
   look at each other is is determined by media, and in this sense, the
   game becomes more influential. This fact cannot be ignored by the social
   sciences, especially by those who explore media reality. Refs 33.}},
DOI = {{10.21638/11701/spbu17.2017.212}},
ISSN = {{2542-2278}},
EISSN = {{2541-9382}},
ResearcherID-Numbers = {{Ocheretyany, Konstantin/F-5532-2016}},
ORCID-Numbers = {{Ocheretyany, Konstantin/0000-0002-0711-644X}},
Unique-ID = {{ISI:000413715600012}},
}

@inproceedings{ ISI:000410922900010,
Author = {Rao, Yi and Xu, Bing-li and Jing, Tao and Zhang, Fei and Zhao, Xiu-yu},
Editor = {{Patnaik, S}},
Title = {{The Current Status and Future Perspectives of Virtual Maintenance}},
Booktitle = {{ADVANCES IN INFORMATION AND COMMUNICATION TECHNOLOGY}},
Series = {{Procedia Computer Science}},
Year = {{2017}},
Volume = {{107}},
Pages = {{58-63}},
Note = {{7th International Congress of Information and Communication Technology
   (ICICT), Sanya, PEOPLES R CHINA, JAN 01-02, 2017}},
Organization = {{Interscience Res Network; Int Journal Informat \& Commun Technol}},
Abstract = {{Virtual maintenance, which is widely used in aerospace, automobile,
   military equipment, etc., has been given abroad attention among
   equipment life -cycle including concept definition, system design,
   component production, daily operation, troubleshooting, and so on.
   Virtual maintenance has been given many different definitions and lot of
   technologies for implementation, but there is no clear systematic
   conclusion on the both. Based on the review of the current achievements,
   the elements of virtual maintenance are extracted, the technologies are
   systematically explored, and the applications are developed. Meanwhile,
   the future perspectives of virtual maintenance are discussed associated
   with virtual reality and augmented reality, multi-person collaboration,
   remote assistance, as well as artificial intelligence. (C) 2017 The
   Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2017.03.056}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000410922900010}},
}

@inproceedings{ ISI:000411785000009,
Author = {Bruder, Friedrich-Karl and Faecke, Thomas and Hagen, Rainer and Hansen,
   Sven and Manecke, Christel and Orselli, Enrico and Rewitz, Christian and
   Roelle, Thomas and Walze, Guenther},
Editor = {{Kress, BC and Osten, W and Urbach, HP}},
Title = {{Thin Combiner Optics utilizing Volume Holographic Optical Elements
   (vHOEs) using Bayfol (R) HX Photopolymer Film}},
Booktitle = {{DIGITAL OPTICAL TECHNOLOGIES 2017}},
Series = {{Proceedings of SPIE}},
Year = {{2017}},
Volume = {{10335}},
Note = {{Conference on Digital Optical Technologies, Munich, GERMANY, JUN 26-28,
   2017}},
Organization = {{SPIE}},
Abstract = {{The main function of any augmented reality system is to seamlessly merge
   the real world perception of a viewer with computer generated images and
   information. Besides real-time head-tracking and room-scanning
   capabilities the combiner optics, which optically merge the natural with
   the artificial visual information, represent a key component for those
   systems. Various types of combiner optics are known to the industry, all
   with their specific advantages and disadvantages. Beside the
   well-established solutions based on refractive optics or surface
   gratings, volume Holographic Optical Elements (vHOEs) are a very
   attractive alternative in this field. The unique characteristics of
   these diffractive grating structures - being lightweight, thin, flat and
   invisible in Off Bragg conditions - make them perfectly suitable for
   their use in integrated and compact combiners. For any consumer
   application it is paramount to build unobtrusive and lightweight
   augmented reality displays, for which those volume holographic combiners
   are ideally suited.
   Due to processing challenges of (historic) holographic recording
   materials mass production of vHOE holographic combiners was not
   possible. Therefor vHOE based combiners found use in military
   applications only by now. The new Bayfol (R) HX instant developing
   holographic photopolymer film provides an ideal technology platform to
   optimize the performance of vHOEs in a wide range of applications.
   Bayfol (R) HX provides full color capability and adjustable diffraction
   efficiency as well as an unprecedented optical clarity when compared to
   classical holographic recording materials like silver halide emulsions
   (AgHX) or dichromated gelatin (DCG). Bayfol (R) HX film is available in
   industrial scale and quality. Its properties can be tailored for various
   diffractive performances and integration methods. Bayfol (R) HX film is
   easy to process without any need for chemical or thermal development
   steps, offering simplified contact-copy mass production schemes.}},
DOI = {{10.1117/12.2270158}},
Article-Number = {{UNSP 103350D}},
ISSN = {{0277-786X}},
EISSN = {{1996-756X}},
ISBN = {{978-1-5106-1116-0; 978-1-5106-1115-3}},
Unique-ID = {{ISI:000411785000009}},
}

@inproceedings{ ISI:000411785000012,
Author = {Russo, Juan Manuel and Dimov, Fedor and Padiyar, Joy and Coe-Sullivan,
   Seth},
Editor = {{Kress, BC and Osten, W and Urbach, HP}},
Title = {{Mass production of holographic transparent components for augmented and
   virtual reality applications}},
Booktitle = {{DIGITAL OPTICAL TECHNOLOGIES 2017}},
Series = {{Proceedings of SPIE}},
Year = {{2017}},
Volume = {{10335}},
Note = {{Conference on Digital Optical Technologies, Munich, GERMANY, JUN 26-28,
   2017}},
Organization = {{SPIE}},
Abstract = {{Diffractive optics such as holographic optical elements (HOEs) can
   provide transparent and narrow band components with arbitrary incident
   and diffracted angles for near-to-eye commercial electronic products for
   augmented reality (AR), virtual reality (VR), and smart glass
   applications. In this paper, we will summarize the operational
   parameters and general optical geometries relevant for near-to-eye
   displays, the holographic substrates available for these applications,
   and their performance characteristics and ease of manufacture. We will
   compare the holographic substrates available in terms of fabrication,
   manufacturability, and end-user performance characteristics. Luminit is
   currently emplacing the manufacturing capacity to serve this market, and
   this paper will discuss the capabilities and limitations of this unique
   facility.}},
DOI = {{10.1117/12.2271508}},
Article-Number = {{UNSP 103350H}},
ISSN = {{0277-786X}},
EISSN = {{1996-756X}},
ISBN = {{978-1-5106-1116-0; 978-1-5106-1115-3}},
Unique-ID = {{ISI:000411785000012}},
}

@inproceedings{ ISI:000407472500012,
Author = {Bruder, Friedrich-Karl and Faecke, Thomas and Grote, Fabian and Hagen,
   Rainer and Hoenel, Dennis and Koch, Eberhard and Rewitz, Christian and
   Walze, Guenther and Wewer, Brita},
Editor = {{Hrabovsky, M and Sheridan, JT and Fimia, A}},
Title = {{Performance Optimization in Mass Production of Volume Holographic
   Optical Elements (vHOEs) using Bayfol (R) HX Photopolymer Film}},
Booktitle = {{HOLOGRAPHY: ADVANCES AND MODERN TRENDS V}},
Series = {{Proceedings of SPIE}},
Year = {{2017}},
Volume = {{10233}},
Note = {{Conference on Holography - Advances and Modern Trends V, Prague, CZECH
   REPUBLIC, APR 24-27, 2017}},
Organization = {{SPIE}},
Abstract = {{Volume Holographic Optical Elements (vHOEs) gained wide attention as
   optical combiners for the use in smart glasses and augmented reality (SG
   and AR, respectively) consumer electronics and automotive head-up
   display applications. The unique characteristics of these diffractive
   grating structures - being lightweight, thin and flat - make them
   perfectly suitable for use in integrated optical components like
   spectacle lenses and car windshields. While being transparent in
   Off-Bragg condition, they provide full color capability and adjustable
   diffraction efficiency. The instant developing photopolymer Bayfol (R)
   HX film provides an ideal technology platform to optimize the
   performance of vHOEs in a wide range of applications.
   Important for any commercialization are simple and robust mass
   production schemes. In this paper, we present an efficient and easy to
   control one-beam recording scheme to copy a so-called master vHOE in a
   step-and-repeat process. In this contact-copy scheme, Bayfol (R) HX film
   is laminated to a master stack before being exposed by a scanning laser
   line. Subsequently, the film is delaminated in a controlled fashion and
   bleached. We explain working principles of the one-beam copy concept,
   discuss the opto-mechanical construction and outline the downstream
   process of the installed vHOE replication line. Moreover, we focus on
   aspects like performance optimization of the copy vHOE, the bleaching
   process and the suitable choice of protective cover film in the
   re-lamination step, preparing the integration of the vHOE into the final
   device.}},
DOI = {{10.1117/12.2265022}},
Article-Number = {{UNSP 102330G}},
ISSN = {{0277-786X}},
ISBN = {{978-1-5106-0967-9; 978-1-5106-0968-6}},
Unique-ID = {{ISI:000407472500012}},
}

@inproceedings{ ISI:000407474100009,
Author = {Bruder, Friedrich-Karl and Faecke, Thomas and Grote, Fabian and Hagen,
   Rainer and Hoenel, Dennis and Koch, Eberhard and Rewitz, Christian and
   Walze, Guenther and Wewer, Brita},
Editor = {{Bjelkhagen, HI and Bove, VM}},
Title = {{Mass Production of Volume Holographic Optical Elements (vHOEs) using
   Bayfol (R) HX Photopolymer Film in a Roll-to-Roll Copy Process}},
Booktitle = {{PRACTICAL HOLOGRAPHY XXXI: MATERIALS AND APPLICATIONS}},
Series = {{Proceedings of SPIE}},
Year = {{2017}},
Volume = {{10127}},
Note = {{SPIE Conference on Practical Holography XXXI - Materials and
   Applications, San Francisco, CA, JAN 30-FEB 01, 2017}},
Organization = {{SPIE}},
Abstract = {{Volume Holographic Optical Elements (vHOEs) gained wide attention as
   optical combiners for the use in augmented and virtual reality (AR and
   VR, respectively) consumer electronics and automotive head-up display
   applications. The unique characteristics of these diffractive grating
   structures - being lightweight, thin and flat - make them perfectly
   suitable for use in integrated optical components like spectacle lenses
   and car windshields. While being transparent in Off-Bragg condition,
   they provide full color capability and adjustable diffraction
   efficiency. The instant developing photopolymer Bayfol (R) HX film
   provides an ideal technology platform to optimize the performance of
   vHOEs in a wide range of applications.
   Important for any commercialization are simple and robust mass
   production schemes. In this paper, we present an efficient and easy to
   control one-beam recording scheme to copy a so-called master vHOE in a
   step-and-repeat process. In this contact-copy scheme, Bayfol (R) HX film
   is laminated to a master stack before being exposed by a scanning laser
   line. Subsequently, the film is delaminated in a controlled fashion and
   bleached. We explain working principles of the one-beam copy concept and
   discuss the mechanical construction of the installed vHOE replication
   line. Moreover, we treat aspects like master design, effects of
   vibration and suppression of noise gratings. Furthermore, digital vHOEs
   are introduced as master holograms. They enable new ways of optical
   design and paths to large scale vHOEs.}},
DOI = {{10.1117/12.2250933}},
Article-Number = {{UNSP 101270A}},
ISSN = {{0277-786X}},
ISBN = {{978-1-5106-0696-8}},
Unique-ID = {{ISI:000407474100009}},
}

@inproceedings{ ISI:000404958000038,
Author = {Gasova, Martina and Gaso, Martin and Stefanik, Andrej},
Editor = {{Bujnak, J and Guagliano, M}},
Title = {{Advanced industrial tools of ergonomics based on Industry 4.0 concept}},
Booktitle = {{12TH INTERNATIONAL SCIENTIFIC CONFERENCE OF YOUNG SCIENTISTS ON
   SUSTAINABLE, MODERN AND SAFE TRANSPORT}},
Series = {{Procedia Engineering}},
Year = {{2017}},
Volume = {{192}},
Pages = {{219-224}},
Note = {{12th International Scientific Conference of Young Scientists on
   Sustainable, Modern and Safe Transport, High Tatras, SLOVAKIA, MAY
   31-JUN 02, 2017}},
Organization = {{Univ Zilina}},
Abstract = {{Over the years approach focusing in ergonomics has changed. We still
   talk about identification - analysis - elimination of the risks on the
   workplaces. But differences are at the possibilities of modem
   ergonomics, movement of science and technical possibilities. The options
   of using a mobile applications, Internet of Things, data gathering and
   their real time evaluation and their sharing. We present those solutions
   that combine traditional knowledge and modem technologies. The results
   are innovative and advanced ergonomic tools based on Industry 4.0
   concept. Electronic tools are a new direction in ergonomics. With the
   support of mobile applications we see a way to create healthy conditions
   at work for production and also non -production workers, assembly and
   logistics. At the beginning of 20-th century, majority of us had no idea
   what the ergonomics is, how many risks occur during our job that they
   are connected with the health of employees and have not known that
   special methods and tools for their identification, analysis, evaluation
   and identification are developed. With the growing development of
   society we got to stadium when, luckily, majority of companies -
   employers even know the meaning of ergonomics or work risks, about risks
   at their workplaces and establish their evaluation and try to eliminate
   them. We have many methods and tools of modern ergonomics which enable
   us to realize analysis and optimization of employee's work to their
   benefit. Considering experience we can surely claim that we know the
   main problem of these days. It is requisite to realize ergonomic
   evaluation perfectly, extensively and mainly quickly. Slowness of some
   solutions discourages managers and directors and makes effective
   improving of work conditions impossible. The idea of mobile application
   developing which works as a screening tool came with demands from big
   companies that have dozens of workplaces and cannot identify work risks
   by themselves. Ceit ERgonomics Analysis Application, which is described
   in article, is output of our own research and development. It is a
   mobile application developed in CEIT Company in collaboration with the
   University of Zilina and Slovak ergonomic association. It is a screening
   evaluation of space conditions and work positions of workers at
   potentially risky workplaces. It is developed at the base of legislation
   and technical nom's, at our own platform, with the support of virtual
   and augmented reality. The main goal of evaluation by the CERAA usage is
   to find out if the workplace is risky from the ergonomic view. It is an
   innovative way of applied augmented reality tools during the ergonomic
   evaluation of chosen workplaces. Nowadays, the new submodules are being
   developed. They will identify risks at administrative workplaces,
   submodule which will evaluate working with loads and other that will
   evaluate repetitive operations. CERAA is used in several industrial
   companies in Slovakia and Czech Republic from the second half of 2016.
   (C) 2017 The Authors. Published by Elsevier Ltd.}},
DOI = {{10.1016/j.proeng.2017.06.038}},
ISSN = {{1877-7058}},
Unique-ID = {{ISI:000404958000038}},
}

@inproceedings{ ISI:000404511900088,
Author = {Steinhaeusser, Tobias and Reinhart, Gunther},
Editor = {{Takata, S and Umeda, Y and Kondoh, S}},
Title = {{Ensuring Time-saving and Effective Production Planning by Prioritizing
   Activities based on Company-specific Validation Success Rates}},
Booktitle = {{24TH CIRP CONFERENCE ON LIFE CYCLE ENGINEERING}},
Series = {{Procedia CIRP}},
Year = {{2017}},
Volume = {{61}},
Pages = {{505-510}},
Note = {{24th CIRP Conference on Life Cycle Engineering (CIRP LCE), Kamakura,
   JAPAN, MAR 08-10, 2017}},
Organization = {{CIRP; Denso; DMG MORI; Mazak Fdn; JSPS Grant Aid; Japan World Exposit
   1970 Commemorat Fund}},
Abstract = {{Through the use of recent technological advances, such as virtual- and
   augmented-reality validation techniques, many companies were able to
   reduce the number of physical prototypes used during their production
   planning process and thus improve their Time-To-Market. However,
   substituting physical prototypes in production planning comes at a cost,
   as validation results obtained from virtual-or augmented-reality
   techniques are not as reliable as those conventionally generated.
   Considering the fact that up to 85\% of a product's life cycle costs are
   determined during product- and production planning {[}1,2] raises the
   question, at which point accelerating the planning process compromises
   its effectiveness and thus has a negative impact on the Life Cycle
   Costs. To answer this question, this paper discusses a novel approach to
   measure the success rate of non-physical prototype validation techniques
   and, using a Monte-Carlo Simulation, calculate a product's
   production-readiness. This contemplation allows an algorithm-based
   identification of part-specific validation activities that need to be
   carried out in order to ensure a satisfying degree of
   production-readiness while minimizing the number of physical prototypes
   needed. Our time-saving and effective approach has been implemented as a
   software-tool (SIMBAPLAN (R)) and put to use at a German Commercial
   Vehicle Manufacturer. Based on this use case, potentials and limitations
   of the approach are discussed and areas for future research are derived.}},
DOI = {{10.1016/j.procir.2016.11.198}},
ISSN = {{2212-8271}},
Unique-ID = {{ISI:000404511900088}},
}

@inproceedings{ ISI:000404252400186,
Author = {Kranzer, Simon and Prill, Dorian and Aghajanpour, Davood and Merz,
   Robert and Strasser, Rafaela and Mayr, Reinhard and Zoerrer, Helmut and
   Plasch, Matthias and Steringer, Robert},
Book-Group-Author = {{IEEE}},
Title = {{An Intelligent Maintenance Planning Framework Prototype for Production
   Systems}},
Booktitle = {{2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT)}},
Year = {{2017}},
Pages = {{1124-1129}},
Note = {{IEEE International Conference on Industrial Technology (ICIT), Toronto,
   CANADA, MAR 22-25, 2017}},
Organization = {{IEEE; IEEE Ind Elect Soc}},
Abstract = {{The Intelligent Maintenance Planner (IMP) is designed to automate and
   improve maintenance processes in industrial applications. The system
   tracks the entire process cycle beginning with data acquisition and
   management, it then detects and classifies failure states, initializes
   maintenance cases, and selects and assigns the required resources. IMP
   guides maintenance work processes, by automatically providing
   instructions and augmented reality information. Subsequent feedback of
   the maintenance process and new or updated information is added to the
   system and used to train selection algorithms. A prototype of IMP was
   implemented based on an industrial SCADA system and cloud solutions for
   storage and machine learning capabilities. This report explains the
   stages of the maintenance process and provides an outline of the
   implementation and project results.}},
ISBN = {{978-1-5090-5320-9}},
Unique-ID = {{ISI:000404252400186}},
}

@inproceedings{ ISI:000403149400016,
Author = {Luo, Ran and Fang, Qiang and Wei, Jianguo and Lu, Wenhuan and Xu, Weiwei
   and Yang, Yin},
Book-Author = {{Rosenberg, ES
   Krum, DM
   Wartell, Z
   Mohler, B
   Babu, SV
   Steinicke, F
   Interrante, V}},
Title = {{Acoustic VR in the Mouth: A Real-Time Speech-Driven Visual Tongue System}},
Booktitle = {{2017 IEEE VIRTUAL REALITY (VR)}},
Series = {{Proceedings of the IEEE Virtual Reality Annual International Symposium}},
Year = {{2017}},
Pages = {{112-121}},
Note = {{19th IEEE Virtual Reality Conference (VR), Los Angeles, CA, MAR 18-22,
   2017}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Comp Soc Visualizat \& Graph Tech Comm}},
Abstract = {{We propose an acoustic-VR system that converts acoustic signals of human
   language (Chinese) to realistic 3D tongue animation sequences in real
   time. It is known that directly capturing the 3D geometry of the tongue
   at a frame rate that matches the tongue's swift movement during the
   language production is challenging. This difficulty is handled by
   utilizing the electromagnetic articulography (EMA) sensor as the
   intermediate medium linking the acoustic data to the simulated virtual
   reality. We leverage Deep Neural Networks to train a model that maps the
   input acoustic signals to the positional information of pre-defined EMA
   sensors based on 1,108 utterances. Afterwards, we develop a novel
   reduced physics-based dynamics model for simulating the tongue's motion.
   Unlike the existing methods, our deformable model is nonlinear,
   volume-preserving, and accommodates collision between the tongue and the
   oral cavity (mostly with the jaw). The tongue's deformation could be
   highly localized which imposes extra difficulties for existing spectral
   model reduction methods. Alternatively, we adopt a spatial reduction
   method that allows an expressive subspace representation of the tongue's
   deformation. We systematically evaluate the simulated tongue shapes with
   real-world shapes acquired by MRI/CT. Our experiment demonstrates that
   the proposed system is able to deliver a realistic visual tongue
   animation corresponding to a user's speech signal.}},
ISSN = {{1087-8270}},
ISBN = {{978-1-5090-6647-6}},
Unique-ID = {{ISI:000403149400016}},
}

@inproceedings{ ISI:000403149400100,
Author = {Cho, Hyunwoo and Jung, Sung-Uk and Jee, Hyung-Keun},
Book-Author = {{Rosenberg, ES
   Krum, DM
   Wartell, Z
   Mohler, B
   Babu, SV
   Steinicke, F
   Interrante, V}},
Title = {{Real-Time Interactive AR System for Broadcasting}},
Booktitle = {{2017 IEEE VIRTUAL REALITY (VR)}},
Series = {{Proceedings of the IEEE Virtual Reality Annual International Symposium}},
Year = {{2017}},
Pages = {{353-354}},
Note = {{19th IEEE Virtual Reality Conference (VR), Los Angeles, CA, MAR 18-22,
   2017}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Comp Soc Visualizat \& Graph Tech Comm}},
Abstract = {{For live television broadcast such as the educational program for
   children conducted through viewer participation, the smooth integration
   of virtual contents and the interaction between the casts and them are
   quite important issues. Recently there have been many attempts to make
   aggressive use of interactive virtual contents in live broadcast due to
   the advancement of AR/VR technology and virtual studio technology. These
   previous works have many limitations that do not support real-time 3D
   space recognition or immersive interaction. In this sense, we propose an
   augmented reality based real-time broadcasting system which perceives
   the indoor space using a broadcasting camera and a RGB-D camera. Also,
   the system can support the real-time interaction between the augmented
   virtual contents and the casts. The contribution of this work is the
   development of a new augmented reality based broadcasting system that
   not only enables filming using compatible interactive 3D contents in
   live broadcast but also drastically reduces the production costs. For
   the practical use, the proposed system was demonstrated in the actual
   broadcast program called ``Ding Dong Dang Kindergarten{''} which is a
   representative children educational program on the national broadcasting
   channel of Korea.}},
ISSN = {{1087-8270}},
ISBN = {{978-1-5090-6647-6}},
Unique-ID = {{ISI:000403149400100}},
}

@inproceedings{ ISI:000403051200022,
Author = {Dupre, Ludovic and Marra, Marjorie and Verney, Valentin and Aventurier,
   Bernard and Henry, Franck and Olivier, Francois and Tirano, Sauveur and
   Daami, Anis and Templier, Francois},
Editor = {{Chyi, JI and Fujioka, H and Morkoc, H and Nanishi, Y and Schwarz, UT and Shim, JI}},
Title = {{Processing and characterization of high resolution GaN/InGaN LED arrays
   at 10 micron pitch for micro display applications}},
Booktitle = {{GALLIUM NITRIDE MATERIALS AND DEVICES XII}},
Series = {{Proceedings of SPIE}},
Year = {{2017}},
Volume = {{10104}},
Note = {{Conference on Gallium Nitride Materials and Devices XII, San Francisco,
   CA, JAN 30-FEB 02, 2017}},
Organization = {{SPIE}},
Abstract = {{We report the fabrication process and characterization of high
   resolution 873 x 500 pixels emissive arrays based on blue or green
   GaN/InGaN light emitting diodes (LEDs) at a reduced pixel pitch of 10 mu
   m. A self-aligned process along with a combination of damascene
   metallization steps is presented as the key to create a common cathode
   which is expected to provide good thermal dissipation and prevent
   voltage drops between center and side of the micro LED matrix. We will
   discuss the challenges of a self-aligned technology related to the
   choice of a good P contact metal and will present our solutions for the
   realization of the metallic interconnections between the GaN contacts
   and the higher levels of metallization at such a small pixel pitch.
   Enhanced control of each technological step allows scalability of the
   process up to 4 inch LED wafers and production of high quality LED
   arrays. The very high brightness (up to 107 cd. m(-2)) and good external
   quantum efficiency (EQE) of the resulting device make these kind of
   micro displays suitable for augmented reality or head up display
   applications.}},
DOI = {{10.1117/12.2252196}},
Article-Number = {{UNSP 1010422-1}},
ISSN = {{0277-786X}},
EISSN = {{1996-756X}},
ISBN = {{978-1-5106-0649-4; 978-1-5106-0650-0}},
Unique-ID = {{ISI:000403051200022}},
}

@inproceedings{ ISI:000401707900017,
Author = {Miguel Santana, Jose and Wendel, Jochen and Trujillo, Agustin and Pablo
   Suarez, Jose and Simons, Alexander and Koch, Andreas},
Editor = {{Gartner, G and Huang, H}},
Title = {{Multimodal Location Based Services-Semantic 3D City Data as Virtual and
   Augmented Reality}},
Booktitle = {{PROGRESS IN LOCATION-BASED SERVICES 2016}},
Series = {{Lecture Notes in Geoinformation and Cartography}},
Year = {{2017}},
Pages = {{329-353}},
Note = {{13th Location-Based Services (LBS) Conference, Tech Univ Wien, Vienna,
   AUSTRIA, NOV, 2016}},
Abstract = {{The visualization of cross-domain spatial data sets has become an
   important task within the analysis of energy models. The representation
   of these models is especially important in urban areas, in which the
   under-standing of patterns of energy production and demand is key for an
   efficient city planning. Location Based Services (LBS) provide a
   valuable addition towards the analysis and visualization of those data
   sets as the user can explore the output of different models and
   simulations in the real environment at the location of interest. Towards
   this aim, the present research explores mobile alternatives to the
   visual analysis of temporal data series and 3D building models. Based on
   the fields of numerical simulation, GIS and computer graphics, this work
   presents a novel mobile service that allows exploring urban models at
   different Level of Details (LoDs) using well-known standards such as
   CityGML. Ultimately, the project enables researchers, city planners and
   technicians to explore urban energy datasets in an interactive and
   immersive manner as Virtual Globes, Virtual Reality and Augmented
   Reality. Using models of the city of Karlsruhe, the final service has
   been implemented and tested on the iOS platform providing an empirical
   insight on the performance of the system. In addition, this research
   provides a holistic approach by developing one application that is
   capable of seamlessly change the visualization mode.}},
DOI = {{10.1007/978-3-319-47289-8\_17}},
ISSN = {{1863-2246}},
ISBN = {{978-3-319-47289-8; 978-3-319-47288-1}},
ResearcherID-Numbers = {{Santana Nunez, Jose Miguel/M-2255-2014
   Trujillo-Pino, Agustin/K-5825-2014
   }},
ORCID-Numbers = {{Santana Nunez, Jose Miguel/0000-0002-5391-9964
   Trujillo-Pino, Agustin/0000-0001-6212-5317
   Suarez, Jose Pablo/0000-0001-8140-9008}},
Unique-ID = {{ISI:000401707900017}},
}

@article{ ISI:000390996300004,
Author = {Barroso Osuna, Julio Manuel and Gallego Perez, Oscar Manuel},
Title = {{Learning resource production in Augmented Reality supported by education
   students}},
Journal = {{EDMETIC}},
Year = {{2017}},
Volume = {{6}},
Number = {{1}},
Pages = {{23-38}},
Abstract = {{The educational and technological reality in the classrooms of the
   different academic levels in our educational system at present, comes
   from the hand of the incorporation of new tools that bring over the
   students, of simple, playful and formative form, to the contents. One of
   the technologies that take more impulse and importance at present is the
   Augmented Reality, which has been opening way him, specially in the
   higher education. In this article let's sense beforehand the results of
   a study realized with students of science education in the University of
   Seville, which have taken part in a training activity in the use of the
   Augmented Reality as tool for the creation of objects of learning.
   Across a questionnaire, we analyze the degree of satisfaction of the
   participants with regard to the above mentioned training activity, being
   the results reached after the analysis of the very positive information.}},
ISSN = {{2254-0059}},
Unique-ID = {{ISI:000390996300004}},
}

@article{ ISI:000390996300005,
Author = {Fombona Cadavieco, Javier and Pascual Sevillano, Maria Angeles},
Title = {{The scientific production on Augmented Reality, an educational
   literature review in SCOPUS}},
Journal = {{EDMETIC}},
Year = {{2017}},
Volume = {{6}},
Number = {{1}},
Pages = {{39-61}},
Abstract = {{This review shows the current implementation of technology of Augmented
   Reality. From an educational perspective, we use as instrument the
   Scopus repository. The procedure is a descriptive study on n=1336
   references: articles, conference papers, books and book chapters. The
   quantitative result shows the mainly thematic areas involved. On the
   other hand the qualitative analysis discovers the situation of the
   phenomenon. The review highlights the positive performance derived from
   RA, linked by its creative, motivational, playful potential and the
   veracity of the RA experience. This fact is important to represent
   environments impossible in the classroom. We also found research
   highlighting the problems of RA.}},
ISSN = {{2254-0059}},
Unique-ID = {{ISI:000390996300005}},
}

@article{ ISI:000390996300009,
Author = {Madrigal Lozano, Maria Magdalena and Hernandez Moreno, Laura Alicia and
   Lopez Solorzano, Juan Gabriel and Merla Gonzalez, Alama Elizabeth},
Title = {{Incursion of emerging technologies in a public business school in Mexico}},
Journal = {{EDMETIC}},
Year = {{2017}},
Volume = {{6}},
Number = {{1}},
Pages = {{124-144}},
Abstract = {{This article show the results obtained from an exploratory, descriptive
   study with transectional scope, to know the use, production and research
   of emerging technologies MOOC, gamification and Augmented Reality in the
   educational processes of the business programs. A measurement instrument
   was applied to faculty of the academic programs of the mixed modality in
   the business school of a Public University in the Northeast of Mexico.
   This study is an opportunity to report findings in the field of business
   schools that incorporate these technologies for didactic purposes and to
   create proposals of work on these areas.}},
ISSN = {{2254-0059}},
Unique-ID = {{ISI:000390996300009}},
}

@article{ ISI:000382273700015,
Author = {Elia, Valerio and Gnoni, Maria Grazia and Lanzilotto, Alessandra},
Title = {{Evaluating the application of augmented reality devices in manufacturing
   from a process point of view: An AHP based model}},
Journal = {{EXPERT SYSTEMS WITH APPLICATIONS}},
Year = {{2016}},
Volume = {{63}},
Pages = {{187-197}},
Month = {{NOV 30}},
Abstract = {{Augmented Reality (AR) systems in last few years show great
   potentialities in the manufacturing context: recent pilot projects were
   developed for supporting quicker product and process design, as well as
   control and maintenance activities. The high technological complexity
   together with the wide variety of AR devices require a high
   technological skill; on the other hand, evaluating their actual impacts
   on the manufacturing process is still an open question. Few recent
   studies have analysed this topic by using qualitative approaches based
   on an ``ex post{''} analysis i.e. after the design and/or the adoption
   of the AR system - for evaluating the effectiveness of a developed AR
   application. The paper proposes an expert based tool for supporting
   production managers and researchers in effectively evaluating a
   preliminary ex ante feasibility analysis for assessing quantitatively
   most efficient single AR devices (or combinations) to be applied in
   specific manufacturing processes. A multi-criteria model based on
   Analytic Hierarchy Process (AHP) method has been proposed to provide
   decision makers with quantitative knowledge for more efficiently
   designing AR applications in manufacturing. The model allows to
   integrate, in the same decision support tool, technical knowledge
   regarding AR devices with critical process features characterizing
   manufacturing processes, thus allowing to assess the contribution of the
   AR device in a wider prospective compared to current technological
   analyses. A test case study about the evaluation of AR system in on-site
   maintenance service is also discussed aiming to validate the model, and
   to outline its global applicability and potentialities. Obtained results
   highlighted the full efficacy of the proposed model in supporting
   ex-ante feasibility studies. (C) 2016 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.eswa.2016.07.006}},
ISSN = {{0957-4174}},
EISSN = {{1873-6793}},
ORCID-Numbers = {{gnoni, maria grazia/0000-0001-7930-0556}},
Unique-ID = {{ISI:000382273700015}},
}

@article{ ISI:000392947900002,
Author = {Templier, Francois},
Title = {{GaN-based emissive microdisplays: A very promising technology for
   compact, ultra-high brightness display systems}},
Journal = {{Journal of the Society for Information Display}},
Year = {{2016}},
Volume = {{24}},
Number = {{11}},
Pages = {{669-675}},
Month = {{NOV}},
Abstract = {{High-brightness GaN-based emissive microdisplays can be fabricated with
   different approaches that are listed and described. They consist either
   of hybridizing a GaN LED array on a CMOS circuit or building a
   monolithic component on a single substrate. Using the hybridization
   approach, two types of 10-mu m pixel pitch GaN microdisplay prototypes
   were developed: (1) directly driven, 300 x 252 pixels and (2)
   active-matrix, 873 x 500 pixels. Brightness as high as 1 x 10(6) and 1 x
   10(7) cd/m(2) for blue and green arrays, respectively, were reached.
   GaN-based emissive microdisplays are suitable for augmented reality
   systems or head-up displays, but some challenges remain before they can
   be put in production.}},
DOI = {{10.1002/jsid.516}},
ISSN = {{1071-0922}},
EISSN = {{1938-3657}},
Unique-ID = {{ISI:000392947900002}},
}

@article{ ISI:000391707700030,
Author = {Simon, Laurent S. R. and Zacharov, Nick and Katz, Brian F. G.},
Title = {{Perceptual attributes for the comparison of head-related transfer
   functions}},
Journal = {{JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA}},
Year = {{2016}},
Volume = {{140}},
Number = {{5}},
Pages = {{3623-3632}},
Month = {{NOV}},
Abstract = {{The benefit of using individual head-related transfer functions (HRTFs)
   in binaural audio is well documented with regards to improving
   localization precision. However, with the increased use of binaural
   audio in more complex scene renderings, cognitive studies, and virtual
   and augmented reality simulations, the perceptual impact of HRTF
   selection may go beyond simple localization. In this study, the authors
   develop a list of attributes which qualify the perceived differences
   between HRTFs, providing a qualitative understanding of the perceptual
   variance of non-individual binaural renderings. The list of attributes
   was designed using a Consensus Vocabulary Protocol elicitation method.
   Participants followed an Individual Vocabulary Protocol elicitation
   procedure, describing the perceived differences between binaural stimuli
   based on binauralized extracts of multichannel productions. This was
   followed by an automated lexical reduction and a series of consensus
   group meetings during which participants agreed on a list of relevant
   attributes. Finally, the proposed list of attributes was then evaluated
   through a listening test, leading to eight valid perceptual attributes
   for describing the perceptual dimensions affected by HRTF set
   variations. (C) 2016 Acoustical Society of America.}},
DOI = {{10.1121/1.4966115}},
ISSN = {{0001-4966}},
EISSN = {{1520-8524}},
ResearcherID-Numbers = {{Katz, Brian/I-3191-2012}},
ORCID-Numbers = {{Katz, Brian/0000-0001-5118-0943}},
Unique-ID = {{ISI:000391707700030}},
}

@article{ ISI:000388446200021,
Author = {Patney, Anjul and Salvi, Marco and Kim, Joohwan and Kaplanyan, Anton and
   Wyman, Chris and Benty, Nir and Luebke, David and Lefohn, Aaron},
Title = {{Towards Foveated Rendering for Gaze-Tracked Virtual Reality}},
Journal = {{ACM TRANSACTIONS ON GRAPHICS}},
Year = {{2016}},
Volume = {{35}},
Number = {{6}},
Month = {{NOV}},
Note = {{ACM SIGGRAPH Asia Conference, Macao, PEOPLES R CHINA, 2016}},
Organization = {{ACM SIGGRAPH; Adobe Syst Inc; King Abdullah Univ Sci \& Technol;
   Microsoft Corp}},
Abstract = {{Foveated rendering synthesizes images with progressively less detail
   outside the eye fixation region, potentially unlocking significant
   speedups for wide field-of-view displays, such as head mounted displays,
   where target framerate and resolution is increasing faster than the
   performance of traditional real-time renderers.
   To study and improve potential gains, we designed a foveated rendering
   user study to evaluate the perceptual abilities of human peripheral
   vision when viewing today's displays. We determined that filtering
   peripheral regions reduces contrast, inducing a sense of tunnel vision.
   When applying a postprocess contrast enhancement, subjects tolerated up
   to 2x larger blur radius before detecting differences from a
   non-foveated ground truth. After verifying these insights on both
   desktop and head mounted displays augmented with high-speed
   gaze-tracking, we designed a perceptual target image to strive for when
   engineering a production foveated renderer.
   Given our perceptual target, we designed a practical foveated rendering
   system that reduces number of shades by up to 70\% and allows coarsened
   shading up to 30 degrees closer to the fovea than Guenter et al.
   {[}2012] without introducing perceivable aliasing or blur. We filter
   both pre-and post-shading to address aliasing from undersampling in the
   periphery, introduce a novel multiresolution-and saccade-aware temporal
   antialising algorithm, and use contrast enhancement to help recover
   peripheral details that are resolvable by our eye but degraded by
   filtering.
   We validate our system by performing another user study. Frequency
   analysis shows our system closely matches our perceptual target.
   Measurements of temporal stability show we obtain quality similar to
   temporally filtered non-foveated renderings.}},
DOI = {{10.1145/2980179.2980246}},
Article-Number = {{179}},
ISSN = {{0730-0301}},
EISSN = {{1557-7368}},
ORCID-Numbers = {{Wyman, Chris/0000-0002-5133-4292}},
Unique-ID = {{ISI:000388446200021}},
}

@article{ ISI:000389214400007,
Author = {Franceschini, Fiorenzo and Galetto, Maurizio and Maisano, Domenico and
   Mastrogiacomo, Luca},
Title = {{Towards the use of augmented reality techniques for assisted acceptance
   sampling}},
Journal = {{PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF
   ENGINEERING MANUFACTURE}},
Year = {{2016}},
Volume = {{230}},
Number = {{10}},
Pages = {{1870-1884}},
Month = {{OCT}},
Abstract = {{Acceptance sampling is a statistical procedure for accepting or
   rejecting production lots according to the result of a sample
   inspection. Formalizing the concept of assisted acceptance sampling,
   this article suggests the use of consolidated tools for reducing the
   risk of human errors in acceptance sampling activities. To this purpose,
   the application of augmented reality techniques may represent a
   profitable and sustainable solution. An augmented reality-based
   prototype system is described in detail and tested by an experimental
   plan. The major original contributions of this work are (a) introducing
   the new paradigm of assisted acceptance sampling and (b) developing a
   preliminary application in an industrial-like environment. This
   application is a first step towards the realization of a complete
   assisted acceptance sampling system.}},
DOI = {{10.1177/0954405415624360}},
ISSN = {{0954-4054}},
EISSN = {{2041-2975}},
ORCID-Numbers = {{Mastrogiacomo, Luca/0000-0002-8454-5918
   MAISANO, Domenico/0000-0002-8154-4469}},
Unique-ID = {{ISI:000389214400007}},
}

@article{ ISI:000393027600005,
Author = {Pande, Rukmini and Nadkarni, Samira},
Title = {{I Will Tell Your Story: New Media Activism and the Indian ``Rape
   Crisis{''}}},
Journal = {{Journal of Feminist Scholarship}},
Year = {{2016}},
Number = {{11}},
Pages = {{28-45}},
Month = {{FAL}},
Abstract = {{This article analyzes the mediatized representations of the Indian
   ``rape crisis{''} that gained global attention in the aftermath of the
   brutal gang rape of Jyoti Singh Pandey in New Delhi in 2012. While much
   attention was given to Leslie Udwin's documentary on the incident,
   India's Daughter (2015), which was subsequently banned by the Indian
   government, there were several other creative responses that attempted
   to negotiate with the meaning of the event. This article examines two
   such texts-the multimedia short story We Are Angry (2015) and the
   augmented-reality comic Priya's Shakti (2014). Both these texts declare
   their intention to function as ``activist{''} multimedia pieces that
   leverage the power of Internet-mediated platforms to raise awareness
   about the condition of the ``Indian woman{''} in the contemporary
   moment. This article argues that these texts, in their attempts to
   portray an essentialized and universalized image of the ``Indian
   woman,{''} reenact certain violent historical erasures along the lines
   of caste, sexuality, class, and religion. The article undertakes a
   medium-specific examination of the works, considering their presumed
   audiences, language, content, and most notably their (failed) attempts
   at locating themselves within both historical and contemporary Indian
   feminist landscapes. In doing so, this discussion situates itself within
   ongoing Indian social justice debates, specifically those pertaining to
   mediatized narratives of rape, in order to critique the production of
   ``feminism{''} in We Are Angry and Priya's Shakti. By considering these
   texts alongside other, more inclusive online narrative spaces, we
   underline the importance of multiple feminist voices being heard on the
   issues in question, as well as the need to question any seemingly
   universal ``we{''} of these narratives, their audience, or the women
   they claim to represent.}},
ISSN = {{2158-6179}},
ResearcherID-Numbers = {{Pande, Rukmini/S-2745-2017}},
ORCID-Numbers = {{Pande, Rukmini/0000-0002-3438-727X}},
Unique-ID = {{ISI:000393027600005}},
}

@article{ ISI:000378731600009,
Author = {Skola, Filip and Liarokapis, Fotis},
Title = {{Examining the effect of body ownership in immersive virtual and
   augmented reality environments}},
Journal = {{VISUAL COMPUTER}},
Year = {{2016}},
Volume = {{32}},
Number = {{6-8}},
Pages = {{761-770}},
Month = {{JUN}},
Note = {{33rd Conference on Computer Graphics International (CGI), Heraklion,
   GREECE, JUN 28-JUL 01, 2016}},
Organization = {{Fdn Res Technol}},
Abstract = {{The traditional rubber hand illusion is a psychological experiment where
   participants are under the illusion that a rubber hand is part of their
   own body. This paper examines the use of real, virtual and augmented
   reality environments for identifying the elements that influence body
   ownership in healthy participants. Compared to the classical experiment
   where a plastic rubber hand was used, a realistic 3D representation was
   chosen to create the same illusion this time in both immersive virtual
   reality and augmented reality. Experiments were performed on 30
   volunteers undergoing testing session composed of three stages.
   Participants were asked to complete two different questionnaires, one
   measuring their cognitive workload and another one regarding their
   experience with the rubber hand illusion. In addition, EEG signals of
   the individuals were recorded, resulting in 90 electroencephalogram
   datasets. Results indicate correlations between ownership statements
   with beta and gamma electroencephalogram bands in premotor cortex
   activity. Link between higher gamma production in ventral premotor area
   during the illusion was established in previous studies.}},
DOI = {{10.1007/s00371-016-1246-8}},
ISSN = {{0178-2789}},
EISSN = {{1432-2315}},
ORCID-Numbers = {{Liarokapis, Fotis/0000-0003-3617-2261}},
Unique-ID = {{ISI:000378731600009}},
}

@article{ ISI:000369214700005,
Author = {Yew, A. W. W. and Ong, S. K. and Nee, A. Y. C.},
Title = {{Towards a griddable distributed manufacturing system with augmented
   reality interfaces}},
Journal = {{ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING}},
Year = {{2016}},
Volume = {{39}},
Pages = {{43-55}},
Month = {{JUN}},
Abstract = {{Rapidly changing demand and mass customization require highly flexible
   and adaptive manufacturing systems. Manufacturing operations have
   evolved in order to keep up by organizing themselves into smaller units
   of specialized production processes that are combined in different ways
   to create different products. Human workers are integral in the
   manufacturing systems and they too must be flexible and adaptive. This
   paper describes an augmented reality manufacturing system that aims to
   greatly improve the information perception of the different types of
   workers in a manufacturing facility and to make interaction with
   manufacturing software natural and efficient. In this approach,
   traditionally paper-based and computer-based tasks are augmented to the
   workers' interactions in the environment. The system is distributed and
   modular as the different functions of CAD/CAM software are provided by
   individual physical or virtual objects in the environment or by a
   combination of them working cooperatively. This modularity allows the
   individual resources and facilities to be linked via internet onto a
   manufacturing grid with universally-accessible augmented reality
   interfaces to their services. (C) 2015 Elsevier Ltd. All rights
   reserved.}},
DOI = {{10.1016/j.rcim.2015.12.002}},
ISSN = {{0736-5845}},
EISSN = {{1879-2537}},
ORCID-Numbers = {{Yew, Andrew/0000-0002-1791-4525}},
Unique-ID = {{ISI:000369214700005}},
}

@article{ ISI:000377147900004,
Author = {Lin, Yi Lung and Yang, Jie Chi},
Title = {{AUGMENTED REALITY BASED LEARNING APPLIED TO GREEN ENERGY}},
Journal = {{JOURNAL OF MATERIALS EDUCATION}},
Year = {{2016}},
Volume = {{38}},
Number = {{1-2}},
Pages = {{37-50}},
Month = {{APR}},
Abstract = {{Education about green energy, such as understanding of principles and
   applications of solar energy or wind power, is a crucial topic in
   general science courses. The course unit for the process development of
   energy-related materials includes topics that are complex and abstract,
   such as the principle of the n-type, and p-type semiconductors, or
   photoconductive effects in solar cells, thus hindering the learning
   process of learners who do not specialize in this field, when they read
   related books and attempt to understand physical and chemical phenomena.
   To assist such learners in enhancing their learning effectiveness, this
   study used an augmented reality-based learning (ARBL) method and virtual
   reality technology to help learners comprehend green energy. Through
   ARBL integrated with virtual reality technology, learners were presented
   with various types of visual media (including web pages, text and
   pictures, animations, videos, and interactive games) while they learn
   about the related green energy knowledge. Such visual presentations were
   used to illustrate the operating principles for the process development
   of solar energy production, reduce the number of abstract words, and
   enhance learner comprehension. In addition, a global positioning system
   (GPS) was integrated into ARBL to guide learners in visiting locations
   where green energy equipment (e.g., solar street lights) is used.
   Through observations, reflections, and cloud recording, learners
   documented the strengths and limitations of green energy use and
   proposed related application methods and innovative ideas. In cloud
   recording, text mining technology (Pang and Lee) and a word cloud (Cui
   et al.) were adopted to summarize crucial points and assist learners in
   understanding critical problems. Group discussion was conducted for
   learners to share their learning approaches, observations, and findings,
   thereby enhancing their learning effectiveness. The results of this
   study demonstrated that learners strongly accepted ARBL and were highly
   satisfied with this learning approach. Conclusions drawn in this study
   can serve as a reference for educators and educational institutions in
   designing courses.}},
ISSN = {{0738-7989}},
ResearcherID-Numbers = {{Yang, Jie Chi/E-1506-2011}},
ORCID-Numbers = {{Yang, Jie Chi/0000-0002-6265-1453}},
Unique-ID = {{ISI:000377147900004}},
}

@article{ ISI:000376809100015,
Author = {Pirvu, Bogdan-Constantin and Zamfirescu, Constantin-Bala and Gorecky,
   Dominic},
Title = {{Engineering insights from an anthropocentric cyber-physical system: A
   case study for an assembly station}},
Journal = {{MECHATRONICS}},
Year = {{2016}},
Volume = {{34}},
Number = {{SI}},
Pages = {{147-159}},
Month = {{MAR}},
Abstract = {{To effectively cope with the complexity of manufacturing control
   problems the cyber-physical systems are engineered to work in the social
   space. Therefore the research in the field of cyber-physical systems
   needs to address social aspects when this concept is adopted in factory
   automation. The paper argues for an anthropocentric cyber-physical
   reference model as the basic decomposition unit for the design of
   distributed manufacturing control systems. The model assimilates all the
   required components (i.e. physical, computational and human) of a
   synthetic hybrid system in an integrated way. This is due to the real
   need to design cyber-physical production systems where the technological
   advances are merging their functionalities in a way more and more
   difficult to distinctly draw between the physical, computational and
   human components. If this view is almost obvious for advanced
   technologies, such as brain computer interfaces, controlled assistive
   robots and intelligent prostheses, it is equally true even for simple
   automated systems, like context-aware assistive systems that are built
   with state-of-the-art technologies. This assertion is demonstrated in
   the context of the SmartFactory(KL) production system, where the manual
   assembly station exhibits all the key features of an anthropocentric
   cyber-physical system by employing a seamless augmented reality to guide
   the human operator. (C) 2015 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.mechatronics.2015.08.010}},
ISSN = {{0957-4158}},
Unique-ID = {{ISI:000376809100015}},
}

@article{ ISI:000382785800008,
Author = {Yengoh, Genesis Tambang and Armah, Frederick Ato},
Title = {{Land access constraints for communities affected by large-scale land
   acquisition in Southern Sierra Leone}},
Journal = {{GEOJOURNAL}},
Year = {{2016}},
Volume = {{81}},
Number = {{1}},
Pages = {{103-122}},
Month = {{FEB}},
Abstract = {{While national figures of land availability are used to justify
   accepting large-scale land investors, not very much is known about the
   local level realities of land availability. By combining remotely sensed
   data with fieldwork, system dynamics modelling and qualitative research
   methods, we examine local level realities of land use and availability
   in the Malen Chiefdom of Southern Sierra Leone. Here, local communities
   are experiencing the outcomes of large-scale investments in oil palmfor
   biodiesel and other industrial purposes by the SOCFIN Agricultural
   Company. We find that beyond agricultural production, there are other
   land uses that are vital for the socio-cultural, economic and
   environmental realities of communities. The Company does not respect
   engagements promised to local people to set aside buffer zones around
   living areas to serve as biodiversity corridors. Local communities are
   severely deprived of agricultural land and other land resources. The
   operations of SOCFIN do not take account of present or future land needs
   of local people. A baseline requirement of food crop land should be set
   aside for each community, to ensure the attainment of food security in
   communities affected by land acquisitions. Such baseline requirement
   should be augmented with local level needs assessments to meet new
   demand for cropland necessitated by changing demography. This model of
   land planning can be applied to other land use and additional
   engagements of large-scale land investors.}},
DOI = {{10.1007/s10708-014-9606-2}},
ISSN = {{0343-2521}},
EISSN = {{1572-9893}},
ResearcherID-Numbers = {{Armah, Frederick/R-3906-2017}},
ORCID-Numbers = {{Armah, Frederick/0000-0002-9371-5683}},
Unique-ID = {{ISI:000382785800008}},
}

@article{ ISI:000409903700019,
Author = {Moreno Martinez, Noelia Margarita and Leiva Olivencia, Juan Jose and
   Lopez Meneses, Eloy},
Title = {{A FORMATIVE EXPERIENCE IN REALITY AUGMENTED WITH STUDENTS OF MASTER'S IN
   SECONDARY EDUCATION TEACHER TRAINING AT THE UNIVERSITY OF MALAGA}},
Journal = {{INNOVACION EDUCATIVA}},
Year = {{2016}},
Number = {{26}},
Pages = {{265-303}},
Abstract = {{Within emerging educational technologies, we meet with the Augmented
   Reality (AR) as a methodological strategy with a great educational
   potential for the creation and production of interactive scenarios,
   dynamic and highly motivating for students. Thus, in this paper we
   present the most significant findings of a formative experience
   developed in the course ``Society, Family and Education{''} with 123
   students of the Master of Teacher Training in Compulsory Secondary
   Education, Vocational Training and Language Teaching and the specialties
   on Language and Literature, Geography and History, Health processes and
   Training and Guidance of the University of Malaga during the academic
   year 2015/2016. The methodology of the research was quantitative with
   exploratory and descriptive techniques in its first phase, and
   qualitative and interpretative, in a second phase. The questionnaire was
   administered with Survey Monkey (https://es. surveymonkey. com/home/)
   structured in a pretest that students must complete before receiving
   training sessions on the knowledge and use of augmented reality in
   education, and a post-test questionnaire that students answer after the
   teaching sesions. The objective of this experiment was to know and
   identify the students' skills and attitudes towards AR and the
   advantages that such technology could pose in education at different
   levels and subjects. Among the results obtained after the development of
   four training sessions about implementation of augmented reality tools
   using Pre-test and Post-test techniques and the development of cloud
   concepts, we found that, in general, students have a positive attitude
   towards the educational use of the AR. Results were obtained after data
   collected, firstly with the pretest, before conducting the training
   sessions about Augmented Reality applied to Education over the first two
   weeks of November, and on the other side of the posttest, made available
   to the students throughout the first two weeks of December. The number
   of students who participated in the research was 87. After the analysis,
   we can confirm how the use of emerging technologies could be an
   appropriate and useful practice for students to play an active role in
   their education and being able to develop higher order skills and
   digital competences for the implementation of AR tools from an
   educational and didactic perspective.}},
ISSN = {{1130-8656}},
EISSN = {{2340-0056}},
Unique-ID = {{ISI:000409903700019}},
}

@inproceedings{ ISI:000406804000023,
Author = {Pucihar, Klen Copic and Kljun, Matjaz and Coulton, Paul},
Editor = {{Kreps, D and Fletcher, G and Griffiths, M}},
Title = {{Using a Mobile Phone as a 2D Virtual Tracing Tool: Static Peephole vs.
   Magic Lens}},
Booktitle = {{TECHNOLOGY AND INTIMACY: CHOICE OR COERCION}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2016}},
Volume = {{474}},
Pages = {{277-288}},
Note = {{12th IFIP TC 9 International Conference on Human Choice and Computers
   (HCC), Int Federat Informat Proc Tech Comm 9, Salford, ENGLAND, SEP
   07-09, 2016}},
Organization = {{Informat \& Commun Technol Soc}},
Abstract = {{Traditional sketching aids rely on the physical production of templates
   or stencils which is particularly problematic in the case of larger
   formats. One possible solution is 2D virtual tracing using a virtual
   template to create a physical sketch. This paper evaluates a mobile
   phone as a 2D virtual tracing tool by comparing three tracing methods:
   (i) a traditional tracing method with a printed template, (ii) a virtual
   tracing method Static Peephole (SP) in which the virtual template is
   manually adjusted to a physical contour by drag and pinch gestures, and
   (iii) a virtual tracing method augmented reality Magic Lens (ML) in
   which template is projected on the physical object such as paper hence
   navigation is possible through physical movement of the mobile device.
   The results show that it is possible to use mobile phones for virtual
   tracing, however, ML only achieved comparable performance to SP mode and
   traditional methods continued to be quicker and preferred by users.}},
DOI = {{10.1007/978-3-319-44805-3\_22}},
ISSN = {{1868-4238}},
ISBN = {{978-3-319-44805-3; 978-3-319-44804-6}},
ORCID-Numbers = {{Kljun, Matjaz/0000-0002-6988-3046}},
Unique-ID = {{ISI:000406804000023}},
}

@inproceedings{ ISI:000406376400015,
Author = {Dey, Surojit and Sarkar, Pratiti},
Book-Group-Author = {{ACM}},
Title = {{Augmented Reality Based Integrated Intelligent Maintenance System For
   Production Line}},
Booktitle = {{PROCEEDINGS OF THE 8TH INDIAN CONFERENCE ON HUMAN COMPUTER INTERACTION
   (INDIA HCI 2016)}},
Year = {{2016}},
Pages = {{126-131}},
Note = {{8th Indian Conference on Human Computer Interaction (India HCI), IIT
   Bombay, Ind Design Ctr, Mumbai, INDIA, DEC 07-09, 2016}},
Organization = {{Globant; Tata Consultancy Serv; SIGCHI; Adobe; HCI Profess Assoc; Assoc
   Comp Machinery}},
Abstract = {{In a production line, the maintenance is a crucial aspect to prevent
   untimely breakdown as it might lead to decrease in productivity and huge
   financial losses. This paper presents a concept to develop an integrated
   intelligent maintenance system for the production line which works when
   incorporated with an Augmented Reality (AR) device. The overall system
   will be integrated with the Internet of Things (IoT) for rapid access to
   varied and arranged information on the AR device. This will provide
   quick assistance to the users and help in reducing their cognitive load
   which will in turn help in decreasing the time of maintenance as well as
   the overall working time of production line.}},
DOI = {{10.1145/3014362.3014377}},
ISBN = {{978-1-4503-4863-8}},
Unique-ID = {{ISI:000406376400015}},
}

@inproceedings{ ISI:000402634701058,
Author = {Yang, Yoonsik and Shim, Jinwook and Chae, Seungho and Han, Tack-Don},
Book-Group-Author = {{IEEE}},
Title = {{Interactive Augmented Reality Authoring System using Mobile Device as
   Input Method}},
Booktitle = {{2016 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)}},
Series = {{IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings}},
Year = {{2016}},
Pages = {{1429-1432}},
Note = {{IEEE International Conference on Systems, Man, and Cybernetics (SMC),
   Budapest, HUNGARY, OCT 09-12, 2016}},
Organization = {{IEEE}},
Abstract = {{The proposed system is a user-friendly interactive Augmented Reality
   Authoring System, which is for users with basic knowledge of augmented
   reality or without programming skills. The user can wear the
   head-mounted display and easily create AR content by using sensors on
   mobile devices. The user can also directly apply a variety of methods to
   interact with the AR content. Interaction with the AR content is enabled
   by using the user's hand, which is recognized by the camera attached to
   the HMD, and the mobile device's sensor data. In order to evaluate the
   effectiveness of the proposed system, a system prototype was presented
   to users. A usability test was conducted with regard to AR content
   production and interactive tasks.}},
ISSN = {{1062-922X}},
ISBN = {{978-1-5090-1897-0}},
Unique-ID = {{ISI:000402634701058}},
}

@inproceedings{ ISI:000402738404101,
Author = {Petruse, R. E. and Bondrea, I.},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{AUGMENTED REALITY AIDED PRODUCT LIFE CYCLE MANAGEMENT COLLABORATIVE
   PLATFORM}},
Booktitle = {{INTED2016: 10TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT
   CONFERENCE}},
Series = {{INTED Proceedings}},
Year = {{2016}},
Pages = {{4652-4659}},
Note = {{10th International Technology, Education and Development Conference
   (INTED), Valencia, SPAIN, MAR 07-09, 2016}},
Abstract = {{The purpose of this research is to identify how to better handle the new
   trends in collaborative production and to understand how to improve the
   efficiency of a distributed virtual team. In order to achieve these
   goals, a cloud-based collaborative manufacturing platform was developed,
   for educational purposes. This platform, intends to simulate the entire
   product life cycle, in a virtual environment, combining the latest
   software tools available on the market. The collaborative product
   development platform is divided in 12 stages based on the product life
   cycle management (PLM) steps. It starts from a market study that leads
   to the concept creation, reverse engineering and product design. The
   next phase involves virtual testing and virtual manufacturing for the
   previously designed product. After these simulations the platform leads
   to rapid prototyping (3D printing) and a physical inspection of the 3D
   printed product. The final stages of the platform are marketing, client
   feedback, recycle and improvement. In order to improve the collaborative
   working environment, augmented reality is applied for almost all the
   stages of the platform, starting from the ``concept creation{''} to the
   ``marketing{''} stage. The augmented reality used consists in 3D CAD
   models or other digital information superimposed over environment. This
   collaborative platform is used by groups of students (which simulate a
   geographically dispersed virtual team) to develop new products using the
   PLM steps.}},
ISSN = {{2340-1079}},
ISBN = {{978-84-608-5617-7}},
Unique-ID = {{ISI:000402738404101}},
}

@inproceedings{ ISI:000401904700019,
Author = {Barreiros, Carla and Veas, Eduardo and Pammer-Schindler, Viktoria},
Editor = {{Veas, E and Langlotz, T and Martinezcarranza, J and Grasset, R and Sugimoto, M and Martin, A}},
Title = {{Pre-attentive Features in Natural Augmented Reality Visualizations}},
Booktitle = {{ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)}},
Year = {{2016}},
Pages = {{72-73}},
Note = {{15th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR-Adjunct), Merida, MEXICO, SEP 19-23, 2016}},
Organization = {{IEEE; IEEE Comp Soc; DAQRI; ARTOOLKIT; Off Naval Res; Off Naval Res, Sci
   \& Technol; Vuforia; Intel; Envrmnt; PREFIXA; fayteq}},
Abstract = {{The movement towards cyberphysical systems and Industry 4.0 promises to
   imbue each and every stage of production with a myriad of sensors. The
   open question is how people are to comprehend and interact with data
   originating from industrial machinery. We propose a metaphor that
   compares machines with natural beings that appeal to people by
   representing machine states with patterns occurring in nature. Our
   approach uses augmented reality (AR) to represent machine states as
   trees of different shapes and colors (BioAR). We performed a study on
   pre-attentive processing of visual features in AR to determine if our
   BioAR metaphor conveys fast changes unambiguously and accurately. Our
   results indicate that the visual features in our BioAR metaphor are
   processed pre-attentively. In contrast to previous research, for the
   BioAR metaphor, variations in form induced less errors than variations
   in hue in the target detection task.}},
DOI = {{10.1109/ISMAR-Adjunct.2016.36}},
ISBN = {{978-1-5090-3740-7}},
ORCID-Numbers = {{Pammer-Schindler, Viktoria/0000-0001-7061-8947}},
Unique-ID = {{ISI:000401904700019}},
}

@inproceedings{ ISI:000401904700023,
Author = {Wiesner, Christian A. and Ruf, Mike and Sirim, Demet and Klinker, Gudrun},
Editor = {{Veas, E and Langlotz, T and Martinezcarranza, J and Grasset, R and Sugimoto, M and Martin, A}},
Title = {{Visualisation of the electronic horizon in Head-Up-Displays}},
Booktitle = {{ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)}},
Year = {{2016}},
Pages = {{87-89}},
Note = {{15th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR-Adjunct), Merida, MEXICO, SEP 19-23, 2016}},
Organization = {{IEEE; IEEE Comp Soc; DAQRI; ARTOOLKIT; Off Naval Res; Off Naval Res, Sci
   \& Technol; Vuforia; Intel; Envrmnt; PREFIXA; fayteq}},
Abstract = {{Dangerous driving situations can arise from poor visibility due to
   weather conditions or sharp turns. These situations could be prevented,
   if the driver knew about the future road course, while still being on
   the lookout for obstacles. The Head-Up-Display (HUD) helps to keep the
   driver's gaze on the road by projecting virtual information onto the
   windshield. The electronic horizon provides information about the future
   road course. The Advanced Driver Assistance Systems Interface
   Specifications (ADASIS) aims to standardise the way the electronic
   horizon is distributed amongst the different ADAS applications. Within
   this work, we combined the HUD with the electronic horizon to create a
   visualisation of the future road course in the HUD. We implemented this
   visualisation in a car prototype. The application was developed by using
   automotive standards, to show feasibility of integrating such a
   visualisation into a series-production vehicle. In future work we intend
   to investigate the change of drivers' behaviour while using this
   application with a user study.}},
DOI = {{10.1109/ISMAR-Adjunct.2016.40}},
ISBN = {{978-1-5090-3740-7}},
Unique-ID = {{ISI:000401904700023}},
}

@inproceedings{ ISI:000401904700032,
Author = {Naik, Hemal and Bahaa, Mahmoud and Tombari, Federico and Keitler, Peter
   and Navab, Nassir},
Editor = {{Veas, E and Langlotz, T and Martinezcarranza, J and Grasset, R and Sugimoto, M and Martin, A}},
Title = {{Frustration Free Pose Computation For Spatial AR Devices in Industrial
   Scenario}},
Booktitle = {{ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED
   AND AUGMENTED REALITY (ISMAR-ADJUNCT)}},
Year = {{2016}},
Pages = {{121-122}},
Note = {{15th IEEE International Symposium on Mixed and Augmented Reality
   (ISMAR-Adjunct), Merida, MEXICO, SEP 19-23, 2016}},
Organization = {{IEEE; IEEE Comp Soc; DAQRI; ARTOOLKIT; Off Naval Res; Off Naval Res, Sci
   \& Technol; Vuforia; Intel; Envrmnt; PREFIXA; fayteq}},
Abstract = {{The quest for finding the killer application for Industrial Augmented
   Reality(IAR) is still active. The existing solutions are ingenious but
   most can not be directly integrated with the existing industrial
   workflows. Generally, IAR applications require modifications in the
   industrial workflows depending on the tracking methodology. These
   modifications end up being an overhead for the users and deter them from
   using AR solutions. In this poster we propose a resourceful solution to
   achieve end-to-end workflow integration with minimum effort from the
   user end. The solution is suited for laser guided Spatial Augmented
   Reality(SAR) systems mainly preferred for industrial manufacturing
   applications. We also introduce a new concept for pose computation,
   which is inspired from existing mechanical concept of part alignment.
   The accuracy of our method is comparable to the classical marker based
   methods. The complete process of pose computation, from initialisation
   to refinement, is designed to be plug and play.}},
DOI = {{10.1109/ISMAR-Adjunct.2016.49}},
ISBN = {{978-1-5090-3740-7}},
Unique-ID = {{ISI:000401904700032}},
}

@article{ ISI:000401260300037,
Author = {Aschenbrenner, Doris and Maltry, Nicolas and Kimmel, Johannes and
   Albert, Michael and Scharnagl, Julian and Schilling, Klaus},
Title = {{ARTab - using Virtual and Augmented Reality Methods for an improved
   Situation Awareness for Telemaintenance}},
Journal = {{IFAC PAPERSONLINE}},
Year = {{2016}},
Volume = {{49}},
Number = {{30}},
Pages = {{204-209}},
Note = {{4th IFAC Symposium on Telematics Applications (TA), Porto Alwegre,
   BRAZIL, SEP 06-09, 2016}},
Organization = {{Int Federat Automat Control, Tech Comm 3 3 Telemat Control Commun
   Networks; Brazilian Automat Soc, IFAC Brazilian Natl Member Org;
   Fundacao Amparo Pesquisa RGS; Coordenacao Aperfeicoamento Pessoal Nivel
   Super; Fed Univ Rio Grande Sul, Sch Engn; Grad Program Elect Engn; Int
   Federat Automat Control, Tech Comm 1 5 Networked Syst; Int Federat
   Automat Control, Tech Comm 3 1 Comp Control; Int Federat Automat
   Control, Tech Comm 3 2 Computat Intelligence Control; Int Federat
   Automat Control, Tech Comm 4 1 Components \& Technologies Control; Int
   Federat Automat Control, Tech Comm 4 3 Robot; Int Federat Automat
   Control, Tech Comm 5 1 Mfg Plant Control; Int Federat Automat Control,
   Tech Comm 5 3 Enterprise Integrat \& Networking; Int Federat Automat
   Control, Tech Comm 7 3 Aerosp; Int Federat Automat Control, Tech Comm 7
   5 Intelligent Autonomous Vehicles; Int Federat Automat Control, Tech
   Comm 9 4 Control Educ}},
Abstract = {{In practice, remote maintenance of industrial manipulators is performed
   via telephone support. Recent research in context of Industry 4.0 or
   Industrial Internet use internet technologies and Augmented Reality to
   enhance the situation awareness of external experts. With remote
   analysis, maintenance scenarios like failure detection and optimization
   can be performed without traveling to the production site. In this
   paper, we present a mobile Augmented Reality architecture with a tablet
   PC and a high precision localization system. Remote experts can walk
   around the virtual plant to understand the production process and the
   machine context. We compare this method with other methods using virtual
   reality and video (C) 2016, IFAC ( International Federation of Automatic
   Control) Hosting by Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.ifacol.2016.11.168}},
ISSN = {{2405-8963}},
Unique-ID = {{ISI:000401260300037}},
}

@inproceedings{ ISI:000393551200023,
Author = {Maly, Ivo and Sedlacek, David and Leitao, Paulo},
Book-Group-Author = {{IEEE}},
Title = {{Augmented Reality Experiments with Industrial Robot in Industry 4.0
   Environment}},
Booktitle = {{2016 IEEE 14TH INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS
   (INDIN)}},
Series = {{IEEE International Conference on Industrial Informatics INDIN}},
Year = {{2016}},
Pages = {{176-181}},
Note = {{14th IEEE International Conference on Industrial Informatics (INDIN),
   Poitiers, FRANCE, JUL 19-21, 2016}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Ind Elect Soc; Institut P; Univ
   Poitiers; CNRS}},
Abstract = {{The role of human in the Industrie 4.0 vision is still considered as
   irreplaceable. Therefore, user interfaces of cyber-physical systems
   involved in the production automation need to be well designed and
   taking into consideration the industrial application requirements. With
   the advances in augmented and virtual reality data visualization and
   novel interaction techniques like mid-air gestures, these approaches
   seem to be suitable for integration into the industry environment. This
   paper describes the implementation of an augmented reality application
   for smart glasses with mid- air gestures and smart phone with touch
   interaction to compare and evaluate the usage of such interfaces in a
   production cell comprising an industrial robot.}},
ISSN = {{1935-4576}},
ISBN = {{978-1-5090-2870-2}},
ResearcherID-Numbers = {{Leitao, Paulo/A-8390-2011
   Sedlacek, David/C-9000-2016}},
ORCID-Numbers = {{Leitao, Paulo/0000-0002-2151-7944
   Sedlacek, David/0000-0003-0973-0248}},
Unique-ID = {{ISI:000393551200023}},
}

@inproceedings{ ISI:000392727400014,
Author = {Simonis, K. and Gloy, Y-S and Gries, T.},
Editor = {{Aumann, S and Ehrmann, A and Weber, MO}},
Title = {{INDUSTRIE 4.0-Automation in weft knitting technology}},
Booktitle = {{48TH CONFERENCE OF THE INTERNATIONAL FEDERATION OF KNITTING
   TECHNOLOGISTS (IFKT)}},
Series = {{IOP Conference Series-Materials Science and Engineering}},
Year = {{2016}},
Volume = {{141}},
Note = {{48th International Congress of the
   International-Federation-of-Knitting-Technologists (IFKT),
   Moenchengladbach, GERMANY, JUN 08-11, 2016}},
Organization = {{Int Federat Knitting Technologists}},
Abstract = {{Industry 4.0 applies to the knitting industry. Regarding the knitting
   process retrofitting activities are executed mostly manually by an
   operator on the basis on the operator's experience. In doing so, the
   knitted fabric is not necessarily produced in the most efficient way
   regarding process speed and fabric quality aspects. The knitting
   division at ITA is concentrating on project activities regarding
   automation and Industry 4.0. ITA is working on analysing the
   correspondences of the knitting process parameters and their influence
   on the fabric quality. By using e.g. the augmented reality technology,
   the operator will be supported when setting up the knitting machine in
   case of product or pattern change - or in case of an intervention when
   production errors occur. Furthermore, the RFID-Technology offers great
   possibilities to ensure information flow between sub-processes of the
   fragmented textile process chain. ITA is using RFID-chips to save yarn
   production information and connect the information to the fabric
   producing machine control. In addition, ITA is currently working on
   integrating image processing systems into the large circular knitting
   machine in order to ensure online-quality measurement of the knitted
   fabrics. This will lead to a self-optimizing and self-learning knitting
   machine.}},
DOI = {{10.1088/1757-899X/141/1/012014}},
Article-Number = {{012014}},
ISSN = {{1757-8981}},
ResearcherID-Numbers = {{Gries, Thomas/M-8206-2018}},
ORCID-Numbers = {{Gries, Thomas/0000-0002-2480-8333}},
Unique-ID = {{ISI:000392727400014}},
}

@inproceedings{ ISI:000392331500323,
Author = {Camba, Jorge D. and Bonnet De Leon, Alejandro and de la Torre, Jorge and
   Luis Saorin, Jose and Contero, Manuel},
Book-Group-Author = {{IEEE}},
Title = {{Application of Low-Cost 3D Scanning Technologies to the Development of
   Educational Augmented Reality Content}},
Booktitle = {{2016 IEEE FRONTIERS IN EDUCATION CONFERENCE (FIE)}},
Series = {{Frontiers in Education Conference}},
Year = {{2016}},
Note = {{IEEE Frontiers in Education Conference (FIE), Gannon Univ, Erie, PA, OCT
   12-15, 2016}},
Organization = {{Amer Soc Engn Educ Educ Res Methods Div; Inst Elect \& Elect Engineers
   Comp Soc; Inst Elect \& Elect Engineers Educ Soc; IEEE Comp Soc; Erie;
   Inst Elect \& Elect Engineers}},
Abstract = {{This paper builds on the authors' previous work with Augmented Reality
   (AR) technology as a tool to enhance traditional visualizations and
   facilitate the understanding of complex information. In this paper, we
   expand our previous work with AR technology by focusing on the process
   of creating custom content. Based on users' feedback, we describe and
   compare various strategies to create 3D models from real objects that
   can be subsequently integrated into augmented reality scenes.
   Specifically, we evaluate current 3D scanning technologies that are
   affordable and suitable for educational applications. We present a
   comparative analysis of low-cost 3D scanning technologies, its use,
   integration with AR, and implementation as educational tools. Factors
   considered in our study include portability, model size, resolution, and
   post production requirements.}},
ISSN = {{0190-5848}},
ISBN = {{978-1-5090-1790-4}},
Unique-ID = {{ISI:000392331500323}},
}

@inproceedings{ ISI:000392289100011,
Author = {Erdei, Timotei Istvan and Molnar, Zsolt and Husi, Geza},
Book-Group-Author = {{IEEE}},
Title = {{Robot visual and virtual control technology In industrial environment}},
Booktitle = {{2016 INTERNATIONAL SYMPOSIUM ON SMALL-SCALE INTELLIGENT MANUFACTURING
   SYSTEMS (SIMS)}},
Year = {{2016}},
Pages = {{71-75}},
Note = {{International Symposium on Small-Scale Intelligent Manufacturing Systems
   (SIMS), Narvik, NORWAY, JUN 21-24, 2016}},
Abstract = {{The application of mobile robots in production processes has become more
   significant nowadays. Several challenges arises in the 21st Century,
   these include material handling and logistics. The globalization of
   induced intralogistics (transportation within a building, such as a
   factory), is facilitated by a vast amount of, internet-equipped and
   round-the-clock remotely controlled, devices.}},
ISBN = {{978-1-5090-3074-3}},
Unique-ID = {{ISI:000392289100011}},
}

@inproceedings{ ISI:000391514400064,
Author = {Aschenbrenner, Doris and Latoschik, Marc Erich and Schilling, Klaus},
Editor = {{Spencer, SN}},
Title = {{Industrial Maintenance with Augmented Reality: Two Case Studies}},
Booktitle = {{22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST
   2016)}},
Year = {{2016}},
Pages = {{341-342}},
Note = {{22nd ACM Conference on Virtual Reality Software and Technology (VRST),
   Munich, GERMANY, NOV 02-04, 2016}},
Organization = {{ACM; ACM SIGCHI; ACM SIGGRAPH}},
Abstract = {{Remote maintenance of industrial manipulators often is performed via
   telephone support. Recent approaches in the context of the `Industry
   4.0' consider internet technologies and Augmented Reality (AR) to
   enhance situation awareness between external experts and local service
   technicians. We present two AR-based case studies: First, a mobile AR
   architecture based on optical see through glasses is used for an on-site
   local repair task. Second, a remote architecture based on a portable
   tablet PC and a high precision tracking system is used to realize an
   off-site expert access. The to-be-serviced machine is visualized inside
   of a large area similar to a machinery hall and can be inspected by the
   experts walking around this virtual plant using the tablet and
   perspectively correct rendering to understand the production process and
   the operation context. Both methods have been evaluated in first user
   studies.}},
DOI = {{10.1145/2993369.2996305}},
ISBN = {{978-1-4503-4491-3}},
Unique-ID = {{ISI:000391514400064}},
}

@inproceedings{ ISI:000391357500009,
Author = {Zakharchenko, Vladyslav and Choi, Kwang Pyo and Park, Jeong Hoon},
Editor = {{Iftekharuddin, KM and Awwal, AAS and Vazquez, MG and Marquez, A and Matin, MA}},
Title = {{Quality Metric for Spherical Panoramic Video}},
Booktitle = {{OPTICS AND PHOTONICS FOR INFORMATION PROCESSING X}},
Series = {{Proceedings of SPIE}},
Year = {{2016}},
Volume = {{9970}},
Note = {{10th Conference on Optics and Photonics for Information Processing, San
   Diego, CA, AUG 29-30, 2016}},
Organization = {{SPIE}},
Abstract = {{Virtual reality (VR)/ augmented reality (AR) applications allow users to
   view artificial content of a surrounding space simulating presence
   effect with a help of special applications or devices. Synthetic
   contents production is well known process form computer graphics domain
   and pipeline has been already fixed in the industry. However emerging
   multimedia formats for immersive entertainment applications such as
   free-viewpoint television (FTV) or spherical panoramic video require
   different approaches in content management and quality assessment. The
   international standardization on FTV has been promoted by MPEG. This
   paper is dedicated to discussion of immersive media distribution format
   and quality estimation process. Accuracy and reliability of the proposed
   objective quality estimation method had been verified with spherical
   panoramic images demonstrating good correlation results with subjective
   quality estimation held by a group of experts.}},
DOI = {{10.1117/12.2235885}},
Article-Number = {{UNSP 99700C}},
ISSN = {{0277-786X}},
ISBN = {{978-1-5106-0331-8; 978-1-5106-0332-5}},
Unique-ID = {{ISI:000391357500009}},
}

@inproceedings{ ISI:000390205300029,
Author = {Postranecky, Michal and Svitek, Miroslav},
Editor = {{Koukol, M}},
Title = {{Dynamic Social Evolution Model in Virtual City Laboratory}},
Booktitle = {{2016 SMART CITIES SYMPOSIUM PRAGUE (SCSP)}},
Year = {{2016}},
Note = {{Smart Cities Symposium Prague (SCSP), Prague, CZECH REPUBLIC, MAY 26-27,
   2016}},
Organization = {{IEEE}},
Abstract = {{The paper is proposing a framework of a dynamic social evolution model
   called SynopCity - Virtual City serving as virtual living laboratory for
   a research of topics related to smart cities. Concept of SynopCity -
   Virtual City is an application representing a model of virtual city,
   connected to a social network (www.synopcity.com) where network's
   members are acting as a citizens developing new urban developments in a
   virtual world under specific rules and regulations. It will allow
   authors of paper to study complex social behavior of all parties
   responsible for city development and decision making processes based on
   available historical data collected during this experiment of dynamic
   social evolution model development. Citizens are actively participating
   on this process along with model authorities and community
   representatives following statutes, rules and law. Authors of paper are
   also proposing an implementation of Industry 4.0 principles. The city is
   acting as an Industry 4.0 factory where all processes and relation
   between product and production are mirrored between physical factory
   networked systems and factory's virtual model.}},
ISBN = {{978-1-5090-1116-2}},
Unique-ID = {{ISI:000390205300029}},
}

@inproceedings{ ISI:000390297200040,
Author = {Obinata, Yuya and Fujii, Yusaku and Suzuki, Genta and Murase, Taichi},
Book-Group-Author = {{ACM}},
Title = {{Pose Estimation for a Cuboid with Regular Patterns in an Interactive
   Assembly-support Projection System}},
Booktitle = {{PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE
   SURFACES AND SPACES, (ISS 2016)}},
Year = {{2016}},
Pages = {{331-336}},
Note = {{ACM International Conference on Interactive Surfaces and Spaces (ISS),
   Niagara Falls, CANADA, NOV 06-09, 2016}},
Organization = {{Assoc Comp Machinery; ACM SIGCHI; Microsoft; Univ Waterloo}},
Abstract = {{Workers in factories often have to stop an operation to confirm various
   assembly instructions, for example, component numbers and/or the
   location to place a component; this is particularly the case with
   exceptional or inexperienced operations in a mixed-flow production line.
   These types of operation interruptions are one of the most significant
   factors linked to a decreasing productivity rate. In this study, we
   propose a novel method that estimates, in real time, the pose of a
   manufactured product on a production line without any augmented reality
   (AR) markers. This system projects instructions and/or component
   positions to help a worker process production information quickly. In
   this paper, we produced assembly-support system experimentally using
   projection-based AR. We develop a highly accurate object pose estimation
   method for manufactured products. The result of this experimental
   evaluation indicates that the combination of ORB and our algorithm can
   detect an object's pose more precisely than ORB only. We also develop an
   algorithm that is robust even if a part of an object is occluded by a
   worker's hand. We consider that this system helps workers understand
   instructions and component positions without the need to stop and
   confirm assembly instructions, thus enabling more efficient operation of
   tasks.}},
DOI = {{10.1145/2992154.2996776}},
ISBN = {{978-1-4503-4248-3}},
Unique-ID = {{ISI:000390297200040}},
}

@inproceedings{ ISI:000389524200134,
Author = {Peake, Ian D. and Blech, Jan Olaf and Schembri, Matthew},
Book-Group-Author = {{IEEE}},
Title = {{A Software Framework for Augmented Reality-based Support of Industrial
   Operations}},
Booktitle = {{2016 IEEE 21ST INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES AND
   FACTORY AUTOMATION (ETFA)}},
Series = {{IEEE International Conference on Emerging Technologies and Factory
   Automation-ETFA}},
Year = {{2016}},
Note = {{21st IEEE International Conference on Emerging Technologies and Factory
   Automation (ETFA), OWL Univ Appl Sci, Fraunhofer IOSB INA, Berlin,
   GERMANY, SEP 06-09, 2016}},
Organization = {{IEEE; IES; OWL Univ Appl Sci, Inst Ind Informat Technologies}},
Abstract = {{We report on work towards a software framework for augmented
   reality-based support of industrial operations. In particular, we are
   aiming at empowering mobile devices such that they are able to recognise
   different parts of production plant machinery in order to provide
   relevant information to on-site engineers. Such information may be
   retrieved from cloud-based services and may comprise partially simulated
   operations.}},
ISSN = {{1946-0740}},
ISBN = {{978-1-5090-1314-2}},
Unique-ID = {{ISI:000389524200134}},
}

@inproceedings{ ISI:000390036200041,
Author = {Fischer, Christian and Lusic, Mario and Faltus, Florian and Hornfeck,
   Ruediger and Franke, Joerg},
Editor = {{Alexopoulos, K}},
Title = {{Enabling live data controlled manual assembly processes by worker
   information system and nearfield localization system}},
Booktitle = {{5TH CIRP GLOBAL WEB CONFERENCE - RESEARCH AND INNOVATION FOR FUTURE
   PRODUCTION (CIRPE 2016)}},
Series = {{Procedia CIRP}},
Year = {{2016}},
Volume = {{55}},
Pages = {{242-247}},
Note = {{5th CIRP Global Web Conference - Research and Innovation for Future
   Production (CIRPe), Patras, GREECE, OCT 04-06, 2016}},
Organization = {{CIRP; Univ Patras, Lab Mfg Syst \& Automat}},
Abstract = {{Existing localization solutions cannot be directly integrated into
   production systems. This article describes a nearfield localization
   system which can be installed on tools due to its small dimensions. Live
   data controlled manual assembly processes are enabled. In combination
   with worker information systems, the manual assembly process can be
   supported more precisely compared to common systems. The benefits are
   shown within product-specific assembly scenarios. One benefit is
   enabling work out of sight (non-visible range) guided through a virtual
   model on a screen. Error prevention (zero-defect assembly) can be
   realized by monitoring and matching the actual position to the assembly
   location. Even without augmented reality devices, comparative 3-D
   representations of real and virtual world are feasible, supporting
   employees in mobile workshop with complex repairs. In particular,
   difficult accessibility can be easily determined when carrying out
   maintenance work by knowing the complete product structure. (C) 2016 The
   Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procir.2016.08.013}},
ISSN = {{2212-8271}},
Unique-ID = {{ISI:000390036200041}},
}

@inproceedings{ ISI:000389494900020,
Author = {Scheuermann, Constantin and Meissgeier, Felix and Bruegge, Bernd and
   Verclas, Stephan},
Editor = {{DePaolis, LT and Mongelli, A}},
Title = {{Mobile Augmented Reality Based Annotation System: A Cyber-Physical Human
   System}},
Booktitle = {{Augmented Reality, Virtual Reality, and Computer Graphics, Pt I}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2016}},
Volume = {{9768}},
Pages = {{267-280}},
Note = {{3rd International Conference on Augmented Reality, Virtual Reality and
   Computer Graphics (SALENTO AVR), Otranto, ITALY, JUN 15-18, 2016}},
Organization = {{Univ Salento, Dept Engn Innovat}},
Abstract = {{One goal of the Industry 4.0 initiative is to improve knowledge sharing
   among and within production sites. A fast and easy knowledge exchange
   can help to reduce costly down-times in factory environments. In the
   domain of automotive manufacturing, production line down-times cost in
   average about \$1.3 million per hour. Saving seconds or minutes have a
   real business impact and the reduction of such downtime costs is of
   major interest.
   In this paper we describe MARBAS, a Mobile Augmented Reality based
   Annotation System, which supports production line experts during their
   maintenance tasks. We developed MARBAS as Cyber-Physical Human System
   that enables experts to annotate a virtual representation of a real
   world scene. MARBAS uses a mobile depth sensor that can be attached to
   smart phones or tablets in combination with Instant Tracking. Experts
   can share information using our proposed system. We believe that such an
   annotation system can excel current maintenance processes by
   accelerating them.
   To identify applicable mesh registration algorithms we conducted a
   practical simulation. We used a 6 axis joint-arm robot to evaluate 7
   different ICP algorithms concerning time and accuracy. Our results show
   that PCL non-linear ICP offers best performance for our scenario.
   Additionally, we developed a vertical prototype using a mobile depth
   sensor in combination with a tablet. We could show the feasibility of
   our approach augmenting real world scenes with virtual information.}},
DOI = {{10.1007/978-3-319-40621-3\_20}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-40621-3; 978-3-319-40620-6}},
Unique-ID = {{ISI:000389494900020}},
}

@inproceedings{ ISI:000389214900150,
Author = {Yang, Yuan and Zhu, Yingzhou and Sui, Chaoqun},
Editor = {{McAnally, E and Hylind, M and Volodina, T and Zhang, Y and Solovjeva, I}},
Title = {{Study on Design and Production of Augmented Reality Work Integrated with
   Shadow Art Element}},
Booktitle = {{Proceedings of the 2016 International Conference on Arts, Design and
   Contemporary Education}},
Series = {{Advances in Social Science Education and Humanities Research}},
Year = {{2016}},
Volume = {{64}},
Pages = {{638-641}},
Note = {{2nd International Conference on Arts, Design and Contemporary Education
   (ICADCE), Moscow, RUSSIA, MAY 23-25, 2016}},
Organization = {{Russian State Specialized Acad Arts; Zhengzhou Univ, Inst Fine Arts; Int
   Sci \& Culture Ctr Acad Contacts}},
Abstract = {{This paper analyzes and studies the digital media design work produced
   based on the augmented reality technology. The work applies the shadow
   play to show the design of role, scene and action. The production
   process includes both the image production with computer software and
   the design and production of the interactive exhibition part of the work
   for the purpose of applying the representative element of the
   traditional Chinese shadow art to the augmented reality work in a
   reasonable and effective manner.}},
ISSN = {{2352-5398}},
ISBN = {{978-94-6252-211-4}},
Unique-ID = {{ISI:000389214900150}},
}

@inproceedings{ ISI:000386327700325,
Author = {Kerpen, D. and Loehrer, M. and Saggiomo, M. and Kemper, M. and Lemm, J.
   and Gloy, Y. -S},
Book-Group-Author = {{IEEE}},
Title = {{Effects of Cyber-Physical Production Systems on Human Factors in a
   Weaving Mill Implementation of Digital Working Environments based on
   Augmented reality}},
Booktitle = {{PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY
   (ICIT)}},
Year = {{2016}},
Pages = {{2094-2098}},
Note = {{IEEE International Conference on Industrial Technology (ICET), Taipei,
   TAIWAN, MAR 14-17, 2016}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Ind Elect Soc; Natl Taiwan Univ, Int
   Ctr Excellence Intelligent Robot \& Automat Res}},
Abstract = {{Smart manufacturing concepts merge modern production machinery and
   digital technologies in Cyber-Physical Production Systems (CPPS). CPPS
   consist of intelligent, real-time-capable, networked sensors and
   actuators. Operation of such advanced machinery requires substantial
   employees' skills in various qualification phases. This holds true for
   different industries, such as the German textile industry. An important
   measure that is intertwined with the implementation of advanced
   manufacturing concepts in textile production is supporting employees in
   their development of skills concerning smart manufacturing concepts. For
   this purpose, the development of Augmented reality (AR)-based assistance
   systems in connection with up-to-date textile machinery is regarded as a
   promising step towards the successful implementation of adequate,
   user-adaptable digital working environments in the textile industry. As
   the implementation of such assisted digital working environments in
   industrial organizations poses challenges, they might most adequately be
   addressed by adhering to standardized implementation procedures.}},
ISBN = {{978-1-4673-8075-1}},
Unique-ID = {{ISI:000386327700325}},
}

@inproceedings{ ISI:000382025400020,
Author = {Chandra, Natalia and Purnomo, Fredy and Ricky, Michael Yoseph and
   Leonard, Christianto and Verdian, Arvin},
Editor = {{AbouElHossein, K}},
Title = {{3D Catalogue based on Augmented Reality in Android Operating System}},
Booktitle = {{2016 7TH INTERNATIONAL CONFERENCE ON MECHANICAL, INDUSTRIAL, AND
   MANUFACTURING TECHNOLOGIES (MIMT 2016)}},
Series = {{MATEC Web of Conferences}},
Year = {{2016}},
Volume = {{54}},
Note = {{7th International Conference on Mechanical, Industrial, and
   Manufacturing Technologies (MIMT), Cape Town, SOUTH AFRICA, FEB 01-03,
   2016}},
Organization = {{IACT}},
Abstract = {{Along with the continued development of Smartphone and the era of
   globalization, human needs are increasing for technology. They continue
   to look for ways that can ease their lives and it is up to the
   explanation of the visualization that closer to the actual visualization
   and support fast, precise and clear retrieval of interactive
   information. In order to realize the visualization, augmented reality
   technology is being used. Augmented reality is a technology that uses
   camera technology to recognize real world, images, objects, and
   environments and superimposes virtual information and data onto reality
   in real time. It combines a virtual object into two or three dimensions
   in a real three-dimensional environment. By developing an application
   with augmented reality, it can help user to look more detail into a
   product and give advantages to company to save the brochure production
   cost. The development of this application is using client-side and
   server-side, where the client-side will be run on android smartphone and
   server-side using a php based web service. The goal of this paper is to
   develop a 3D catalogue that helps to depict a product in interactive
   ways with zoom, rotate, choose color, and animation features.}},
DOI = {{10.1051/matecconf/20165405002}},
Article-Number = {{05002}},
ISSN = {{2261-236X}},
ORCID-Numbers = {{Ricky, Michael Yosep/0000-0002-2828-897X}},
Unique-ID = {{ISI:000382025400020}},
}

@inproceedings{ ISI:000385289400096,
Author = {Santos, Helen de Freitas and de Souza, Wanderley Lopes and do Prado,
   Antonio Francisco and dos Santos Forghieri Pereira, Sissi Marilia},
Editor = {{Latifi, S}},
Title = {{Augmented Reality Approach for Knowledge Visualization and Production
   (ARAKVP) in Educational and Academic Management System for Courses Based
   on Active Learning Methodologies (EAMS-CBALM)}},
Booktitle = {{INFORMATION TECHNOLOGY: NEW GENERATIONS}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2016}},
Volume = {{448}},
Pages = {{1113-1123}},
Note = {{13th International Conference on Information Technology - New
   Generations (ITNG), Las Vegas, NV, APR 11-13, 2016}},
Abstract = {{The education has configured itself by the transfer of teacher's
   knowledge to the student, without the proper criticism or reflection by
   the student. Thereby, the main objective of the education, the student's
   learning, is not being achieved and it has taken people to a constant
   questioning of this traditional education and giving space to the Active
   Learning Methodologies (ALM). Such methodologies use the questioning as
   the strategy of the learning, where the student builds his own
   knowledge, by problems that given to him, making this student a being
   reflexive and critical. In recent decades Information and Communication
   Technologies (ICT) are used more and more on education, being even more
   useful when in ALM environment. In this sense, the objective of this
   paper is to present an Augmented Reality Approach for Knowledge
   Visualization and Production (ARAKVP) in Educational and Academic
   Management System for Courses based on Active Learning Methodologies
   (EAMS-CBALM).}},
DOI = {{10.1007/978-3-319-32467-8\_96}},
ISSN = {{2194-5357}},
ISBN = {{978-3-319-32467-8; 978-3-319-32466-1}},
Unique-ID = {{ISI:000385289400096}},
}

@article{ ISI:000380603200016,
Author = {Makris, Sotiris and Karagiannis, Panagiotis and Koukas, Spyridon and
   Matthaiakis, Aleksandros-Stereos},
Title = {{Augmented reality system for operator support in human-robot
   collaborative assembly}},
Journal = {{CIRP ANNALS-MANUFACTURING TECHNOLOGY}},
Year = {{2016}},
Volume = {{65}},
Number = {{1}},
Pages = {{61-64}},
Abstract = {{This paper presents the design and implementation of an augmented
   reality (AR) tool in aid of operators being in a hybrid, human and robot
   collaborative industrial environment. The system aims to provide
   production and process related information as well as to enhance the
   operators' immersion in the safety mechanisms, dictated by the
   collaborative workspace. The developed system has been integrated with a
   service based station controller, which is responsible for orchestrating
   the flow of information to the operator, according to the task execution
   status. The tool has been applied to a case study from the automotive
   sector, resulting in an enhanced operator's integration with the
   assembly process. (C) 2016 CIRP.}},
DOI = {{10.1016/j.cirp.2016.04.038}},
ISSN = {{0007-8506}},
EISSN = {{1726-0604}},
Unique-ID = {{ISI:000380603200016}},
}

@article{ ISI:000379835700008,
Author = {Yoo, Byounghyun and Ko, Heedong and Chun, Sungkuk},
Title = {{Prosumption perspectives on additive manufacturing: reconfiguration of
   consumer products with 3D printing}},
Journal = {{RAPID PROTOTYPING JOURNAL}},
Year = {{2016}},
Volume = {{22}},
Number = {{4}},
Pages = {{691-705}},
Abstract = {{Purpose - This paper aims to examine the changing backdrop of the
   consumer market in relation to three-dimensional (3D) printing,
   especially in the context of Web infrastructure that connects consumers
   and producers with unprecedented diversity and scale and Web 2.0
   user-created content in the material domain.
   Design/methodology/approach - The paper presents a conceptual
   architecture and software platform that facilitates do-it-yourself
   reconfiguration of existing products incorporating 3D printing, mobile
   3D sensor, augmented reality (AR) and Web technologies.
   Findings - This work shows that prosumer reconfiguration of consumer
   products is the major paradigm in the era of democratized production.
   The results suggest that this approach may be used in the consumer
   market to meet consumer preferences for adopting innovations without
   redundant consumption.
   Research limitations/implications - Verification of the proposed
   conceptual approach is limited to the use of household consumer
   products. A critical mass of participants and product information are
   both necessary to achieve a sustainable ecosystem from the proposed
   platform. Intellectual property issues rely on the fair use of end-user
   production in this paper.
   Social implications - The proposed approach allows users to swap out
   consumer product parts or upgrade individual modules as innovations
   emerge, extending the lifecycles of consumer products and potentially
   reducing consumer waste.
   Originality/value - There is a lack of work on facilitating the
   proliferation of practical 3D printing through prosumption in relation
   to existing consumer products. This paper's scientific contribution
   involves how 3D printing affords social manufacturing and
   consumer-oriented presumption in conjunction with mobile 3D sensor, AR,
   and Web technologies.}},
DOI = {{10.1108/RPJ-01-2015-0004}},
ISSN = {{1355-2546}},
EISSN = {{1758-7670}},
Unique-ID = {{ISI:000379835700008}},
}

@inproceedings{ ISI:000379247600063,
Author = {Michalos, George and Karagiannis, Panagiotis and Makris, Sotiris and
   Tokcalar, Onder and Chryssolouris, George},
Editor = {{Teti, R}},
Title = {{Augmented reality (AR) applications for supporting human-robot
   interactive cooperation}},
Booktitle = {{RESEARCH AND INNOVATION IN MANUFACTURING: KEY ENABLING TECHNOLOGIES FOR
   THE FACTORIES OF THE FUTURE - PROCEEDINGS OF THE 48TH CIRP CONFERENCE ON
   MANUFACTURING SYSTEMS}},
Series = {{Procedia CIRP}},
Year = {{2016}},
Volume = {{41}},
Pages = {{370-375}},
Note = {{48th CIRP International Conference on Manufacturing Systems (CIRP CMS),
   Ischia, ITALY, JUN 24-26, 2015}},
Abstract = {{The paper presents an Augmented Reality (AR) tool for supporting
   operators where humans and robots coexist in a shared industrial
   workplace. The system provides AR visualization of the assembly process,
   video and text based instructions and production status updates. The
   tool also enhances the operator's safety and acceptance of hybrid
   assembly environments through the immersion capabilities of AR
   technology. A hardware landscape including the AR equipment and markers,
   the handheld devices for user input and the network infrastructure for
   interfacing the robot and the storage database is provided. The software
   architecture for coordinating the AR tool with the assembly process and
   the data retrieval from the robot controller are also presented. The
   tool has been tested on a pilot case in the automotive sector. The
   results indicate that the approach can significantly enhance the
   operator's working conditions and their integration in the assembly
   process. (C) 2015 The Authors. Published by Elsevier B.V. This is an
   open access article under the CC BY-NC-ND license
   (http://creativecommons.org/licenses/by-nc-nd/4.0/).}},
DOI = {{10.1016/j.procir.2015.12.005}},
ISSN = {{2212-8271}},
Unique-ID = {{ISI:000379247600063}},
}

@inproceedings{ ISI:000377501300026,
Author = {Cota, Miguel and Gonzalez-Castro, Miguel and Branco, Frederico and
   Goncalves, Ramiro and Martins, Jose},
Editor = {{Mejia, J and Munoz, M and Rocha, A and CalvoManzano, J}},
Title = {{Emerging Industrial Visualization Systems: The Challenges and
   Opportunities of Virtual and Immersive Reality Technologies}},
Booktitle = {{TRENDS AND APPLICATIONS IN SOFTWARE ENGINEERING}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2016}},
Volume = {{405}},
Pages = {{305-315}},
Note = {{4th International Conference on Software Process Improvement (CIMPS),
   Autonomous Univ Sinaloa, Fac Informatic Mazatlan, Culiacan, MEXICO, OCT
   28-30, 2015}},
Abstract = {{The continuous process industry is currently facing a serious need for
   systems that allow to monitor and manage their factories. Despite the
   existing industrial visualization screens provide for a partial answer
   to the identified issue, there is a set of new technologies who might
   help on developing the existing industrial visualization systems and
   provide and improved aid to the human controllers who monitor and manage
   the production processes. The presented paper aims at not only
   delivering a serious and focused characterization on the existing
   industry visualization screens, but above all, it intends to present
   several opportunities, challenges and new perspectives for the use of
   innovative visualization technologies (such as 2.5D/3D screens,
   augmented and virtual reality) in those industries whose production
   process assumes itself as continuous. This contribute, from our
   perspective will serve as a basis for further research on the field.}},
DOI = {{10.1007/978-3-319-26285-7\_26}},
ISSN = {{2194-5357}},
ISBN = {{978-3-319-26285-7; 978-3-319-26283-3}},
ORCID-Numbers = {{Martins, Jose/0000-0002-7787-6305}},
Unique-ID = {{ISI:000377501300026}},
}

@inproceedings{ ISI:000376432200006,
Author = {Otto, Michael and Prieur, Michael and Agethen, Philipp and Rukzio,
   Enrico},
Editor = {{Soderberg, R}},
Title = {{Dual Reality for Production Verification Workshops: A Comprehensive Set
   of Virtual Methods}},
Booktitle = {{6TH CIRP CONFERENCE ON ASSEMBLY TECHNOLOGIES AND SYSTEMS (CATS)}},
Series = {{Procedia CIRP}},
Year = {{2016}},
Volume = {{44}},
Pages = {{38-43}},
Note = {{6th CIRP Conference on Assembly Technologies and Systems (CATS),
   Chalmers Univ Technol, Wingquist Lab, Gothenburg, SWEDEN, MAY 16-18,
   2016}},
Organization = {{CIRP}},
Abstract = {{In automotive industry, planning of manual assembly is getting
   ever-increasing complex, diverse and variant-rich due to ever-increasing
   market demands for more models and derivatives with shorter life-cycles.
   In order to reduce the costs for building physical prototypes before
   ramp-up processes, we present a comprehensive set of virtual and
   augmented reality methods for real-time assessments of manual assembly
   tasks used in interdisciplinary production planning workshops. This
   novel mixed reality assessment system unifies innovative interaction
   concepts with display technologies from a variety of domains.
   True-to-scale floor projections, interactive tangible tabletops,
   powerwalls and head mounted displays are used in combination with
   markerless full body motion capture and motion controller interfaces.
   Therewith, production planners in workshop situations are enabled to
   collaboratively plan and optimize station layouts, author 3D scenes and
   assess product and process related topics, such as buildability,
   reachability, assembly and disassembly routines. An in-depth evaluation
   on collaborative task performance using differing visualization
   scenarios is presented and discussed. (C) 2016 The Authors. Published by
   Elsevier B.V.}},
DOI = {{10.1016/j.procir.2016.02.140}},
ISSN = {{2212-8271}},
ORCID-Numbers = {{Otto, Michael/0000-0003-0212-0965}},
Unique-ID = {{ISI:000376432200006}},
}

@inproceedings{ ISI:000376432200020,
Author = {Li, Dan and Mattsson, Sandra and Fast-Berglund, Asa and Akerman, Magnus},
Editor = {{Soderberg, R}},
Title = {{Testing Operator Support Tools for a Global Production Strategy}},
Booktitle = {{6TH CIRP CONFERENCE ON ASSEMBLY TECHNOLOGIES AND SYSTEMS (CATS)}},
Series = {{Procedia CIRP}},
Year = {{2016}},
Volume = {{44}},
Pages = {{120-125}},
Note = {{6th CIRP Conference on Assembly Technologies and Systems (CATS),
   Chalmers Univ Technol, Wingquist Lab, Gothenburg, SWEDEN, MAY 16-18,
   2016}},
Organization = {{CIRP}},
Abstract = {{Globalisation of industry puts new demands on technologies and
   instructions to work in different time-space contexts. This paper
   examines four different support tools that can be used for different
   time-space contexts: face-to-face instructor (same time-same place),
   remote guidance with augmented reality (same time-different place),
   movie-based instructions and text-picture based instructions (different
   time-same place). Experiments of simulated product assembly were
   conducted to measure assembly time, product quality and the operators'
   subjective emotions of the support tools. In total, 46 number of tests
   were conducted. Results indicate that the different support tools have
   both advantages and disadvantages, and therefore selecting appropriate
   support tools is dependent of the situation. (C) 2016 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.procir.2016.02.089}},
ISSN = {{2212-8271}},
ORCID-Numbers = {{Fast-Berglund, Asa/0000-0002-0524-7913
   Li, Dan/0000-0003-1636-9745
   Mattsson, Sandra/0000-0001-8694-4122}},
Unique-ID = {{ISI:000376432200020}},
}

@article{ ISI:000375301300004,
Author = {Abedi, M. and Fathi, M. S. and Mirasa, A. K. and Rawai, N. M.},
Title = {{Integrated collaborative tools for precast supply chain management}},
Journal = {{SCIENTIA IRANICA}},
Year = {{2016}},
Volume = {{23}},
Number = {{2}},
Pages = {{429-448}},
Abstract = {{Precast construction projects are associated with many activities,
   numerous parties, enormous effort, and different processes. For
   effective communication, this requires delivering appropriate and
   up-to-date information to enhance collaboration and improve integration.
   The purpose of this paper is to develop the system architecture and
   prototype of Context-Aware Cloud Computing Building Information
   Modelling (CACCBIM) for precast supply chain management. The findings of
   this research are grounded on the literature of cloud computing,
   context-awareness, building information modelling, and, ultimately, the
   analysis of interviews with stakeholders in precast construction.
   Findings determine that lack of integration, improper planning and
   scheduling, poor production timing, poor coordination, lack of good
   communication among parties, wrong deliveries, and poor control and
   supervision are the major issues within the precast supply chain. These
   issues could result in adverse consequences for the objectives and
   success of the precast project. Eventually, to reduce and eliminate
   these issues, the proposed prototype will support appropriate
   deliveries, efficient monitoring, facilitation of coordination, and
   collaboration with improved communication. It is anticipated that this
   research will establish a unique perception in the precast construction
   industry, which will finally enhance its productivity, improve its
   efficiency, and maximise its effectiveness. (c) 2016 Sharif University
   of Technology. All rights reserved.}},
DOI = {{10.24200/sci.2016.2129}},
ISSN = {{1026-3098}},
Unique-ID = {{ISI:000375301300004}},
}

@inproceedings{ ISI:000436122900083,
Author = {Bodi, S. and Comes, R. and Weckenmann, A. and Popescu, S.},
Editor = {{Popescu, D}},
Title = {{ASSISTIVE AUGMENTED ENVIRONMENT IN QUALITY INSPECTION AND STATISTICAL
   PROCESS CONTROL}},
Booktitle = {{2016 INTERNATIONAL CONFERENCE ON PRODUCTION RESEARCH - REGIONAL
   CONFERENCE AFRICA, EUROPE AND THE MIDDLE EAST (ICPR-AEM 2016) AND 4TH
   INTERNATIONAL CONFERENCE ON QUALITY AND INNOVATION IN ENGINEERING AND
   MANAGEMENT (QIEM 2016)}},
Year = {{2016}},
Pages = {{493-498}},
Note = {{International Conference on Production Research - Africa, Europe and the
   Middle East (ICPR-AEM) / 4th International Conference on Quality and
   Innovation in Engineering and Management (QIEM), Cluj Napoca, ROMANIA,
   JUL 25-30, 2016}},
Organization = {{IFPR; Tech Univ Cluj Napoca; INOTEC; Bielomatik; CMIE; Tenaris Silcotub;
   IRUM}},
Abstract = {{Advancements in ICT systems brought forward progress in many fields. In
   production engineering, for example, facilitated the emergence of the
   fourth Industrial Revolution or Industry 4.0, which, among others,
   promotes the use of virtual or augmented environments in various
   industrial processes. Thus, it creates a new branch in the quality
   approach that tackles the virtual aspects of quality management,
   entitled Virtual Quality Management (vQM). In this context, this paper
   presents the implementation of an augmented reality (AR) application
   linked to a web platform, both developed to aid the workers on the
   factory floor and supervisors, to monitor and control different
   manufacturing processes. The workers are assisted throughout the
   measurement of workpieces by the application providing them with
   relevant information about the measured dimensions. The values of the
   latter ones are recorded into a database with the help of an online,
   easy to use and intuitive platform. Users with special access
   credentials can login to the web platform and generate control charts,
   histograms or bar charts that are constructed based on the values from
   the database. The purpose of these charts is to assist the supervisors
   in monitoring the processes, aiding them with information for taking the
   proper corrective or preventive actions. This approach is in line with
   the currently trending Industry 4.0 concept by making use of smart
   devices on the factory floor.}},
ISBN = {{978-606-737-180-2}},
Unique-ID = {{ISI:000436122900083}},
}

@inproceedings{ ISI:000417330202025,
Author = {Gil Ospina, L. and Cardozo, J.},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{INTERACTION DESIGN SYSTEM FOR MULTI-DIMENSION EXPERIENCE IN LEARNING
   BOTANY BY A TECHNOLOGICAL TOOL APPLICATION (APP) AND AUGMENTED REALITY}},
Booktitle = {{ICERI2016: 9TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND
   INNOVATION}},
Series = {{ICERI Proceedings}},
Year = {{2016}},
Pages = {{2120-2126}},
Note = {{9th Annual International Conference of Education, Research and
   Innovation (iCERi), Seville, SPAIN, NOV 14-16, 2016}},
Abstract = {{Currently, teaching methodologies in any field are migrating to the
   application of information and communication technology (ICT) as they
   are changing our world view and changing patterns of access to knowledge
   and interpersonal interaction. The use of interaction devices enhances
   teaching methods and reduces the time required for the appropriation of
   knowledge, allowing to instil in students an experiential learning. At
   the Universidad Nacional de Colombia, a research project was developed
   to meet through a preliminary analysis by the method of survey and field
   observation, current behaviors and methodologies for the class of
   Botany, to propose a communication system student-professor through
   technology and augmented reality mobile application. As a result of this
   analysis the opportunity to implement technologies to multi-dimension
   the experience of the class of Botany was obtained. The methodology
   applied in the development of this project is exploratory and is based
   on industrial design methods; it begins with an investigation of
   existing technologies; tests and approaches are conducted through
   surveys and user panel for preliminary analysis; the data are analysed
   to meet the needs of the student and teacher launching the design
   requirements and production to develop a conceptual proposal of
   communication and interaction, this was assessed through a survey with a
   Likert scale with 20 students in general botany, which measures the
   interaction, experience and acceptance of the application by users. The
   85\% of students passed the tool as a facilitator in class, proposing
   concepts to be communicated through; post-test tool with students, and
   an expert panel was made with 7 botanicals proficient in pedagogy
   providing contributions to the methodology and specifications in the
   information transmitted by the application. This research pretends to
   highlight the importance of contributing to a paradigm shift in the
   methodology of teaching and learning Botany, where learning is active
   and meaningful.}},
ISSN = {{2340-1095}},
ISBN = {{978-84-617-5895-1}},
Unique-ID = {{ISI:000417330202025}},
}

@inproceedings{ ISI:000417330204031,
Author = {Godejord, Beata and Gonzalez-Perez, Alicia and Figueiredo, Mauro and
   Solmaz, Arif},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{BREAKING FREE OF THE CLASSROOM: IMPLEMENTING DIGITAL MEDIA TO ENHANCE
   STUDENTS' INVOLVEMENT IN LEARNING MATHEMATICS}},
Booktitle = {{ICERI2016: 9TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND
   INNOVATION}},
Series = {{ICERI Proceedings}},
Year = {{2016}},
Pages = {{4144-4150}},
Note = {{9th Annual International Conference of Education, Research and
   Innovation (iCERi), Seville, SPAIN, NOV 14-16, 2016}},
Abstract = {{This paper is related the qualitative evaluation of the Erasmus+ project
   MILAGE ``Interactive Mathematics by implementing a Blended-Learning
   model with Augmented Reality and Game books{''}. Presented evaluation
   summarizes the first year of project realisation in selected upper
   secondary schools in Norway, Portugal and Spain. The analysis focuses on
   students' perceptions of the use of digital media for producing and
   sharing digital learning content for mathematics. The aim of the
   research is to develop an insight in students' attitudes, feelings and
   opinions on learning experience resulting from the engagement in the
   first year of the project activities, which, on the analysed stage,
   included production and sharing of videos presenting solutions to
   mathematical problems included in the curriculum for the first grade of
   upper secondary schools. These videos will be elements of a summative
   digital learning resource, which will cover curriculum in mathematics
   for upper secondary schools in the form of an e-book and an educational
   application for mobile use. To obtain perceptions on the defined area of
   interest, the involved researchers conducted focus groups with selected
   students and interpreted collected documents with the aid of
   computer-supported qualitative content analysis techniques. This article
   presents themes that emerged in the responses and seeks to outline
   discussion that would contribute to successful implementation of project
   goals in the following years of its realisation.}},
ISSN = {{2340-1095}},
ISBN = {{978-84-617-5895-1}},
Unique-ID = {{ISI:000417330204031}},
}

@inproceedings{ ISI:000417330206066,
Author = {Hobert, Sebastian and Schumann, Matthias},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{LEARNING PROCEDURAL KNOWLEDGE USING AUGMENTED REALITY APPLICATIONS ON
   SMART GLASSES - REQUIREMENTS AND CONCEPTUAL DESIGN}},
Booktitle = {{ICERI2016: 9TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND
   INNOVATION}},
Series = {{ICERI Proceedings}},
Year = {{2016}},
Pages = {{6382-6392}},
Note = {{9th Annual International Conference of Education, Research and
   Innovation (iCERi), Seville, SPAIN, NOV 14-16, 2016}},
Abstract = {{Highly skilled employees who are able to apply their procedural
   knowledge at the workplace are important for many enterprises as the
   number of knowledge and technology intensive activities increases. Thus,
   many enterprises undertake efforts to train their employees properly:
   For instance, in many industrial enterprises newly hired employees need
   to train practical tasks - like operating or repairing a production
   machine - as part of their incorporation into the job. Such learning
   scenarios usually take place directly at the workplace in a situational
   learning context (e.g. in the production hall) and hence the learning
   content is directly linked to the learners' location. This has the
   advantage that learners are able to extend their knowledge at their
   current location when they require it.
   One emerging technology which is able to support such situational
   learning scenarios is augmented reality. As augmented reality allows
   linking real world objects (like machines) with learning content, it is
   suited for imparting procedural knowledge. This is especially true if
   augmented reality is provided by smart glasses, i.e. small computers
   which are worn on the user's head. These head-mounted wearable computers
   are suited for situated learning on-the-job as these devices are able to
   present learning content to learners on a head-mounted display while
   they are executing practical tasks. In this way, smart glasses are able
   to guide learners step-by-step through tasks within working processes.
   In contrast to other technologies like smartphones or tablets, smart
   glasses have the advantage that they can be used simultaneously while
   learners perform tasks.
   Even though prior research on using augmented reality on smart glasses
   for learning procedural tasks is limited, experts anticipate that the
   technology can enhance learning processes in enterprises massively.
   Thus, the main goal of our paper is to analyze how augmented reality
   learning applications for smart glasses are able to support learners
   while practicing procedural tasks. Therefore, we conducted qualitative,
   explorative interviews with 21 domain experts from industrial
   enterprises. Based on this, we derived requirements in order to describe
   which functionalities need to be provided by augmented reality learning
   applications in order to support learners effectively. Furthermore, we
   present a conceptual design including mockups to outline how an
   application should be implemented.
   The results of our study - the identified requirements which describe
   functionalities as well as the conceptual design - can be used by both,
   practitioners and researchers: Practitioners get insights about
   advantages and potential learning scenarios of using augmented reality
   applications on smart glasses for imparting procedural knowledge.
   Researchers can use the identified requirements and the conceptual
   design as a basis for developing augmented reality learning
   applications.}},
ISSN = {{2340-1095}},
ISBN = {{978-84-617-5895-1}},
Unique-ID = {{ISI:000417330206066}},
}

@article{ ISI:000390946900009,
Author = {Cabero Almenara, Julio and Garcia Jimenez, Fernando and Barroso Osuna,
   Julio},
Title = {{Productions of learning objects production in Agumented Reality: the
   experience of SAV of the University of Seville}},
Journal = {{IJERI-INTERNATIONAL JOURNAL OF EDUCATIONAL RESEARCH AND INNOVATION}},
Year = {{2016}},
Number = {{6}},
Pages = {{110-123}},
Abstract = {{The augmentative reality (AR) appears as a technology with a few strong
   possibilities of application in the educational area. In the present
   article let's sense beforehand the results of an experience carried out
   in Secretariat of the University of Seville, for production of AR's
   objects for his application in different areas of knowledge. The study
   reveals the potential of this technology in the processes of
   education-learning, simultaneously that states the relevancy of
   institutions as the Secretariat of Audio-visual Resources in different
   tasks related to the design and production of TIC, advising and resting
   to the teachers on the correct curricular in tegration of the TIC on the
   processes of education - learning.}},
ISSN = {{2386-4303}},
ORCID-Numbers = {{Cabero Almenara, Julio/0000-0002-1133-6031}},
Unique-ID = {{ISI:000390946900009}},
}

@article{ ISI:000418824100003,
Author = {Hutchinson, Jonathon P.},
Title = {{The future of digital archive collections: Augmenting public service
   media geo-locative archives}},
Journal = {{MOBILE MEDIA \& COMMUNICATION}},
Year = {{2016}},
Volume = {{4}},
Number = {{1}},
Pages = {{37-51}},
Month = {{JAN}},
Abstract = {{During 2011, the now defunct ABC Pool (abc. net. au/pool) project
   developed an experiment that sought to combine emerging augmented
   reality (AR) technology with the archival collection of the Australian
   Broadcasting Corporation (ABC). The MyBurb project attempted to alter
   experiences of Australian suburbs by augmenting ABC archives in
   contemporary suburban environments to explore the blur between physical
   and digital spaces with its citizens. Mobile media, specifically
   geo-locative AR applications such as Layar are ``one of the most widely
   used mobile AR applications{''} (Liao \& Humphreys, 2014, p. 2) and
   challenge the sociological implications of hybrid spaces as ``{[}m]
   obile interfaces. allow users to be constantly connected to the Internet
   while walking through urban spaces{''} (de Souza e Silva, 2006, p. 261).
   The project was successfully implemented, but was rarely utilized by the
   audience it sought to engage, revealing a division between aspects of
   the ABC's remit and engaging its audience through mobile technology and
   environmental hybridity. This observation supports the cultural
   production gap Hesmondhalgh (2007) identified between the production and
   consumption of cultural goods, which I argue could be facilitated
   through technological intermediation as part of the broader concept of
   cultural intermediation (Hutchinson, 2013; Maguire \& Matthews, 2010;
   Negus, 2002). How then could cultural intermediation facilitate the
   collaborative production of cultural goods to include the affordances of
   geo-locative media while avoiding the disconnection between the MyBurb
   project and its stakeholders? The data presented within this paper
   represents 3 years of research at ABC Pool where I was embedded as the
   community manager/researcher in residence.}},
DOI = {{10.1177/2050157915590008}},
ISSN = {{2050-1579}},
EISSN = {{2050-1587}},
ORCID-Numbers = {{Hutchinson, Jonathon/0000-0001-7349-1662}},
Unique-ID = {{ISI:000418824100003}},
}

@inproceedings{ ISI:000432711500070,
Author = {Saggiomo, Marco and Loehrer, Mario and Kerpen, Daniel and Lemm,
   Jacqueline and Gloy, Yves-Simon},
Editor = {{Bui, TX and Sprague, RH}},
Title = {{Human- and Task-Centered Assistance Systems in Production Processes of
   the Textile Industry: Determination of Operator-Critical Weaving Machine
   Components for AR-Prototype Development}},
Booktitle = {{PROCEEDINGS OF THE 49TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM
   SCIENCES (HICSS 2016)}},
Series = {{Proceedings of the Annual Hawaii International Conference on System
   Sciences}},
Year = {{2016}},
Pages = {{560-568}},
Note = {{49th Hawaii International Conference on System Sciences (HICSS), Koloa,
   HI, JAN 05-08, 2016}},
Organization = {{Pacific Res Inst Informat Syst \& Management; Univ Hawaii Manoa, Shidler
   Coll Business, Dept IT Management; IBM; Provalis Res; Int Soc Serv
   Innovat Profess; Teradata; Univ Network; IEEE Comp Soc}},
Abstract = {{Smart manufacturing concepts merge modern production machinery and
   digital technologies in Cyber-Physical Systems (CPS). CPS consist of
   intelligent real-time-capable and networked sensors and actuators. The
   operation of such advanced machinery requires new and substantial skills
   in employees in various qualification phases. Successful implementation
   strategies take these varying skills of the workforce, which result from
   diverse cultural, educational, age- or gender-related socio-demographic
   variables, into account. Thus, the need for a differential-dynamic job
   design in textile production seems more relevant than ever, especially
   regarding the increasing number of older employees due to demographic
   changes in high-wage countries,. An important measure that is
   intertwined with the implementation of advanced manufacturing concepts
   in textile production is supporting employees in their development of
   skills concerning these new production methods. For this purpose, the
   development of Augmented reality-based assistance systems in connection
   with up-to-date textile machinery is regarded as a promising step
   towards the successful implementation of adequate, user-adaptable
   Cyber-Physical Systems.}},
DOI = {{10.1109/HICSS.2016.76}},
ISSN = {{1060-3425}},
ISBN = {{978-0-7695-5670-3}},
Unique-ID = {{ISI:000432711500070}},
}

@article{ ISI:000364737600003,
Author = {Leszczynski, Agnieszka},
Title = {{Spatial media/tion}},
Journal = {{PROGRESS IN HUMAN GEOGRAPHY}},
Year = {{2015}},
Volume = {{39}},
Number = {{6}},
Pages = {{729-751}},
Month = {{DEC}},
Abstract = {{This paper builds on the designation of networked spatial information
   technologies (both hardware/software objects and information artifacts)
   as spatial media' to advance media as an epistemology for engaging these
   presences as both channels for content and as cultural apparatuses.
   Doing so directly asserts their materiality as coincident with (new)
   media techno-cultural productions. This allows for a theory of mediation
   that belies narratives of virtual'-real' spatial hybrids by instead
   understanding spatiality (as the nexus of material
   socio-spatio-technical relations) as always-already mediated - i.e. as
   the ontogenetic effects of the contingent, necessarily incomplete
   comings-together of technical presences, persons, and space/place.}},
DOI = {{10.1177/0309132514558443}},
ISSN = {{0309-1325}},
EISSN = {{1477-0288}},
ORCID-Numbers = {{Leszczynski, Agnieszka/0000-0002-5167-0499}},
Unique-ID = {{ISI:000364737600003}},
}

@article{ ISI:000360892400003,
Author = {Wang, Wenyi and Zhao, Jiying},
Title = {{Robust Image Chroma-Keying: A Quadmap Approach Based on Global Sampling
   and Local Affinity}},
Journal = {{IEEE TRANSACTIONS ON BROADCASTING}},
Year = {{2015}},
Volume = {{61}},
Number = {{3}},
Pages = {{356-366}},
Month = {{SEP}},
Abstract = {{Chroma-keying is a technique used to replace solid-colored background of
   images or video frames. This technique is widely used in TV
   broadcasting, film production, augmented reality, and virtual
   environment. This paper proposes a new chroma-keying method, which can
   automatically remove the background color in an image and accurately
   segment the foreground objects along with their transparency property.
   Compared to conventional chroma-keying methods based on color
   clustering, color difference, or thresholding, the proposed method
   analyzes the color statistics and color confidence of the image in
   global range. By analyzing image color statistics, local lightness
   variation, and experience from human visual perception in HSV color
   space, a segmentation map called quadmap is automatically generated to
   segment the image into four types of regions: 1) foreground; 2)
   background; 3) transparent; and 4) reflective regions. By using quadmap,
   the proposed chroma-keying system can differentiate between transparent
   and reflective regions. This has always been a challenging problem in
   conventional chroma-keying or a matting systems. This improvement
   generates more reliable foreground colors in reflective regions. As a
   result, there can be less constrains for foreground scene used in
   TV-broadcasting or film making. The procedures of the proposed method
   consist of the following five steps: 1) background region detection
   based on color statistics and local lightness variation; 2) absolute
   foreground region detection based on the knowledge of background color
   and predefined thresholds in Hue channel of HSV color space; 3)
   reflective region detection based on experience from human visual
   system; 4) background color propagation based on Laplacian equation; and
   5) transparency value and foreground color estimation based on global
   sampling and color confidence.}},
DOI = {{10.1109/TBC.2015.2419181}},
ISSN = {{0018-9316}},
EISSN = {{1557-9611}},
Unique-ID = {{ISI:000360892400003}},
}

@article{ ISI:000357626800038,
Author = {Fernandez, Pablo S. and Gomes, Janaina Fernandes and Angelucci, Camilo
   A. and Tereshchuk, Polina and Martins, Caue A. and Camara, Giuseppe A.
   and Martins, Maria E. and Da Silva, Juarez L. F. and Tremiliosi-Filho,
   Germano},
Title = {{Establishing a Link between Well-Ordered Pt(100) Surfaces and Real
   Systems: How Do Random Superficial Defects Influence the
   Electro-oxidation of Glycerol?}},
Journal = {{ACS CATALYSIS}},
Year = {{2015}},
Volume = {{5}},
Number = {{7}},
Pages = {{4227-4236}},
Month = {{JUL}},
Abstract = {{Glycerol (GlOH) accumulation and its very low price constitute a real
   problem for the biodiesel industry. To overcome these problems, it is
   imperative to find new GlOH applications. In this context,
   electrochemistry arises as an important alternative to the production of
   energy or fine chemicals using GlOH as a reactant. To make these
   opportunities a reality, it is fundamentally necessary to understand how
   the glycerol electro-oxidation reaction (GEOR) occurs on catalysts used
   in real systems. Thus, research using model surfaces has generated the
   first insight into the electrochemistry of extremely complex real
   catalysts. Accordingly, in this work, we generate Pt(100) disturbed
   surfaces in a reproducible manner, carefully controlling the surface
   defect density. Then, GEOR is studied on well-ordered Pt(100) and on the
   disturbed Pt(100) surfaces in 0.5 M H2SO4 using cyclic voltammetry (CV)
   and in situ Fourier transform infrared spectroscopy (FTIR). The CV
   profile of GEOR consists of a single peak in the positive scan. The
   onset reaction displays the influence of defects present on the surface.
   On a surface with a high degree of disorder, the main GlOH oxidation
   process begins at 0.8 V vs RHE, whereas for well-ordered Pt(100), it
   starts 0.1 V earlier. FTIR experiments show the presence of carbon
   monoxide and carbonyl absorption bands. The electrochemical and
   spectroelectrochemical results are supported by density functional
   theory calculations showing that both CO and GlOH bind more strongly on
   disturbed than on well-ordered surfaces. Thus, our experiments show that
   Pt-CO (or other GlOH residue) bond breaking may be the GEOR
   rate-determining step.}},
DOI = {{10.1021/acscatal.5b00451}},
ISSN = {{2155-5435}},
ResearcherID-Numbers = {{Camara, Giuseppe/G-2247-2011
   Fernandez, Pablo/B-8066-2014
   Martins, Caue/L-9387-2013
   Da Silva, Juarez L. F./D-1779-2011
   Fernandes Gomes, Janaina/C-1224-2013
   Tremiliosi-Filho, Germano/D-6684-2012
   Angelucci, Camilo/F-2884-2012}},
ORCID-Numbers = {{Martins, Caue/0000-0003-3634-0624
   Da Silva, Juarez L. F./0000-0003-0645-8760
   Fernandes Gomes, Janaina/0000-0002-9542-8944
   Tremiliosi-Filho, Germano/0000-0001-9162-3438
   Angelucci, Camilo/0000-0002-2891-3210}},
Unique-ID = {{ISI:000357626800038}},
}

@article{ ISI:000358151300003,
Author = {Bleser, Gabriele and Damen, Dima and Behera, Ardhendu and Hendeby,
   Gustaf and Mura, Katharina and Miezal, Markus and Gee, Andrew and
   Petersen, Nils and Macaes, Gustavo and Domingues, Hugo and Gorecky,
   Dominic and Almeida, Luis and Mayol-Cuevas, Walterio and Calway, Andrew
   and Cohn, Anthony G. and Hogg, David C. and Stricker, Didier},
Title = {{Cognitive Learning, Monitoring and Assistance of Industrial Workflows
   Using Egocentric Sensor Networks}},
Journal = {{PLOS ONE}},
Year = {{2015}},
Volume = {{10}},
Number = {{6}},
Month = {{JUN 30}},
Abstract = {{Today, the workflows that are involved in industrial assembly and
   production activities are becoming increasingly complex. To efficiently
   and safely perform these workflows is demanding on the workers, in
   particular when it comes to infrequent or repetitive tasks. This burden
   on the workers can be eased by introducing smart assistance systems.
   This article presents a scalable concept and an integrated system
   demonstrator designed for this purpose. The basic idea is to learn
   workflows from observing multiple expert operators and then transfer the
   learnt workflow models to novice users. Being entirely learning-based,
   the proposed system can be applied to various tasks and domains. The
   above idea has been realized in a prototype, which combines components
   pushing the state of the art of hardware and software designed with
   interoperability in mind. The emphasis of this article is on the
   algorithms developed for the prototype: 1) fusion of inertial and visual
   sensor information from an on-body sensor network (BSN) to robustly
   track the user's pose in magnetically polluted environments; 2)
   learning-based computer vision algorithms to map the workspace, localize
   the sensor with respect to the workspace and capture objects, even as
   they are carried; 3) domain-independent and robust workflow recovery and
   monitoring algorithms based on spatiotemporal pairwise relations deduced
   from object and user movement with respect to the scene; and 4)
   context-sensitive augmented reality (AR) user feedback using a
   head-mounted display (HMD). A distinguishing key feature of the
   developed algorithms is that they all operate solely on data from the
   on-body sensor network and that no external instrumentation is needed.
   The feasibility of the chosen approach for the complete
   action-perception-feedback loop is demonstrated on three increasingly
   complex datasets representing manual industrial tasks. These limited
   size datasets indicate and highlight the potential of the chosen
   technology as a combined entity as well as point out limitations of the
   system.}},
DOI = {{10.1371/journal.pone.0127769}},
Article-Number = {{e0127769}},
ISSN = {{1932-6203}},
ResearcherID-Numbers = {{Hendeby, Gustaf/E-5959-2016}},
ORCID-Numbers = {{Hendeby, Gustaf/0000-0002-1971-4295}},
Unique-ID = {{ISI:000358151300003}},
}

@article{ ISI:000211266000002,
Author = {Chikumbo, Oliver and Goodman, Erik and Deb, Kalyanmoy},
Title = {{Triple Bottomline Many-Objective-Based Decision Making for a Land Use
   Management Problem}},
Journal = {{JOURNAL OF MULTI-CRITERIA DECISION ANALYSIS}},
Year = {{2015}},
Volume = {{22}},
Number = {{3-4}},
Pages = {{133-159}},
Month = {{MAY-AUG}},
Abstract = {{A land use many-objective optimization problem for a 1500-ha farm with
   315 paddocks was formulated with 14 objectives (maximizing sawlog
   production, pulpwood production, milksolids, beef, sheep meat, wool,
   carbon sequestration, water production, income and Earnings Before
   Interest and Tax; and minimizing costs, nitrate leaching, phosphorus
   loss and sedimentation). This was solved using a modified
   Reference-point-based Non-dominated Sorting Genetic Algorithm II
   augmented by simulated epigenetic operations. The search space had
   complex variable interactions and was based on economic data and several
   interoperating simulation models. The solution was an approximation of a
   Hyperspace Pareto Frontier (HPF), where each non-dominated trade-off
   point represented a set of land-use management actions taken within a
   10-year period and their related management options, spanning a planning
   period of 50 years. A trade-off analysis was achieved using Hyper-Radial
   Visualization (HRV) by collapsing the HPF into a 2-D visualization
   capability through an interactive virtual reality (VR)-based method,
   thereby facilitating intuitive selection of a sound compromise solution
   dictated by the decision makers' preferences under uncertainty
   conditions. Four scenarios of the HRV were considered emphasizing
   economic, sedimentation and nitrate leaching aspects-giving rise to a
   triple bottomline (i.e. the economic, environmental and social complex,
   where the social aspect is represented by the preferences of the various
   stakeholders). Highlights of the proposed approach are the development
   of an innovative epigenetics-based multi-objective optimizer,
   uncertainty incorporation in the search space data and decision making
   on a multi-dimensional space through a VR-simulation-based visual
   steering process controlled at its core by a multi-criterion decision
   making-based process. This approach has widespread applicability to many
   other `wicked' societal problem-solving tasks. Copyright (C) 2014 John
   Wiley \& Sons, Ltd.}},
DOI = {{10.1002/mcda.1536}},
ISSN = {{1057-9214}},
EISSN = {{1099-1360}},
ORCID-Numbers = {{Chikumbo, Oliver/0000-0002-2917-9089}},
Unique-ID = {{ISI:000211266000002}},
}

@article{ ISI:000343995000002,
Author = {Mourtzis, Dimitris and Papakostas, Nikolaos and Mavrikios, Dimitris and
   Makris, Sotiris and Alexopoulos, Kosmas},
Title = {{The role of simulation in digital manufacturing: applications and
   outlook}},
Journal = {{INTERNATIONAL JOURNAL OF COMPUTER INTEGRATED MANUFACTURING}},
Year = {{2015}},
Volume = {{28}},
Number = {{1, SI}},
Pages = {{3-24}},
Month = {{JAN 2}},
Abstract = {{Digital manufacturing technologies have been considered an essential
   part of the continuous effort towards the reduction in a product's
   development time and cost, as well as towards the expansion in
   customisation options. The simulation-based technologies constitute a
   focal point of digital manufacturing solutions, since they allow for the
   experimentation and validation of different product, process and
   manufacturing system configurations. This article investigates
   simulation-based applications in a series of different technological and
   manufacturing domains. First, this article discusses the current
   industrial practice, focusing on the use of information technology.
   Next, a series of simulation-based solutions are explored in the domains
   of product and production process design, as well as in the area of
   enterprise resource planning. The current technologies and research
   trends are discussed in the context of the new landscape of computing
   hardware technologies and the emerging computing services, including the
   initiatives comprising both the Internet cloud and the Internet of
   things.}},
DOI = {{10.1080/0951192X.2013.800234}},
ISSN = {{0951-192X}},
EISSN = {{1362-3052}},
ORCID-Numbers = {{Papakostas, Nikolaos/0000-0002-0443-221X}},
Unique-ID = {{ISI:000343995000002}},
}

@inproceedings{ ISI:000386557900120,
Author = {van der Vaart, Merel and Damala, Areti},
Editor = {{Guidi, G and Torres, JC and Scopigno, R and Graf, H and Remondino, F and Brunet, P and Barcelo, J and Duranti, L and Hazan, S}},
Title = {{Through the Loupe: Visitor Engagement With a Primarily Text-Based
   Handheld AR Application}},
Booktitle = {{2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS \&
   INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION \& STANDARDS DIGITAL
   HERITAGE PROJECTS \& APPLICATIONS}},
Year = {{2015}},
Pages = {{565-572}},
Note = {{Digital Heritage International Congress, Granada, SPAIN, SEP 28-OCT 02,
   2015}},
Organization = {{VSMM; EG; IEEE; Sociedad Espanola Arqueologia Virtual; Univ Granada;
   Innova Virtual Archaeol; Archeo Virtual; CIPA; Comp Applicat \&
   Quantitat Methods Archaeol; SPACE2PLACE; V-Must; Council Alhambra \&
   Generalife; Andalusian Regional Minist Econ \& Knowledge; Spanish Minist
   Econ \& Competitiveness; AUTODESK; IBERIA; BARCO; Viajes \& Corte
   Ingles; Escuela Tecnica Superior Ingenierias Informatica Telecomunicac;
   Oficina Software Libre; LST; Intl Campus Excellence Heritage; Sci Pk
   Museum}},
Abstract = {{The use of Augmented Reality (AR) in a museum or heritage setting holds
   great potential. However, until now, introducing AR into their buildings
   has been prohibitively expensive for most museums. On the one hand,
   programming the AR application could not be done in-house and would be
   rather costly. Secondly, the time-consuming production of high-quality
   digital visuals, often used in AR installations, needed to be
   outsourced. With the arrival of several AR engines, creating the actual
   experience has become easy, relatively fast and cheap, meaning the costs
   and skills associated with content creation might be the prime reason
   for particularly small and medium sized museums to not engage with the
   use of AR. This begs the question: Can other, simpler, types of content,
   such as texts, also be used to create a valued AR interpretation tool?
   This paper will discuss a study that has made a first attempt to
   answering this question. In addition, it explored the role AR can play
   in improving engagement between visitor, the object and its related
   information. The Loupe is a handheld AR application that was designed
   and tested as part of the meSch project. For this study, content, mainly
   consisting of text, was created for the Loupe at the Allard Pierson
   Museum. The tool was then tested with 22 participants who were asked to
   use the Loupe, either alone or together. Through questionnaires,
   observations and interviews, participants' engagement with and response
   to the Loupe were analyzed. This paper will discuss the findings of that
   study, focusing on the way the Loupe influenced the relationship between
   visitor and object, as well as the value of textual content as part of
   such an AR tool.}},
ISBN = {{978-1-5090-0048-7}},
Unique-ID = {{ISI:000386557900120}},
}

@inproceedings{ ISI:000383740303075,
Author = {Korn, Oliver and Schmidt, Albrecht},
Editor = {{Ahram, T and Karwowski, W and Schmorrow, D}},
Title = {{Gamification of business processes: Re-designing work in production and
   service industry}},
Booktitle = {{6TH INTERNATIONAL CONFERENCE ON APPLIED HUMAN FACTORS AND ERGONOMICS
   (AHFE 2015) AND THE AFFILIATED CONFERENCES, AHFE 2015}},
Series = {{Procedia Manufacturing}},
Year = {{2015}},
Volume = {{3}},
Pages = {{3424-3431}},
Note = {{6th International Conference on Applied Human Factors and Ergonomics
   (AHFE), Las Vegas, NV, JUL 26-30, 2015}},
Abstract = {{In this work we provide an overview of gamification, i.e. the
   application of methods from game design to enrich non-gaming processes.
   The contribution is divided into five subsections: an introduction
   focusing on the progression of gamification through the hype cycle in
   the recent years (1), a brief introduction to gamification mechanics (1)
   and an overview of the state of the art in established areas (3). The
   focus is a discussion of more recent attempts of gamification in service
   and production (4). We also discuss the ethical implications (5) and the
   future perspectives (6) of gamified business processes. Gamification has
   been successfully applied in the domains education (serious games) and
   health (exergames) and is spreading to other areas. In recent years
   there have been various attempts to ``gamify{''} business processes.
   While the first efforts date back as far as the collection of miles in
   frequent flyer programs, we will portray some of the more recent and
   comprehensive software-based approaches in the service industry, e.g.
   the gamification of processes in sales and marketing. We discuss their
   accomplishments as well as their social and ethical implicatio. Finally
   a very recent approach is presented: the application of gamification in
   the domain of industrial production. We discuss the special requirements
   in this domain and the effects on the business level and on the users.
   We conclude with a prognosis on the future development of gamification.
   (C) 2015 The Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.promfg.2015.07.616}},
ISSN = {{2351-9789}},
ResearcherID-Numbers = {{Korn, Oliver/G-1798-2017
   }},
ORCID-Numbers = {{Schmidt, Albrecht/0000-0003-3890-1990}},
Unique-ID = {{ISI:000383740303075}},
}

@inproceedings{ ISI:000380607300017,
Author = {Grani, Francesco and Overholt, Dan and Erkut, Cumhur and Gelineck,
   Steven and Triantafyllidis, Georgios and Nordahl, Rolf and Serafin,
   Stefania},
Editor = {{Kalliris, G and Dimoulas, C}},
Title = {{Spatial Sound and Multimodal Interaction in Immersive Environments}},
Booktitle = {{PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH
   SOUND, AM'15}},
Year = {{2015}},
Note = {{Audio Mostly (AM) Conference on Sound, Semantics and Social Interaction,
   Thessaloniki, GREECE, OCT 07-09, 2015}},
Abstract = {{Spatial sound and interactivity are key elements of investigation at the
   Sound And Music Computing master program at Aalborg University
   Copenhagen.
   We present a collection of research directions and recent results from
   work in these areas, with the focus on our multifaceted approaches to
   two primary problem areas: 1) creation of interactive spatial audio
   experiences for immersive virtual and augmented reality scenarios, and
   2) production and mixing of spatial audio for cinema, music, and other
   artistic contexts. Several ongoing research projects are described,
   wherein the latest developments are discussed.
   These include elements in which we have provided sonic interaction in
   virtual environments, interactivity with volumetric sound sources using
   VBAP and Wave Field Synthesis (WFS), and binaural sound for virtual
   environments and spatial audio mixing. We show that the variety of
   approaches presented here are necessary in order to optimize
   interactivity with spatial audio for each particular type of task.}},
DOI = {{10.1145/2814895.2814919}},
ORCID-Numbers = {{Erkut, Cumhur/0000-0003-0750-1919
   Grani, Francesco/0000-0002-0550-8191}},
Unique-ID = {{ISI:000380607300017}},
}

@inproceedings{ ISI:000380606000006,
Author = {Trottnow, Jonas and Goetz, Kai and Seibert, Stefan and Spielmann, Simon
   and Helzle, Volker and Einabadi, Farshad and Sielaff, Clemens K. H. and
   Grau, Oliver},
Book-Group-Author = {{ACM}},
Title = {{Intuitive Virtual Production Tools for Set and Light Editing}},
Booktitle = {{CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA
   PRODUCTION}},
Year = {{2015}},
Note = {{12th International Conference on Visual Media Production (CVMP), London,
   UNITED KINGDOM, NOV 24-25, 2015}},
Organization = {{Foundary; BMVA; AUTODESK; Google; YouTube; NVIDIA; Centre Digital
   Entertainment}},
Abstract = {{This contribution describes a set of newly developed tools for virtual
   production. Virtual production aims to bring together the creative
   production aspects into one real-time environment, to overcome the
   bottlenecks of offline processing in digital content production. This
   paper introduces tools and an architecture to edit set assets and adjust
   the lighting set-up. A set of tools was designed, implemented and tested
   on tablet PCs and one augmented reality and a virtual reality device.
   These tools are designed to be used on a movie set by staff not
   necessarily familiar with 3D software. Further, an approach to harmonize
   light set-ups in virtual and real scenes is introduced. This approach
   uses an automated image-based light capture process, which models the
   dominant lights as discrete light sources with fall-off characteristics
   to give required fine details for close range light set-ups and
   overcomes limitations of traditional image-based light probes. The paper
   describes initial results of a user evaluation using the developed tools
   in production-like environments.}},
DOI = {{10.1145/2824840.2824851}},
ISBN = {{978-1-4503-3560-7}},
Unique-ID = {{ISI:000380606000006}},
}

@inproceedings{ ISI:000380436600019,
Author = {Dandachi, Ghina and Assoum, Ammar and Elhassan, Bachar and Dornaika,
   Fadi},
Book-Group-Author = {{IEEE}},
Title = {{Machine Learning Schemes in Augmented Reality for Features Detection}},
Booktitle = {{2015 FIFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION AND
   COMMUNICATION TECHNOLOGY AND ITS APPLICATIONS (DICTAP)}},
Year = {{2015}},
Pages = {{101-105}},
Note = {{International Conference on Digital Information and Communication
   Technology and its Applications (DICTAP), Beirut, LEBANON, APR 29-MAY
   01, 2015}},
Abstract = {{Augmented Reality (AR) is a relatively old concept technology, which
   reached the large public very recently. We can use it to enhance our
   environments, by augmenting the image, the voice and delivering details
   and annotations about the surrounding space. Augmented reality (AR) is a
   growing field, with many diverse applications ranging from TV and film
   production, to industrial maintenance, medicine, education,
   entertainment and games. This paper presents an improved approach for
   image augmented-reality, by acting on two axes in the augmented reality
   process. First, a machine learning step is added to the detection part.
   Second, the registration of augmented image is processed by using the
   following techniques: statistical appearance models, and covariance
   matrices of dense image descriptors. A tuning of the used techniques and
   algorithms will be done in order to obtain a reliable and real-time
   image augmentation. We give a detailed description on how we chose the
   methods, and we compare our approach with other methods used in this
   domain. Finally, an evaluation of the proposed technique is presented as
   well as a performance study for a given use case.}},
ISBN = {{978-1-4799-4129-2}},
Unique-ID = {{ISI:000380436600019}},
}

@inproceedings{ ISI:000380459800014,
Author = {Patel, Jigna and Fluet, Gerard and Merians, Alma and Qiu, Qinyin and
   Yarossi, Matthew and Adamovich, Sergei and Tunik, Eugene and Massood,
   Supriya},
Book-Group-Author = {{IEEE}},
Title = {{Virtual reality-augmented rehabilitation in the acute phase post-stroke
   for individuals with flaccid upper extremities: A feasibility study}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS
   (ICVR)}},
Year = {{2015}},
Pages = {{215-223}},
Note = {{International Conference on Virtual Rehabilitation Proceedings (ICVR),
   Valencia, SPAIN, JUN 09-12, 2015}},
Organization = {{Bright Cloud Int}},
Abstract = {{Rehabilitation of individuals with flaccid or severely affected upper
   extremities is challenging due to their limited motor ability and few
   options for therapeutic training. This initial study tested the
   feasibility of training individuals with severe hemiparesis using
   virtual reality (VR) based mirrored feedback and pinch force modulation
   tasks. The results demonstrated that the simulations were well tolerated
   early after stroke. Priming effects of the mirror tasks were suggested
   by increased maximal pinch force immediately after training.
   Furthermore, despite having no clinically observable movement distally,
   the subjects were able to consciously activate their muscles as shown by
   force traces and EMG recorded during the pinch trace task. Motor
   learning was also suggested by the decrease in Root Mean Square Error
   (RMSE) during this task. Lastly the benefits of using objective,
   technology based measurement tools was demonstrated by the ability of
   the force sensor to detect small changes in force production that could
   not be measured with a clinical scale of impairment.}},
ISBN = {{978-1-4799-8984-3}},
Unique-ID = {{ISI:000380459800014}},
}

@inproceedings{ ISI:000380462500017,
Author = {Artut, Selcuk},
Editor = {{Brooks, AL and Ayiter, E and Yazicigil, O}},
Title = {{Augmented Sculptures: What You See is not What You See}},
Booktitle = {{ARTS AND TECHNOLOGY}},
Series = {{Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering}},
Year = {{2015}},
Volume = {{145}},
Pages = {{144-152}},
Note = {{4th International Conference on Arts and Technology (ArtsIT), Istanbul,
   TURKEY, NOV 10-12, 2014}},
Organization = {{Sabanci Univ, Commun Ctr}},
Abstract = {{The idea of Augmented Reality Technologies enhances our ability to
   perceive a location with additional 3D visual elements. A point of
   interest becomes meta-constructed with addition of extended layers via
   augmented space elements. Augmented Reality presents us a virtually
   enriched version of a visually noticeable reality world which already
   exists and can easily be seen. In this article, in addition to
   questioning the representative existence of the art object in the work
   of art called ``What You See is not What You See{''} which is created by
   Augmented Reality technique, the methods being followed for Augmented
   Reality production technique are examined in details.}},
DOI = {{10.1007/978-3-319-18836-2\_17}},
ISSN = {{1867-8211}},
ISBN = {{978-3-319-18836-2; 978-3-319-18835-5}},
Unique-ID = {{ISI:000380462500017}},
}

@inproceedings{ ISI:000379159000019,
Author = {Plinta, Dariusz and Krajcovic, Martin},
Editor = {{Szewczyk, R and Zielinski, C and Kaliczynska, M}},
Title = {{Production System Designing with the Use of Digital Factory and
   Augmented Reality Technologies}},
Booktitle = {{PROGRESS IN AUTOMATION, ROBOTICS AND MEASURING TECHNIQUES: CONTROL AND
   AUTOMATION}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2015}},
Volume = {{350}},
Pages = {{187-196}},
Note = {{International Conference on Automation, Warsaw, POLAND, MAR 18-20, 2015}},
Abstract = {{Current requirements for continuous reduction of products, processes and
   systems life cycles increase the need of rapid design of ``lean{''} and
   ``flexible{''} production systems. This means that classical approaches
   of production systems design have to be extended by the application of
   advanced technologies and methods, such as digital factory, virtual and
   augmented reality, computer simulation, reverse engineering, etc. The
   article describes design, optimization and visualization of the
   production layout using a combination of conventional design approaches
   and modern computer technologies, like VisTable software and augmented
   reality.}},
DOI = {{10.1007/978-3-319-15796-2\_19}},
ISSN = {{2194-5357}},
ISBN = {{978-3-319-15796-2; 978-3-319-15795-5}},
Unique-ID = {{ISI:000379159000019}},
}

@inproceedings{ ISI:000378564800187,
Author = {Flatt, Holger and Koch, Nils and Roecker, Carsten and Guenter, Andrei
   and Jasperneite, Juergen},
Book-Group-Author = {{IEEE}},
Title = {{A Context-Aware Assistance System for Maintenance Applications in Smart
   Factories based on Augmented Reality and Indoor Localization}},
Booktitle = {{PROCEEDINGS OF 2015 IEEE 20TH CONFERENCE ON EMERGING TECHNOLOGIES \&
   FACTORY AUTOMATION (ETFA)}},
Series = {{IEEE International Conference on Emerging Technologies and Factory
   Automation-ETFA}},
Year = {{2015}},
Note = {{20th IEEE Conference on Emerging Technologies and Factory Automation
   (ETFA), Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil \& Trust,
   LUXEMBOURG, SEP 08-11, 2015}},
Organization = {{IEEE; IEEE Ind Elect Soc}},
Abstract = {{The term Industrie 4.0 carries the vision of smart factories, which
   automatically adapt to changes and assist the human as much as possible
   during operation and maintenance. This includes smart human machine
   interfaces, which reduce the chances of errors and help to make the
   right decisions. This paper presents an approach to equip the
   maintenance software running on a tablet PC with augmented reality
   functionality to be able to place virtual sticky notes at production
   modules. Additionally, these sticky notes are enriched with position
   information. The central element of this approach is an ontology-based
   context aware framework, which aggregates and processes data from
   different sources. As a result, a tablet PC application was implemented,
   which allows displaying maintenance information as well as live plant
   process data in the form of augmented reality. More than 100 of those
   sticky notes can be placed using this system, whereas each note requires
   a file size of 12 to 16 kilo bytes. After placing a sticky note, the
   system recognizes it even if the camera's position is not exactly the
   same as during the placing process.}},
ISSN = {{1946-0740}},
ISBN = {{978-1-4673-7929-8}},
Unique-ID = {{ISI:000378564800187}},
}

@inproceedings{ ISI:000376685701122,
Author = {Hobert, Sebastian and Decker, Jasmin and Schumann, Matthias},
Editor = {{GomezChova, L and LopezMartinez, A and CandelTorres, I}},
Title = {{SUPPORTING SITUATED LEARNING ON THE JOB IN INDUSTRIAL PRODUCTION
   FACILITIES USING AUGMENTED REALITY LEARNING ON WEARABLE COMPUTERS}},
Booktitle = {{EDULEARN15: 7TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES}},
Series = {{EDULEARN Proceedings}},
Year = {{2015}},
Pages = {{1796-1805}},
Note = {{7th International Conference on Education and New Learning Technologies
   (EDULEARN), Barcelona, SPAIN, JUL 06-08, 2015}},
Abstract = {{As a result of the demographic change-especially in Europe-companies are
   facing challenges to retain the employees' empirical knowledge within
   the company. In addition to that, continuous learning is required in
   many working areas to be able to deal with constant technological
   improvements. This is especially important for companies in the
   high-tech sector, in which employees are dealing with state of the art
   technologies. As an example, employees in industrial production
   facilities (like in the car industry) need to improve their skills
   whenever new components are added to the manufacturing process.
   Therefore, they can hugely benefit from learning on the job.
   Learning on the job while working in a production facility allows
   employees to extend their knowledge at the same time and at their
   current location when they require it. This usually takes place in a
   situational context, i.e. the context of the learner is related to the
   learning content. An example for situated learning on the job in
   manufacturing is an industrial mechanic who looks up instructions for
   the next production step. In contrast to off-the-job training the
   learning content is adjusted to the learner's current context.
   Augmented reality learning is one solution which can be used to enable
   situated learning on the job. This can be achieved by the use of
   wearable computers (wearables). As wearables are worn by the user and as
   such portable, always operational and allow a hands-free use, they can
   be used by employees in many situations when learning content is
   required. Furthermore, wearables can analyze the environment and its'
   surrounding context using build-in sensors (like GPS and Bluetooth for
   localization or image sensors for pattern matching) to provide
   situational learning content. This could even be done proactively, i.e.
   the wearable notifies the employee about relevant learning materials on
   its own.
   The main goal of this paper is to determine how learning in
   manufacturing companies can be supported using augmented reality
   learning on wearables. Therefore, we will first focus on identifying
   application scenarios in industrial production facilities which can
   benefit from using augmented reality learning to enhance the employees'
   skills on the job. Besides the identification of scenarios, we present a
   prototype for smart glasses which is targeted at employees in industrial
   production facilities for supporting learning on the job. It can be used
   for displaying learning content which is linked to real objects or
   locations using Bluetooth low energy. The prototype is developed for
   running natively on Google Glass.
   The results of this paper-the identified applications scenarios and the
   developed prototype-can be used as a basis for further research and for
   developing and deploying augmented reality learning applications in
   companies.}},
ISSN = {{2340-1117}},
ISBN = {{978-84-606-8243-1}},
Unique-ID = {{ISI:000376685701122}},
}

@inproceedings{ ISI:000377404100028,
Author = {Buyer, Sven and Wittenberg, Carsten},
Editor = {{Stephanidis, C}},
Title = {{AR and Maintenance - Visualization of Process Data and Engineering
   Information}},
Booktitle = {{HCI INTERNATIONAL 2015 - POSTERS' EXTENDED ABSTRACTS, PT I}},
Series = {{Communications in Computer and Information Science}},
Year = {{2015}},
Volume = {{528}},
Pages = {{159-162}},
Note = {{2nd International Conference on Learning and Collaboration Technologies
   / 17th International Conference on Human-Computer Interaction, Los
   Angeles, CA, AUG 02-07, 2015}},
Abstract = {{Nowadays the trend in the industry is to centralize production systems.
   For example almost autonomous power plants will be spread over the
   regions. In case of malfunctions the maintenance staff has to react very
   fast to reduce downtimes and costs. Based on a user analysis, different
   requirements such as fast information gathering and straightforward
   handling have been determined. Required documents are often spread
   across the company. This leads to time-intensive searching and
   obtaining. Modern technologies like Augmented Reality (AR) can support
   the staff. AR-applications have great potential for practical use,
   however, essential parts of today's popular desktop-based interaction
   concepts have to be redesigned. Computer games provide solutions for
   presenting complex information in a way that is easy to understand.
   Anforderungen an AR-Anwendungen in der Instandhaltung.}},
DOI = {{10.1007/978-3-319-21380-4\_28}},
ISSN = {{1865-0929}},
ISBN = {{978-3-319-21380-4; 978-3-319-21379-8}},
Unique-ID = {{ISI:000377404100028}},
}

@article{ ISI:000375789200005,
Author = {Boccara, Vincent and Delgoulet, Catherine},
Title = {{A works analysis approach for designing professional training.
   Contribution of ergonomics in orienting the upstream design of a virtual
   reality environment}},
Journal = {{ACTIVITES-REVUE ELECTRONIQUE}},
Year = {{2015}},
Volume = {{12}},
Number = {{2}},
Pages = {{73-97}},
Abstract = {{The aim of this article is to present and discuss a work analysis
   approach. This approach was developed within the context of a design
   project aiming to build a virtual environment for training (VET) workers
   involved in the assembly of aircraft parts. The frameworks of ergonomics
   and professional didactics served as a background for this study which
   took place in three stages: 1) an analysis of both demand and project,
   2) work analysis (trainers, trainees and production unit workers, and 3)
   a co-analysis device to co-analyse with trainers the work knowledge and
   its transmission. During the study, the focal point of work analysis,
   the people concerned and the results produced by ergonomists all evolved
   and became more complex. Using reflection on our own ergonomic practice,
   we discuss the benefits of work analysis as a means of identifying the
   wide range of training situations and of taking part in design projects.}},
ISSN = {{1765-2723}},
Unique-ID = {{ISI:000375789200005}},
}

@inproceedings{ ISI:000371977802013,
Author = {Furch, Johannes and Hilsmann, Anna and Eisert, Peter},
Book-Group-Author = {{IEEE}},
Title = {{A FRAMEWORK FOR IMAGE-BASED ASSET GENERATION AND ANIMATION}},
Booktitle = {{2015 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)}},
Series = {{IEEE International Conference on Image Processing ICIP}},
Year = {{2015}},
Pages = {{1950-1954}},
Note = {{IEEE International Conference on Image Processing (ICIP), Quebec City,
   CANADA, SEP 27-30, 2015}},
Organization = {{Inst Elect \& Elect Engineers; IEEE Signal Proc Soc}},
Abstract = {{Creating digital animatable models of real-world objects and characters
   is important for many applications, ranging from highly expensive movie
   productions to low-cost real-time applications like computer games and
   augmented reality. However, achieving real photorealism with convincing
   appearance and deformation behavior requires sophisticated capturing,
   elaborate manual modeling and time-consuming simulation. This can only
   be achieved in well funded film productions, while in low-cost
   applications, animated objects usually lack visual quality. In this
   paper, we present a new framework for image-based animatable asset
   generation which avoids these time-consuming processes both in the
   modeling and the simulation stage. Real-time photo-realistic animation
   is enabled by the use of captured images and shifting computational
   complexity to an a-priori training phase. Our paper covers the complete
   pipeline of content creation, asset generation and representation, and a
   real-time animation and rendering implementation.}},
ISSN = {{1522-4880}},
ISBN = {{978-1-4799-8339-1}},
ORCID-Numbers = {{Eisert, Peter/0000-0001-8378-4805}},
Unique-ID = {{ISI:000371977802013}},
}

@inproceedings{ ISI:000371986600029,
Author = {St Clair, Aaron and Mataric, Maja},
Book-Group-Author = {{ACM}},
Title = {{How Robot Verbal Feedback Can Improve Team Performance in Human-Robot
   Task Collaborations}},
Booktitle = {{PROCEEDINGS OF THE 2015 ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT
   INTERACTION (HRI'15)}},
Series = {{ACMIEEE International Conference on Human-Robot Interaction}},
Year = {{2015}},
Pages = {{213-220}},
Note = {{10th Annual ACM/IEEE International Conference on Human-Robot Interaction
   (HRI), Portland, OR, MAR 02-05, 2015}},
Organization = {{IEEE; ACM; ACM SIGCHI; ACM SIGART; IEEE Robot \& Automat Soc; AAAI;
   HFES; ACM SIGAI}},
Abstract = {{We detail an approach to planning effective verbal feedback during
   pairwise human-robot task collaboration. The approach is motivated by
   social science literature as well as existing work in robotics and is
   applicable to a variety of task scenarios. It consists of a dynamic,
   synthetic task implemented in an augmented reality environment. The
   result is combined robot task control and speech production, allowing
   the robot to actively participate and communicate with its teammate. A
   user study was conducted to experimentally validate the efficacy of the
   approach on a task in which a single user collaborates with an
   autonomous robot. The results demonstrate that the approach is capable
   of improving both objective measures of team performance and the user's
   subjective evaluation of both the task and the robot as a teammate.}},
DOI = {{10.1145/2696454.2696491}},
ISSN = {{2167-2121}},
ISBN = {{978-1-4503-2882-1}},
Unique-ID = {{ISI:000371986600029}},
}

@inproceedings{ ISI:000370943500011,
Author = {Olmedo, Hector and Olalde, Karle and Garcia, Benat},
Editor = {{GonzalezMendivil, E and Flores, PGR and Gutierrez, JM and Ginters, E}},
Title = {{MotoStudent and the Web3D}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE VIRTUAL AND AUGMENTED REALITY IN EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2015}},
Volume = {{75}},
Pages = {{84-94}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Tecnologico Monterrey, Campus Monterrey, Monterrey, MEXICO, NOV
   19-21, 2015}},
Organization = {{Univ La Laguna, Tecnologico Monterrey; Univ Appl Sci, Sociotechn Syst
   Engn Inst Vidzeme}},
Abstract = {{In the field of engineering, the best results can be obtained if we are
   able to interact with our models. Customers generally want to interact
   with models or designs for new products, so we are developing various
   alternatives for visualization, such as Virtual and Augmented Realities
   based on accurate models with no need of using specific software. In
   order to have a better and global knowledge of the various
   possibilities, in this paper we show the situation and capabilities of
   these technologies. From models developed with commercial programs and
   tools for industrial design, we propose a workflow to give everybody a
   chance to interact with these models. The sectors where these
   technologies are applied and the services offered are grouped together
   in industrial production systems and learning of related disciplines.
   But also promotion of 3D projects over the Internet can be done. This is
   the case of the MotoStudent project where the work done by designers to
   develop 3D models can be published easily on webpages allowing fully
   interaction to the user with no need of installing plugins. (C) 2015 The
   Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2015.12.220}},
ISSN = {{1877-0509}},
ResearcherID-Numbers = {{Garcia-Gracianteparaluceta, Benat/P-7521-2016
   }},
ORCID-Numbers = {{Garcia-Gracianteparaluceta, Benat/0000-0002-8925-4677
   Olmedo Rodriguez, Hector/0000-0003-0987-5949}},
Unique-ID = {{ISI:000370943500011}},
}

@inproceedings{ ISI:000370943500015,
Author = {Suarez-Warden, Fernando and Gonzalez Mendivil, Eduardo and Fonseca
   Ramirez, Alejandro and Garcia-Lumbreras, Salvador},
Editor = {{GonzalezMendivil, E and Flores, PGR and Gutierrez, JM and Ginters, E}},
Title = {{Profit Model for Incorporating AR Technology in Assembly Tasks of
   Aeronautical Maintenance}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE VIRTUAL AND AUGMENTED REALITY IN EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2015}},
Volume = {{75}},
Pages = {{113-122}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Tecnologico Monterrey, Campus Monterrey, Monterrey, MEXICO, NOV
   19-21, 2015}},
Organization = {{Univ La Laguna, Tecnologico Monterrey; Univ Appl Sci, Sociotechn Syst
   Engn Inst Vidzeme}},
Abstract = {{It has been observed a huge advance in information technologies
   development, which has gotten a severe change in the mode to undertake
   the maintenance and assembly tasks. However it has been difficult to
   reach a right economic and outcome assessment of the contribution of
   this and other technologies to enterprise profit because traditional
   methods of evaluation have not been able to quantify the related
   intangible benefits with enough rigor. Taking the Microeconomics as a
   theoretical reference framework for making plant capacity decisions, we
   deploy various general concepts and production function; but a review of
   the (Microeconomic) Production Theory which states that the production
   factors, governed by The Law of Diminishing Returns, coexist in diverse
   combinations, reveals that the enterprise operates in the short term
   under a series of parametric determinants that does not seem to respond
   to the socio-economic and technological reality faced in the new
   century. This investigation proposes a model of profit deducted by
   considering a microeconomic effect analysis of augmented reality
   technology incorporation into aeronautical maintenance assembly tasks.
   (C) 2015 Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2015.12.227}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000370943500015}},
}

@inproceedings{ ISI:000370943500038,
Author = {Segovia, Daniel and Mendoza, Miguel and Mendoza, Eloy and Gonzalez,
   Eduardo},
Editor = {{GonzalezMendivil, E and Flores, PGR and Gutierrez, JM and Ginters, E}},
Title = {{Augmented Reality as a Tool for Production and Quality Monitoring}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE VIRTUAL AND AUGMENTED REALITY IN EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2015}},
Volume = {{75}},
Pages = {{291-300}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Tecnologico Monterrey, Campus Monterrey, Monterrey, MEXICO, NOV
   19-21, 2015}},
Organization = {{Univ La Laguna, Tecnologico Monterrey; Univ Appl Sci, Sociotechn Syst
   Engn Inst Vidzeme}},
Abstract = {{Augmented Reality (AR) as an info visualization tool can be used in
   manufacturing industries, where real time reports are essential for the
   decision making process. An organization must guarantee their processes
   are being monitored and constantly improved. That is why an AR system
   linked to an Computer Aided Quality (CAQ) Software is proposed as a
   solution to production monitoring. AR technology displays Key
   Performance Indicators (KPI) of each workstation inside an industrial
   plant, gathered from measuring devices and integrated in the CAQ
   Software; this information is transmitted to a mobile device via
   wireless and located with an Indoor Positioning System (IPS). The
   implementation of this system results in a dynamic tool that allows to
   reduce audit times. (C) 2015 The Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2015.12.250}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000370943500038}},
}

@inproceedings{ ISI:000370943500042,
Author = {Rodriguez, Leonardo and Quint, Fabian and Gorecky, Dominic and Romero,
   David and Siller, Hector R.},
Editor = {{GonzalezMendivil, E and Flores, PGR and Gutierrez, JM and Ginters, E}},
Title = {{Developing a Mixed Reality Assistance System based on Projection Mapping
   Technology for Manual Operations at Assembly Workstations}},
Booktitle = {{2015 INTERNATIONAL CONFERENCE VIRTUAL AND AUGMENTED REALITY IN EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2015}},
Volume = {{75}},
Pages = {{327-333}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Tecnologico Monterrey, Campus Monterrey, Monterrey, MEXICO, NOV
   19-21, 2015}},
Organization = {{Univ La Laguna, Tecnologico Monterrey; Univ Appl Sci, Sociotechn Syst
   Engn Inst Vidzeme}},
Abstract = {{Manual tasks play an important role in social sustainable manufacturing
   enterprises. Commonly, manual operations are used for low volume
   productions, but are not limited to. Operational models in manufacturing
   systems based on ``x-to-order{''} paradigms (e.g. assembly-to-order) may
   require manual operations to speed-up the ramp-up time of new product
   configuration assemblies. The implications of manual operations in any
   production line may imply that any manufacturing or assembly process
   become more susceptible to human errors and therefore translate into
   delays, defects and/or poor product quality. In this scenario, virtual
   and augmented realities can offer significant advantages to support the
   human operator in manual operations. This research work presents the
   development of a mixed (virtual and augmented) reality assistance system
   that permits real-time support in manual operations. A review of mixed
   reality techniques and technologies was conducted, where it was
   determined to use a projection mapping solution for the proposed
   assistance system. According to the specific requirements of the
   demonstration environment, hardware and software components were chosen.
   The developed mixed reality assistance system was able to guide any user
   without any prior knowledge through the successful completion of the
   specific assembly task. (C) 2015 Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2015.12.254}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000370943500042}},
}

@inproceedings{ ISI:000369171900002,
Author = {Bibiloni, Antoni and Mascaro, Miquel and Palmer, Pere and Oliver, Antoni},
Editor = {{Abasolo, MJ and Kulesza, R}},
Title = {{Hypervideo, Augmented Reality on Interactive TV}},
Booktitle = {{APPLICATIONS AND USABILITY OF INTERACTIVE TV}},
Series = {{Communications in Computer and Information Science}},
Year = {{2015}},
Volume = {{389}},
Pages = {{17-31}},
Note = {{3rd Iberoamerican Conference on Applications and Usability of
   Interactive TV (jAUTI) / 3rd Workshop on Interactive Digital TV (WTVDI)
   held as part of 20th Brazilian Symposium on Multimedia and the Web
   (Webmedia), Joao Pessoa, BRAZIL, NOV 18-21, 2014}},
Organization = {{RedAUTI Themat Network Applicat \& Usabil Interact Digital Televis;
   CYTED Ibero Amer Program Sci \& Technol Dev}},
Abstract = {{In this paper, an Augmented Reality system for the Interactive and
   Connected TV is presented through the implementation of a Hypervideo
   platform. This platform consists of two modules that enable editors and
   viewers to enjoy an AR experience on current generation Interactive TVs.
   Two modules are introduced: the first provides the producers tools to
   manage the audiovisual content and points of interest, while the other
   is used by the viewers, in order to play the audiovisual production and
   obtain additional information about the points of interest that appear
   on the video.
   This work presents an innovative way to mix these three technological
   concepts: interactive video, augmented reality and connected TV.}},
DOI = {{10.1007/978-3-319-22656-9\_2}},
ISSN = {{1865-0929}},
ISBN = {{978-3-319-22656-9; 978-3-319-22655-2}},
ORCID-Numbers = {{Oliver Tomas, Antoni/0000-0002-2495-5245}},
Unique-ID = {{ISI:000369171900002}},
}

@inproceedings{ ISI:000368440600028,
Author = {D'Agnano, F. and Balletti, C. and Guerra, F. and Vernier, P.},
Editor = {{GonzalezAguilera, D and Remondino, F and Boehm, J and Kersten, T and Fuse, T}},
Title = {{TOOTEKO: A CASE STUDY OF AUGMENTED REALITY FOR AN ACCESSIBLE CULTURAL
   HERITAGE. DIGITIZATION, 3D PRINTING AND SENSORS FOR AN AUDIO-TACTILE
   EXPERIENCE}},
Booktitle = {{3D-ARCH 2015 - 3D VIRTUAL RECONSTRUCTION AND VISUALIZATION OF COMPLEX
   ARCHITECTURES}},
Series = {{International Archives of the Photogrammetry Remote Sensing and Spatial
   Information Sciences}},
Year = {{2015}},
Volume = {{40-5}},
Number = {{W4}},
Pages = {{207-213}},
Note = {{Conference on 3D-Arch 2015 - 3D Virtual Reconstruction and Visualization
   of Complex Architectures, Avila, SPAIN, FEB 25-27, 2015}},
Organization = {{Int Soc Photogrammetry \& Remote Sensing}},
Abstract = {{Tooteko is a smart ring that allows to navigate any 3D surface with your
   finger tips and get in return an audio content that is relevant in
   relation to the part of the surface you are touching in that moment.
   Tooteko can be applied to any tactile surface, object or sheet. However,
   in a more specific domain, it wants to make traditional art venues
   accessible to the blind, while providing support to the reading of the
   work for all through the recovery of the tactile dimension in order to
   facilitate the experience of contact with art that is not only ``under
   glass.{''} The system is made of three elements: a high-tech ring, a
   tactile surface tagged with NFC sensors, and an app for tablet or
   smartphone. The ring detects and reads the NFC tags and, thanks to the
   Tooteko app, communicates in wireless mode with the smart device. During
   the tactile navigation of the surface, when the finger reaches a
   hotspot, the ring identifies the NFC tag and activates, through the app,
   the audio track that is related to that specific hotspot. Thus a
   relevant audio content relates to each hotspot. The production process
   of the tactile surfaces involves scanning, digitization of data and 3D
   printing. The first experiment was modelled on the facade of the church
   of San Michele in Isola, made by Mauro Codussi in the late fifteenth
   century, and which marks the beginning of the Renaissance in Venice.
   Due to the absence of recent documentation on the church, the Correr
   Museum asked the Laboratorio di Fotogrammetria to provide it with the
   aim of setting up an exhibition about the order of the Camaldolesi,
   owners of the San Michele island and church. The Laboratorio has made
   the survey of the facade through laser scanning and UAV photogrammetry.
   The point clouds were the starting point for prototypation and 3D
   printing on different supports.
   The idea of the integration between a 3D printed tactile surface and
   sensors was born as a final thesis project at the Postgraduate
   Mastercourse in Digital Architecture of the University of Venice (IUAV)
   in 2012. Now Tooteko is now a start up company based in Venice, Italy.}},
DOI = {{10.5194/isprsarchives-XL-5-W4-207-2015}},
ISSN = {{2194-9034}},
Unique-ID = {{ISI:000368440600028}},
}

@inproceedings{ ISI:000366872700223,
Author = {Polcar, Jiri and Gregor, Michal and Horejsi, Petr and Kopecek, Pavel},
Editor = {{Soliman, KS}},
Title = {{Projection of LiDAR Point Cloud Slices to Raster Images as 3D Modelling
   Underlays}},
Booktitle = {{INNOVATION MANAGEMENT AND SUSTAINABLE ECONOMIC COMPETITIVE ADVANTAGE:
   FROM REGIONAL DEVELOPMENT TO GLOBAL GROWTH, VOLS I - VI, 2015}},
Year = {{2015}},
Pages = {{2220-2226}},
Note = {{26th International-Business-Information-Management-Association
   Conference, Madrid, SPAIN, NOV 11-12, 2015}},
Organization = {{Int Business Informat Management Assoc}},
Abstract = {{This paper suggests a new algorithm for LiDAR point cloud processing
   into raster images. The input is a point cloud file in a standard ASCII
   format, the outputs are orthographic projected points in a raster image,
   which can be used as a 3D modelling underlay. The CloudSlicer, a program
   powered by this algorithm, has been developed for validation purposes.
   The suggested algorithm has been successfully validated for more
   practical projects. This paper also shows some examples of practical
   uses. Such a method was firstly intended to be used as a foundation
   stone for production systems layout design, but the CloudSlicer software
   has been proven to be suitable as a general 3D modelling support tool.}},
ISBN = {{978-0-9860419-5-2}},
ResearcherID-Numbers = {{Kopecek, Pavel/Q-3999-2016
   Polcar, Jiri/I-7707-2016
   Horejsi, Petr/P-9672-2016}},
ORCID-Numbers = {{Kopecek, Pavel/0000-0001-9912-4799
   Polcar, Jiri/0000-0002-0157-1927
   Horejsi, Petr/0000-0002-5810-2494}},
Unique-ID = {{ISI:000366872700223}},
}

@inproceedings{ ISI:000366177000025,
Author = {Weidig, C. and Aurich, J. C.},
Editor = {{Caggiano, A}},
Title = {{Systematic development of mobile AR-applications, special focus on user
   participation}},
Booktitle = {{3RD CIRP GLOBAL WEB CONFERENCE - PRODUCTION ENGINEERING RESEARCH
   ADVANCEMENT BEYOND STATE OF THE ART (CIRPE2014)}},
Series = {{Procedia CIRP}},
Year = {{2015}},
Volume = {{28}},
Pages = {{155-160}},
Note = {{3rd CIRP Global Web Conference on Production Engineering Research -
   Advancement Beyond State of the Art (CIRPe), Univ Naples Federico II,
   Naples, ITALY, JUN 03-05, 2014}},
Abstract = {{A comprehensive, systematic planning method to design mobile Augmented
   Reality (AR)-applications in the range of production planning is not
   available. A target driven development process to match mobile
   AR-applications to the methodical needs of production planners is
   therefore proposed in this paper.
   The development process will be presented with special focus on the user
   integration. The incorporation of production planners, their intrinsic
   knowledge and engineering methods needs to be considered. Therefore, the
   paper will introduce how user relevant aspects will be identified and
   considered during the application development. (C) 2014 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.procir.2015.04.026}},
ISSN = {{2212-8271}},
ResearcherID-Numbers = {{Aurich, Jan C/M-7546-2017}},
ORCID-Numbers = {{Aurich, Jan C/0000-0001-7063-9334}},
Unique-ID = {{ISI:000366177000025}},
}

@inproceedings{ ISI:000365866300041,
Author = {Arvanitis, Gerasimos and Moustakas, Konstantinos and Fakotakis, Nikos},
Editor = {{Ronzhin, A and Potapova, R and Fakotakis, N}},
Title = {{Real-Time Context Aware Audio Augmented Reality}},
Booktitle = {{SPEECH AND COMPUTER (SPECOM 2015)}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2015}},
Volume = {{9319}},
Pages = {{333-340}},
Note = {{17th International Conference on Speech and Computer (SPECOM), Athens,
   GREECE, SEP 20-24, 2015}},
Organization = {{Univ Patras; Moscow State Linguist Univ; Russian Acad Sci, St Petersburg
   Inst Informat \& Automat; St Petersburg Natl Res Univ Informat Technolo
   Mech \& Opt; Speech Technol Ctr Ltd; Int Speech Commun Assoc}},
Abstract = {{The purpose of this paper is to present a method for real time augmented
   reality sound production from virtual sources, which are located in a
   real environment. In the performed experiments, we will initially
   emphasize on augmenting audio information, beyond the existing
   environmental sounds, using headphones. The main goal of the approach is
   to produce a virtual sound that has a natural result so that the user
   gets immersed and senses a context aware synthetic sound. The necessary
   data, such as spatial coordinates of source and listener, relative
   distance and relative velocity between them, room dimensions and
   potential obstacles between virtual source and listener are given as
   input to the proposed framework. Real time techniques are used for data
   processing. These techniques are fast and effective in order to achieve
   high performance requirements. The resulted sound gives the impression
   to the listener that the virtual source is part of the real environment.
   Any dynamic change of the parameters will have as a result the
   simultaneous real time change of the produced sound.}},
DOI = {{10.1007/978-3-319-23132-7\_41}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-23132-7; 978-3-319-23131-0}},
Unique-ID = {{ISI:000365866300041}},
}

@inproceedings{ ISI:000361753700001,
Author = {Broll, Wolfgang and Herling, Jan},
Editor = {{Brunnett, G and Coquillart, S and VanLiere, R and Welch, G and Vasa, L}},
Title = {{Live Will Never Be the Same! How Broadcasting Might Influence the
   Acceptance and Widespread Usage of Augmented Reality}},
Booktitle = {{VIRTUAL REALITIES}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2015}},
Volume = {{8844}},
Pages = {{3-15}},
Note = {{2nd International Dagstuhl Seminar on Virtual Reality (VR), Schloss
   Dagstuhl Leibniz Ctr Informat, Dagstuhl Castle, GERMANY, JUN 09-14, 2013}},
Abstract = {{While anticipated in Hollywood movies and sci-fi literature, a perfect
   artifical reality - i.e. the ultimate VR environment - will probably not
   become real within the next couple of years. However, using Augmented
   Reality (AR) technologies in order to seamlessly embed artificial
   content into the real environment, might be a much more feasible way to
   remove the clear border between reality and virtuality. In this paper we
   will look into lately developed AR technologies and how they relate to
   recent trends in movie and TV productions. We will further anticipate
   what this will mean to live broadcasts and which implications this might
   have for a widespread individual usage of sophisticated AR technology.}},
DOI = {{10.1007/978-3-319-17043-5\_1}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-17043-5; 978-3-319-17042-8}},
Unique-ID = {{ISI:000361753700001}},
}

@article{ ISI:000359947200004,
Author = {Quattrini, Ramona and Pierdicca, Roberto and Frontoni, Emanuele and
   Clini, Paolo},
Title = {{FURNITURE AND REALITY AUGMENTED AT THE DOGE'S PALACE OF URBINO: THE
   MUSEUM IS DIGITAL}},
Journal = {{ARCHEOMATICA-TECNOLOGIE PER I BENI CULTURALI}},
Year = {{2015}},
Volume = {{6}},
Number = {{1}},
Pages = {{32-37}},
Abstract = {{In this article we show an interesting approach of exploitation for
   Palazzo Ducale, the most important museum of Marche Region. The main
   objective of this project is to transform the museum into a sort of
   laboratory to experiment new technologies able to give a response to the
   administrations, who have less and less resources available to enhance
   their priceless heritage. We propose innovative solutions to create
   tools, instruments and opportunities for both insiders and common users.
   The production chain starts from cutting edge survey technology that
   gives strong data for the conservation; furthermore they are the
   starting point reach the broader public with augmented reality and
   mobile application.}},
ISSN = {{2037-2485}},
ResearcherID-Numbers = {{Frontoni, Emanuele/D-9838-2013}},
ORCID-Numbers = {{Frontoni, Emanuele/0000-0002-8893-9244}},
Unique-ID = {{ISI:000359947200004}},
}

@inproceedings{ ISI:000398586305012,
Author = {Salinas, Patricia and Quintero, Eliud and Gonzalez-Mendivil, Eduardo},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{FOSTERING VISUALIZATION FOR THE LEARNING OF CALCULUS THROUGH AUGMENTED
   REALITY}},
Booktitle = {{INTED2015: 9TH INTERNATIONAL TECHNOLOGY, EDUCATION AND DEVELOPMENT
   CONFERENCE}},
Series = {{INTED Proceedings}},
Year = {{2015}},
Pages = {{5039-5046}},
Note = {{9th International Technology, Education and Development Conference
   (INTED), Madrid, SPAIN, MAR 02-04, 2015}},
Abstract = {{Several reasons could be given to discuss about the importance of
   evaluating the potential of new digital technologies to incorporate
   visualization for the learning of mathematics. Several reasons also make
   this intention a difficult undertaking. In this work we aim to share the
   experience creating a multidisciplinary team able to give alternatives
   to transform mathematics curriculum to foster the development of
   visualization skills. The presence of emergent technologies - like
   Augmented Reality - is expected when the emphasis in visual aspects to
   trigger processes of mathematical thinking is assumed in these
   visualization skills.
   We focus on the development of certain skills that have not been
   explicit in the curriculum but nevertheless are important when you deal
   with mathematics. We want to make something about this issue and took on
   the task of designing an educational resource improving the development
   of these skills. The experience we share here considers the production
   of an Augmented Reality Application which purpose is to promote the
   spatial visualization skill.
   The necessity of gathering experts using graphical design software,
   programmer specialists and mathematicians skilled in Mathematics
   Education appeared since the beginning. All of them participating
   collaboratively in a creative process for the construction of a
   didactical resource today we're able to share. The application considers
   three levels that could be identified with content in the three first
   calculus courses in college; from 2D to 3D, solids of revolution and 3D
   surfaces.
   Two experiences with students have been conducted in order to appreciate
   the impact of the application's use in the first level, both inside and
   outside classroom. These experiences allowed the improvement of the
   application and the design of a didactical activity using it. Beside the
   motivational aspects that stand out, the usefulness of the integration
   of visualization within the learning process is what motivates us to
   develop qualitative inquiry that could provide feedback about the
   cognitive event promoted by the interaction with this kind of didactical
   resources.
   To transform the learning of Mathematics, to make it an interesting and
   attractive experience in addition to being useful for the development of
   mathematical skills, is the target that keeps us together as a TEAM:
   Tecnologia Educativa para el Aprendizaje de las Matematicas.}},
ISSN = {{2340-1079}},
ISBN = {{978-84-606-5763-7}},
Unique-ID = {{ISI:000398586305012}},
}

@article{ ISI:000214407800005,
Author = {Hachicha, Nejib and Ben Amar, Amine},
Title = {{Does Islamic bank financing contribute to economic growth? The Malaysian
   case}},
Journal = {{INTERNATIONAL JOURNAL OF ISLAMIC AND MIDDLE EASTERN FINANCE AND
   MANAGEMENT}},
Year = {{2015}},
Volume = {{8}},
Number = {{3}},
Pages = {{349-368}},
Abstract = {{Purpose - The purpose of this paper is to investigate empirically the
   impact of the Islamic Bank Financing on Malaysia's economic growth over
   the period 2000Q1-2011Q4.
   Design/methodology/approach - A neoclassical production function
   augmented by some indicators of Islamic bank finance has been the
   theoretical framework for this paper's empirical investigation. The unit
   root tests show that all the variables are integrated of order 1. The
   test of Johansen and Juselius ( 1990) has shown the existence of a
   single cointegrating relationship between the gross domestic product
   (GDP), the investment, the labor force and the indicator of Islamic bank
   finance. Hence, an error correction model has been constructed to
   estimate the economic growth elasticity with respect to the different
   Islamic bank finance indicators.
   Findings - The estimated elasticities show that, in the long run, the
   GDP in Malaysia is not sensitive to the Islamic financing. The
   estimation of an error correction model shows that the elasticity of the
   Malaysian output with respect to the different Islamic financing
   indicators in the short run turn around 0.35. Thus, the effect of the
   different Islamic finance indicators on the economic growth in the long
   run is less important than their effect in the short run. This economic
   result can be explained by the structure of the Islamic bank financing
   that marginalizes the profit-and-loss sharing (PLS)-based instruments.
   This turns out to be consistent with the economic reality in Malaysia,
   as the Islamic banks engage much more in non-participatory activities
   whose impact is, generally, of short term.
   Social implications - To improve the efficiency of the Malaysian Islamic
   banks as financial inter-mediaries that facilitate the capital
   accumulation and the economic growth, the paper suggests to strengthen
   the weight of the PLS-based instruments in the loan portfolios of the
   Malaysian Islamic banks. This may reduce inequalities and improve
   economic opportunities for people who have a high potential to
   contribute to the capital accumulation and the creation of the
   value-added.
   Originality/value - The contribution of this paper is two-fold. On the
   one hand, it provides a further contribution to the rare empirical
   literature relative to the impact of the Islamic finance on growth by
   determining the elasticity of economic growth with respect to Islamic
   bank financing in Malaysia. On the other hand, and to the best of the
   authors' knowledge, this paper remains the first to correctly resort to
   the error correction model in determining this elasticity.}},
DOI = {{10.1108/IMEFM-07-2014-0063}},
ISSN = {{1753-8394}},
EISSN = {{1753-8408}},
Unique-ID = {{ISI:000214407800005}},
}

@article{ ISI:000409686700002,
Author = {Kebo, Vladimir and Stasa, Pavel and Benes, Filip and Svub, Jiri},
Title = {{Auto-Identification in Mining Industry}},
Journal = {{INZYNIERIA MINERALNA-JOURNAL OF THE POLISH MINERAL ENGINEERING SOCIETY}},
Year = {{2015}},
Number = {{1}},
Pages = {{7-12}},
Month = {{JAN-JUN}},
Abstract = {{Automatic identification (AutoID) becomes an important part of control
   systems for movement control of objects in logistics. From the
   perspective of process control multi-agent systems are a distributed
   control system, which sets out the operational objectives of the daily
   production in different production segments that are controlled by the
   individual production units. Next very potential areas for the
   application of Smart technology are intelligent logistics and operations
   management using AutoID RFID technology that allows automatic identifi
   cation and monitoring of any objects in the production networks. The
   next step of smart production control is the application of Holonic
   multiagent systems - HoloMAS. To understand the autonomous control
   processes and technology state, the use of augmented and virtual reality
   will be necessary.}},
ISSN = {{1640-4920}},
Unique-ID = {{ISI:000409686700002}},
}

@article{ ISI:000215871200004,
Author = {Park, Min Ki and Lim, Kyu Je and Seo, Myoung Kook and Jung, Soon Jong
   and Lee, Kwan H.},
Title = {{Spatial augmented reality for product appearance design evaluation}},
Journal = {{JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING}},
Year = {{2015}},
Volume = {{2}},
Number = {{1}},
Pages = {{38-46}},
Month = {{JAN}},
Abstract = {{Augmented reality based on projection, called ``Spatial Augmented
   Reality (SAR){''}, is a new technology that can produce inversive
   contents by overlapping virtuality and real-world environment. It has
   been paid attention as the next generation digital contents in media art
   and human computer interaction (HCI). In this paper, we present a new
   methodology to evaluate the product appearance design more intuitively
   by means of SAR technique. The proposed method first projects the
   high-quality rendered image considering the optical property of
   materials onto the mockup of a product. We also conduct a
   projector-camera calibration to compensate a color distortion according
   to a projector, a projection surl'ace and environment lighting. The
   design evaluation methodology we propose offers more flexible and
   intuitive evaluation environment to a designer and user (evaluator) than
   previous methods that are performed via a digital display. At the end of
   this research, we have conducted a case study for designing and
   evaluating appearance design of an automobile. (C) 2015 Society of
   CAD/CAM Engineers. Production and hosting by Elsevier.}},
DOI = {{10.1016/j.jcde.2014.11.004}},
ISSN = {{2288-4300}},
EISSN = {{2288-5048}},
Unique-ID = {{ISI:000215871200004}},
}

@article{ ISI:000215871200005,
Author = {Aoki, Hiroshi and Mitani, Jun and Kanamori, Yoshihiro and Fukui, Yukio},
Title = {{AR based ornament design system for 3D printing}},
Journal = {{JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING}},
Year = {{2015}},
Volume = {{2}},
Number = {{1}},
Pages = {{47-54}},
Month = {{JAN}},
Abstract = {{In recent years, 3D printers have become popular as a means of
   outputting geometries designed on CAD or 3D graphics systems. However,
   the complex user interfaces of standard 3D software can make it
   difficult for ordinary consumers to design their own objects.
   Furthermore, models designed on 3D graphics software often have
   geometrical problems that make them impossible to output on a 3D
   printer. We propose a novel AR (augmented reality) 3D modeling system
   with an air-spray like interface. We also propose a new data structure
   (octet voxel) for representing designed models in such a way that the
   model is guaranteed to he a complete solid. The target shape is based on
   a regular polyhedron, and the octet voxel representation is suitable for
   designing geometrical objects having the same symmetries as the base
   regular polyhedron. Finally, we conducted a user test and confirmed that
   users can intuitively design their own ornaments in a short time with a
   simple user interface. (C) 2015 Society of CAD/CAM Engineers. Production
   and hosting by Elsevier.}},
DOI = {{10.1016/j.jcde.2014.11.005}},
ISSN = {{2288-4300}},
EISSN = {{2288-5048}},
Unique-ID = {{ISI:000215871200005}},
}

@article{ ISI:000212379200005,
Author = {Crandall, Philip G. and Engler, III, Robert K. and Beck, Dennis E. and
   Killian, Susan A. and O'Bryan, Corliss A. and Jarvis, Nathan and
   Clausen, Ed},
Title = {{Development of an Augmented Reality Game to Teach Abstract Concepts in
   Food Chemistry}},
Journal = {{JOURNAL OF FOOD SCIENCE EDUCATION}},
Year = {{2015}},
Volume = {{14}},
Number = {{1}},
Pages = {{18-23}},
Month = {{JAN}},
Abstract = {{One of the most pressing issues for many land grant institutions is the
   ever increasing cost to build and operate wet chemistry laboratories. A
   partial solution is to develop computer-based teaching modules that take
   advantage of animation, web-based or off-campus learning experiences
   directed at engaging students' creative experiences. We used the
   learning objectives of one of the most difficult topics in food
   chemistry, enzyme kinetics, to test this concept. Students are
   apprehensive of this subject and often criticize the staid instructional
   methods typically used in teaching this material. As a result, students
   do not acquire a useful background in this important subject. To rectify
   these issues, we developed an interactive augmented reality application
   to teach the basic concepts of enzyme kinetics in the context of an
   interactive search that took students to several locations on campus
   where they were able to gather raw materials and view videos that taught
   the basics of enzyme kinetics as applied to the production of high
   fructose corn syrup (HFCS). The students needed this background to
   prepare for a mock interview with an HFCS manufacturer. Students and
   instructors alike found the game to be preferable to sitting in a
   classroom listening to, or giving, a PowerPoint presentation. We feel
   that this use of gaming technology to teach difficult, abstract concepts
   may be a breakthrough in food science education and help alleviate the
   drain on administrative budgets from multiple wet labs.}},
DOI = {{10.1111/1541-4329.12048}},
ISSN = {{1541-4329}},
Unique-ID = {{ISI:000212379200005}},
}

@article{ ISI:000344744200008,
Author = {Kolivand, Hoshang and Noh, Zakiah and Sunar, Mohd Shahrizal},
Title = {{A quadratic spline approximation using detail multi-layer for soft
   shadow generation in augmented reality}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2014}},
Volume = {{73}},
Number = {{3}},
Pages = {{1225-1245}},
Month = {{DEC}},
Abstract = {{Implementation of shadows is crucial to enhancement of images in AR
   environments. Without shadows, virtual objects would look floating over
   the scene resulting in unrealistic rendering of AR environments. Casting
   hard shadows would provide only spatial information while soft shadows
   help improve realism of AR environments. Several algorithms have been
   proposed to render realistic shadows which often incurred high
   computational costs. Little attention has been directed towards the
   balanced trade-off between shadow quality and computational costs. In
   this study, two approaches are proposed: Quadratic Spline Interpolation
   (QSI) to soften the outline of the shadow and Detail Multi-Layer (DML)
   technique to optimize the volume of computations for the generation of
   soft shadows based on real light sources. QSI estimates boarder hard
   shadow samples while DML involves three main phases: real light sources
   estimation, soft shadow production and reduction of the complexity of
   3-Dimensional objects' shadows. To be more precise, a reflective
   hemisphere is used to capture real light and to create an environment
   map. The Median Cut algorithm is implemented to locate the direction of
   real light sources on the environment map. Subsequently, the original
   hard shadows are retrieved and a sample of multilayer hard shadows is
   produced where each layer has its unique size and colour. These layers
   overlap to produce soft shadows based on the real light sources'
   directions. Finally, the Level of Details (LOD) algorithm is implemented
   to increase the efficiency of soft shadows by decreasing the complexity
   of vertex transformations. The proposed technique is tested using three
   samples of multilayer hard shadows with varying numbers of light sources
   generated from the Median Cut algorithm. The experimental results show
   that the proposed technique successfully produces realistic soft shadows
   at low computational costs.}},
DOI = {{10.1007/s11042-013-1630-6}},
ISSN = {{1380-7501}},
EISSN = {{1573-7721}},
Unique-ID = {{ISI:000344744200008}},
}

@article{ ISI:000342623900011,
Author = {Berry, Colin and Board, Jason},
Title = {{A Protein in the Palm of Your Hand Through Augmented Reality}},
Journal = {{BIOCHEMISTRY AND MOLECULAR BIOLOGY EDUCATION}},
Year = {{2014}},
Volume = {{42}},
Number = {{5}},
Pages = {{446-449}},
Month = {{SEP-OCT}},
Abstract = {{Understanding of proteins and other biological macromolecules must be
   based on an appreciation of their 3-dimensional shape and the fine
   details of their structure. Conveying these details in a clear and
   stimulating fashion can present challenges using conventional approaches
   and 2-dimensional monitors and projectors. Here we describe a method for
   the production of 3-D interactive images of protein structures that can
   be manipulated in real time through the use of augmented reality
   software. Users first see a real-time image of themselves using the
   computer's camera, then, when they hold up a trigger image, a model of a
   molecule appears automatically in the video. This model rotates and
   translates in space in response to movements of the trigger card. The
   system described has been optimized to allow customization for the
   display of user-selected structures to create engaging, educational
   visualizations to explore 3-D structures. (c) 2014 by The International
   Union of Biochemistry and Molecular Biology, 42(5):446-449, 2014.}},
DOI = {{10.1002/bmb.20805}},
ISSN = {{1470-8175}},
EISSN = {{1539-3429}},
ResearcherID-Numbers = {{Berry, Colin/A-4338-2010
   }},
ORCID-Numbers = {{Berry, Colin/0000-0002-9943-548X
   Plummer, Beverley/0000-0002-6559-7237}},
Unique-ID = {{ISI:000342623900011}},
}

@article{ ISI:000335740100042,
Author = {Jiang, S. and Ong, S. K. and Nee, A. Y. C.},
Title = {{An AR-based hybrid approach for facility layout planning and evaluation
   for existing shop floors}},
Journal = {{INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY}},
Year = {{2014}},
Volume = {{72}},
Number = {{1-4, SI}},
Pages = {{457-473}},
Month = {{APR}},
Abstract = {{Facility layout planning (FLP) has substantial impact on the various
   aspects of a manufacturing system. FLP is typically performed for new
   shop floors. However, enterprises nowadays are often faced with the need
   to reconfigure the existing shop floor layouts to synchronize the shop
   floor operations with the constantly changing production targets. FLP
   tasks for existing shop floors are often small in scale, e.g., adding or
   removing a couple of machines, but complex to address since a wide range
   of criteria need to be incorporated and the presence of the existing
   facilities imposes critical constraints. Current FLP approaches are not
   efficient to handle these issues. The development of computer-aided
   design (CAD) technology has provided feasible solutions to bridge this
   gap. In this paper, an augmented reality (AR)-based hybrid approach is
   proposed which facilitates on-site layout planning and evaluation in
   real time. By integrating AR technology with the mathematical modeling
   technique, the proposed approach allows the users to augment the shop
   floor with the facilities to be laid out, model the existing facilities
   to obtain their geometric data, and define the criteria and constraints
   to formulate the problems as multi-attribute decision-making (MADM)
   models. Two planning methods are employed to solve the MADM models,
   namely, information-aided manual planning and analytic hierarchy process
   (AHP)-genetic algorithm (GA)-based automatic planning. During the
   planning process, the criteria and the constraints are assessed in real
   time to provide immediate evaluation and feedback to facilitate
   decision-making.}},
DOI = {{10.1007/s00170-014-5653-6}},
ISSN = {{0268-3768}},
EISSN = {{1433-3015}},
Unique-ID = {{ISI:000335740100042}},
}

@inproceedings{ ISI:000363283700433,
Author = {Kirsch, Fabian and Miesen, Robert and Vossiek, Martin},
Book-Group-Author = {{IEEE}},
Title = {{Precise Local-Positioning for Autonomous Situation Awareness in the
   Internet of Things}},
Booktitle = {{2014 IEEE MTT-S INTERNATIONAL MICROWAVE SYMPOSIUM (IMS)}},
Series = {{IEEE MTT-S International Microwave Symposium}},
Year = {{2014}},
Note = {{IEEE MTT-S International Microwave Symposium (IMS), Tampa, FL, JUN
   01-06, 2014}},
Organization = {{IEEE MTT S}},
Abstract = {{This paper reviews different wireless local positioning principles and
   explains the interaction between local positioning and the Internet of
   Things (IOT). The principle, performance and use of recent local
   positioning systems in the context of the IOT are shown in detail for
   typical applications. The first application is the accurate real-time
   localization of transportation vehicles using local positioning radar.
   The second application is the loading state characterization of goods in
   the proximity of a forklift enabling fully automated warehouse
   management. The third application is the dynamic localization of
   UHF-RFID tags with a handheld reader, which provides helpful augmented
   reality for logistics personnel. The final application is the real-time
   localization of tools for production monitoring. The developed
   ultrawideband (UWB) locating system is based on a pulsed frequency
   modulated continuous wave (FMCW) radar principle. By using assisting
   inertial sensors and advanced fusion algorithms, highly accurate 3D
   localization was achieved even in complex industrial environments with
   dense multipath channels and shadowing.}},
ISSN = {{0149-645X}},
ISBN = {{978-1-4799-3869-8}},
Unique-ID = {{ISI:000363283700433}},
}

@inproceedings{ ISI:000361395300019,
Author = {Pintzos, G. and Rentzos, L. and Papakostas, N. and Chryssolouris, G.},
Editor = {{Constantinescu, C and Bauer, W and Sauer, O and Maropoulos, P}},
Title = {{A Novel Approach for the Combined Use of AR Goggles and Mobile Devices
   as Communication Tools on the Shopfloor}},
Booktitle = {{8TH INTERNATIONAL CONFERENCE ON DIGITAL ENTERPRISE TECHNOLOGY - DET 2014
   DISRUPTIVE INNOVATION IN MANUFACTURING ENGINEERING TOWARDS THE 4TH
   INDUSTRIAL REVOLUTION}},
Series = {{Procedia CIRP}},
Year = {{2014}},
Volume = {{25}},
Pages = {{132-137}},
Note = {{8th International Conference on Digital Enterprise Technology (DET),
   Stuttgart, GERMANY, MAR 25-28, 2014}},
Organization = {{Int Acad Prod Engn; Fraunhofer Inst Ind Engn IAO}},
Abstract = {{Existing and evolving trends and paradigms in manufacturing, such as
   mass customisation and personalisation, call for better communication
   among product-production design and customisation and production
   execution. Specifically, the lack of feedback from and to the shopfloor
   can lead to lower product quality and increased production times. In
   state-of-the-art industrial practices, the most common visual interface
   devices for communication comprise control unit terminals, TFT monitors
   mounted over work stations, as well as the growing trend of mobile PCs
   and tablets. New technologies, such as Augmented Reality (AR), have also
   been considered in academic research for process simulation and operator
   guidance and training. This paper proposes a novel use of AR goggles,
   coupled with other mobile devices for the communication of people,
   working on the shopfloor and in the engineering offices. The proposed
   methodology tries to address the challenges, related to the use of both
   technologies (and their respective interfaces) by presenting an
   integrated approach: the use of a mobile device as an input device and
   as a fiducial marker for the positioning of a virtual screen in front of
   the user. After the presentation of the concept, its advantages and
   disadvantages, compared with current practices as well with the rest of
   the relevant academic work, are presented. The technical implementation
   to be realised, including specific software frameworks that will be used
   is also described. Special attention is given to the data models that
   will support the implementation of this approach as well as to show how
   they can be integrated into the existing systems and practices. (C) 2014
   The Authrs. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procir.2014.10.021}},
ISSN = {{2212-8271}},
ORCID-Numbers = {{Papakostas, Nikolaos/0000-0002-0443-221X}},
Unique-ID = {{ISI:000361395300019}},
}

@inproceedings{ ISI:000360999100203,
Author = {Paelke, Volker},
Book-Group-Author = {{IEEE}},
Title = {{Augmented Reality in the Smart Factory Supporting Workers in an Industry
   4.0. Environment}},
Booktitle = {{2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA)}},
Year = {{2014}},
Note = {{19th IEEE International Conference on Emerging Technology and Factory
   Automation (ETFA), Barcelona, SPAIN, SEP 16-19, 2014}},
Organization = {{Univ Politecnica Catalunya; IEEE Ind Elect Soc; IEEE}},
Abstract = {{We present an augmented reality system that supports human workers in a
   rapidly changing production environment. By providing spatially
   registered information on the task directly in the user's field of view
   the system can guide the user through unfamiliar tasks (e.g. assembly of
   new products) and visualize information directly in the spatial context
   were it is relevant. In the first version we present the user with
   picking and assembly instructions in an assembly application. In this
   paper we present the initial experience with this system, which has
   already been used successfully by several hundred users who had no
   previous experience in the assembly task.}},
ISBN = {{978-1-4799-4845-1}},
Unique-ID = {{ISI:000360999100203}},
}

@inproceedings{ ISI:000360012600043,
Author = {Kollatsch, Christian and Schumann, Marco and Klimant, Philipp and
   Wittstock, Volker and Putz, Matthias},
Editor = {{Putz, M}},
Title = {{Mobile Augmented Reality based Monitoring of Assembly Lines}},
Booktitle = {{5TH CATS 2014 - CIRP CONFERENCE ON ASSEMBLY TECHNOLOGIES AND SYSTEMS}},
Series = {{Procedia CIRP}},
Year = {{2014}},
Volume = {{23}},
Pages = {{246-251}},
Note = {{5th CIRP Conference on Assembly Technologies and Systems (CATS),
   Dresden, GERMANY, NOV 13-14, 2014}},
Organization = {{CIRP}},
Abstract = {{Showing process-relevant information of assembly lines is an important
   task in production, e.g. for diagnostic purposes. Accessing the relevant
   manufacturing values during production requires extensive knowledge of
   the used machines and their control systems (e.g. PLC, CNC) and could
   cause a delay of the production process. Therefore, this paper presents
   an Augmented Reality (AR) based application for mobile devices realizing
   a user-friendly and problem-oriented visualization of relevant
   information directly on-site. The AR application uses a uniform
   graphical user interface. Due to this the user does not need to handle
   different human machine interfaces. (C) 2014 The Authors. Published by
   Elsevier B.V.}},
DOI = {{10.1016/j.procir.2014.10.100}},
ISSN = {{2212-8271}},
Unique-ID = {{ISI:000360012600043}},
}

@inproceedings{ ISI:000360082700046,
Author = {Giuliano, Igor and Taurino, Teresa},
Editor = {{CamarinhaMatos, LM and Afsarmanesh, H}},
Title = {{Augmented-Reality Application for a Seru-type Manufacturing as Lean as
   Possible}},
Booktitle = {{COLLABORATIVE SYSTEMS FOR SMART NETWORKED ENVIRONMENTS}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2014}},
Volume = {{434}},
Pages = {{463-470}},
Note = {{15th IFIP WG 5.5 Working Conference on Virtual Enterprises (PRO-VE),
   Amsterdam, NETHERLANDS, OCT 06-08, 2014}},
Organization = {{IFIP WG 5 5 Co Operat infrastructure for Virtual Enterprises \& Elect
   Business; Soc Collaborat Networks; IEEE Syst Man \& Cybernet Soc; Univ
   Amsterdam; New Univ Lisbon; UNINOVA}},
Abstract = {{The goal of this paper is to discuss the island-based organization of a
   manufacturing-assembly system, based on the Seru-Seisan approach, whose
   main goals are to decentralize the production line and to improve
   personnel qualification. The aim is to show that a Seru-type production
   island/cell can be really profitable in case the operator could be
   supported by augmented-reality tools, such to help him in any complex
   processing operation. The efficiency/effectiveness of a Seru-type
   organization will be proved by verifying that it satisfies the main
   principles of ``lean manufacturing{''}, stated in terms of mathematical
   formulation of both the lean goals and the lean processing model. A
   practical validation of the Seru-type approach will be done by analyzing
   an assembly unit, now under development and testing in CNH Industrial,
   where the operator is supported by an augmented-reality system designed
   in cooperation with Regola S.r.l.}},
ISSN = {{1868-4238}},
ISBN = {{978-3-662-44744-4}},
Unique-ID = {{ISI:000360082700046}},
}

@inproceedings{ ISI:000357262304032,
Author = {Ugaz, Max and Bernuy Alva, Augusto},
Editor = {{Carlucci, D and Spender, JC and Schiuma, G}},
Title = {{Model of a Multi-Agent System to Simulate an Environment in Virtual
   Worlds for the Globalized Productive Training of Women with Disabilities}},
Booktitle = {{IFKAD 2014: 9TH INTERNATIONAL FORUM ON KNOWLEDGE ASSET DYNAMICS:
   KNOWLEDGE AND MANAGEMENT MODELS FOR SUSTAINABLE GROWTH}},
Year = {{2014}},
Pages = {{3925-3949}},
Note = {{9th International Forum on Knowledge Asset Dynamics (IFKAD), Matera,
   ITALY, JUN 11-13, 2014}},
Organization = {{Inst Knowledge Asset Management; Univ Basilicata; Arts Business Inst;
   Univ Basilicata, DIMIE}},
Abstract = {{Purpose-The purpose of this research is to develop a learning system
   architecture, based on the knowledge management supported into a valid
   platform, for a globalized production training for disabled women, based
   on their capabilities, skills, and feelings as a tacit knowledge. In
   this context it is necessary to identify a profile which needs
   interaction with the virtual words. The process is completed through the
   developing of a model based on the interaction of the participants with
   intelligent agents, using the MPML3D language and which works through a
   collaborative learning process. The results are validated in a prototype
   for being tested and discussed.
   Design/methodology/approach-Virtual worlds are part of the extensive
   field of ``shared space{''} technologies, as are Augmented Reality,
   Telepresence and Virtual Reality, all discrete spaces represented and
   executed by computers and accessed exclusively through the Internet.
   Virtual worlds have technological capabilities to support the generation
   of knowledge and collaborative learning through the interaction of
   avatars (human-controlled avatar) and these ones with intelligent agents
   (avatars controlled by a machine), developing a collaborative
   information and training system, which in turn may support a platform
   for training and production of women with physical disabilities.
   Originality/value-This research presents a model that allows women with
   physical disabilities to overcome their limitations due to physical
   constraints of the real world so they can become into productive and
   globalized persons, taking advantage from the economy of virtual worlds
   as Second Life.
   The State of the Art of the above mentioned technologies, the specific
   characteristics of women with physical disabilities and the
   characteristics of virtual worlds, can generate capabilities that enable
   a collaborative learning through the interaction with intelligent agents
   (avatars controlled by a machine), which are able to answer frequently
   asked questions to avatars (human-controlled avatar), who in turn can
   generate actions from the agents within the virtual world. These agents
   allow a permanent support without the limitations of fixed schedules,
   personalizing the training without the barriers of the traditional
   process of education.
   Practical implications-The practical implications of the model proposed
   lies in three main areas:
   Productive women who overcome physical limitations due to their
   disability.
   Learning environments, based on low-cost emerging technologies.
   Globalization of people with mobility problems even from developing
   countries.}},
ISBN = {{978-88-96687-04-8}},
Unique-ID = {{ISI:000357262304032}},
}

@inproceedings{ ISI:000354698400018,
Author = {Capozzi, Francesco and Lorizzo, Valerio and Modoni, Gianfranco and
   Sacco, Marco},
Editor = {{DePaolis, LT and Mongelli, A}},
Title = {{Lightweight Augmented Reality Tools for Lean Procedures in Future
   Factories}},
Booktitle = {{AUGMENTED AND VIRTUAL REALITY, AVR 2014}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2014}},
Volume = {{8853}},
Pages = {{232-246}},
Note = {{1st International Conference on Augmented and Virtual Reality (AVR),
   Lecce, ITALY, SEP 17-20, 2014}},
Abstract = {{The aim of this paper is to introduce the main outcomes of the
   application of Augmented Reality (AR) features to manufacturing and
   industrial scenarios under a new perspective. While the request of
   industrial mixed reality technologies is continuously growing, the
   research community is still facing the crucial challenge to give a
   convenient answer to such needs. The problem of the development of
   adaptable and inexpensive AR solutions is herein addressed by proposing
   a new approach for the application of AR technology to lean-based visual
   communication transfer and exchange. This work starts from the concept
   of virtual factory, a place where the real production of future
   factories becomes fully merged with virtual reality features and
   utilities. AR applications may then be reinterpreted as lightweight
   tools that continuously interact with the virtual factory to support
   manufacturing and management tasks, providing just-in-time and adaptive
   augmented information to users. As a case study, several AR tools
   designed following these principles to support a real production process
   are presented.}},
DOI = {{10.1007/978-3-319-13969-2\_18}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-13969-2; 978-3-319-13968-5}},
Unique-ID = {{ISI:000354698400018}},
}

@inproceedings{ ISI:000354774500024,
Author = {Liestol, Gunnar},
Editor = {{Ioannides, M and MagnenatThalmann, N and Fink, E and Zarnic, R and Yen, AY and Quak, E}},
Title = {{Along the Appian Way. Storytelling and Memory across Time and Space in
   Mobile Augmented Reality}},
Booktitle = {{DIGITAL HERITAGE: PROGRESS IN CULTURAL HERITAGE: DOCUMENTATION,
   PRESERVATION, AND PROTECTION}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2014}},
Volume = {{8740}},
Pages = {{248-257}},
Note = {{5th EuroMed International Conference, Amathus, CYPRUS, NOV 03-08, 2014}},
Organization = {{CableNet Ltd; Cyprus Tourism Org; Cyprus Postal Serv; Cyprus Handicraft
   Ctr}},
Abstract = {{In this indirect augmented reality system we have reconstructed about 1
   km of the Via Appia Antica with three time periods represented: 320 CE,
   71 BCE, and 49 BCE. This situated simulation explores the notion of
   narrative movement and travel across space and time in a cultural
   heritage context. The transitions between the temporal phases are
   triggered by the users active repositioning on location. Included in the
   system is also a quiz consisting of verbal and image based alternatives
   to a variety of questions related to the information provided in the
   virtual environments. We describe the main elements of the simulation,
   its technical solution and production, as well as the feedback from real
   users testing on location. We close with a reflection on the multimodal
   quiz and how it relates to memory and learning.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-13695-0; 978-3-319-13694-3}},
Unique-ID = {{ISI:000354774500024}},
}

@inproceedings{ ISI:000349548300017,
Author = {Krichenbauer, Max and Yamamoto, Goshiro and Taketomi, Takafumi and
   Sandor, Christian and Kato, Hirokazu},
Editor = {{Julier, S and Lindeman, RW and Sandor, C}},
Title = {{Towards Augmented Reality User Interfaces in 3D Media Production}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2014}},
Pages = {{23-28}},
Note = {{IEEE International Symposium on Mixed and Augmented Reality (ISMAR) -
   Science and Technology, Munich, GERMANY, SEP 10-12, 2014}},
Organization = {{IEEE; IEEE Visualizat \& Graph Tech Comm; IEEE Comp Soc}},
Abstract = {{The idea of using Augmented Reality (AR) user interfaces (UIs) to create
   3D media content, such as 3D models for movies and games has been
   repeatedly suggested over the last decade. Even though the concept is
   intuitively compelling and recent technological advances have made such
   an application increasingly feasible, very little progress has been made
   towards an actual real-world application of AR in professional media
   production. To this day, no immersive 3D UI has been commonly used by
   professionals for 3D computer graphics (CG) content creation.
   In this paper, we are first to publish a requirements analysis for our
   target application in the professional domain. Based on a survey that we
   conducted with media professionals, the analysis of professional 3D CG
   software, and professional training tutorials, we identify these
   requirements and put them into the context of AR UIs. From these
   findings, we derive several interaction design principles that aim to
   address the challenges of real-world application of AR to the production
   pipeline. We implemented these in our own prototype system while
   receiving feedback from media professionals. The insights gained in the
   survey, requirements analysis, and user interface design are relevant
   for research and development aimed at creating production methods for 3D
   media production.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-6184-9}},
Unique-ID = {{ISI:000349548300017}},
}

@inproceedings{ ISI:000349548300049,
Author = {Carmo, Maria Beatriz and Claudio, Ana Paula and Ferreira, Antonio and
   Afonso, Ana Paula and Redweik, Paula and Catita, Cristina and Brito,
   Miguel Centeno and Pedrosa, Jose Nunes},
Editor = {{Julier, S and Lindeman, RW and Sandor, C}},
Title = {{Visualization of Solar Radiation Data in Augmented Reality}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2014}},
Pages = {{255-256}},
Note = {{IEEE International Symposium on Mixed and Augmented Reality (ISMAR) -
   Science and Technology, Munich, GERMANY, SEP 10-12, 2014}},
Organization = {{IEEE; IEEE Visualizat \& Graph Tech Comm; IEEE Comp Soc}},
Abstract = {{We present an AR application for visualizing solar radiation data on
   facades of buildings, generated from LiDAR data and climatic
   observations. Data can be visualized using colored surfaces and glyphs.
   A user study revealed the proposed AR visualizations were easy to use,
   which can lead to leverage the potential benefits of AR visualizations:
   to detect errors in the simulated data, to give support to the
   installation of photovoltaic equipment and to raise public awareness of
   the use of facades for power production.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-6184-9}},
ResearcherID-Numbers = {{Catita, Cristina/K-8449-2012
   Brito, Miguel/K-8476-2012
   Redweik, Paula/J-7717-2013
   }},
ORCID-Numbers = {{Brito, Miguel/0000-0002-3580-3474
   Redweik, Paula/0000-0002-9644-1147
   Claudio, Ana Paula/0000-0002-4594-8087
   Afonso, Ana Paula/0000-0002-0687-5540}},
Unique-ID = {{ISI:000349548300049}},
}

@inproceedings{ ISI:000349548300096,
Author = {Krichenbauer, Max and Yamamoto, Goshiro and Taketomi, Takafumi and
   Sandor, Christian and Kato, Hirokazu},
Editor = {{Julier, S and Lindeman, RW and Sandor, C}},
Title = {{{[}DEMO] Towards Augmented Reality User Interfaces in 3D Media
   Production}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2014}},
Pages = {{351}},
Note = {{IEEE International Symposium on Mixed and Augmented Reality (ISMAR) -
   Science and Technology, Munich, GERMANY, SEP 10-12, 2014}},
Organization = {{IEEE; IEEE Visualizat \& Graph Tech Comm; IEEE Comp Soc}},
Abstract = {{For this demo, we present an Augmented Reality (AR) User Interface (UI)
   for the 3D design software Autodesk Maya, aimed at professional media
   creation. A user wears a head-mounted display (HMD) and thin cotton
   gloves which allow him to interact with virtual 3D models in the work
   area. Additional viewers can see the video stream on a projector and
   thus share the users view. Both head and hand positions are tracked from
   the HMD video stream, and an inertial measurement unit (IMU) and
   conductive materials on the gloves allow interaction with virtual
   objects. This system is built using Autodesk Maya - a professional 3D
   software package commonly used in the media industry - and aims to
   fulfill the requirements of professional 3D design work which we
   identified in our paper of the same title. While still an early
   prototype, it was already tested with media professionals to evaluate
   our approach.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-6184-9}},
Unique-ID = {{ISI:000349548300096}},
}

@inproceedings{ ISI:000349183500003,
Author = {Clay, Alexis and Domenger, Gael and Conan, Julien and Domenger, Axel and
   Couture, Nadine},
Editor = {{Duh, H and Stadon, J and Stapleton, C}},
Title = {{Integrating Augmented Reality to Enhance Expression, Interaction \&
   Collaboration in Live Performances: a Ballet Dance Case Study}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY -
   MEDIA, ART, SOCIAL SCIENCE, HUMANITIES AND DESIGN (IMSAR-MASH'D)}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2014}},
Pages = {{21+}},
Note = {{IEEE International Symposium on Mixed and Augmented Reality - Media,
   Art, Social Science, Humanities and Design (IMSAR-MASHD), Munich,
   GERMANY, SEP 10-12, 2014}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Visualizat \& Graph Tech Comm}},
Abstract = {{The democratization of high-end, affordable and off-the-shelf sensors
   and displays triggered an explosion in the exploration of interaction
   and projection in arts. Although mostly witnessed in interactive
   artistic installations (e.g. museums and exhibitions), performing arts
   also explore such technologies, using interaction and augmented reality
   as part of the performance. Such works often emerge from collaborations
   between artists and scientists. Despite being antonymic in appearance,
   we advocate that both fields can greatly benefit from this type of
   collaboration.
   Since 2006 the authors of this paper (from a research laboratory and a
   national ballet company) have collaborated on augmenting a ballet
   performance using a dancer's movements for interaction. We focus on
   large productions using high-end motion capture and projection systems
   to allow dancers to interact with virtual elements on an augmented stage
   in front of several hundred people. To achieve this, we introduce an
   `augmented reality engineer', whose role is to design the augmented
   reality systems and interactions according to a show's aesthetic and
   choreographic message, and to control them during the performance
   alongside light and sound technicians.
   Our last production: Debussy3.0 is an augmented ballet based on La Mer
   by Claude Debussy, featuring body interactions by one of the dancers and
   backstage interactions by the augmented reality engineer. For the first
   time, we explored 3D stereoscopy as a display technique for augmented
   reality and interaction in real-time on stage. The show was presented at
   Biarritz Casino in December 2013 in front of around 700 people.
   In this paper, we present the Debussy3.0 augmented ballet both as a
   result of the use of augmented reality in performing arts and as a
   guiding thread to provide feedback on arts-science collaboration. First,
   we will describe how the ballet was constructed aesthetically,
   technically and in its choreography. We will discuss and provide
   feedback on the use of motion capture and stereoscopy techniques in a
   live show and will then broaden the scope of discussion, providing
   feedback on art-science collaboration, the traps and benefits for both
   parties, and the positive repercussions it can bring to a laboratory
   when working on industrial projects.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-6887-9}},
ORCID-Numbers = {{Couture, Nadine/0000-0001-7959-5227}},
Unique-ID = {{ISI:000349183500003}},
}

@inproceedings{ ISI:000349183500012,
Author = {Liberati, Nicola},
Editor = {{Duh, H and Stadon, J and Stapleton, C}},
Title = {{A single co-lived augmented world or many solipsistic fantasies?}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY -
   MEDIA, ART, SOCIAL SCIENCE, HUMANITIES AND DESIGN (IMSAR-MASH'D)}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2014}},
Pages = {{71-72}},
Note = {{IEEE International Symposium on Mixed and Augmented Reality - Media,
   Art, Social Science, Humanities and Design (IMSAR-MASHD), Munich,
   GERMANY, SEP 10-12, 2014}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Visualizat \& Graph Tech Comm}},
Abstract = {{The aim of this paper is to determine the difference, in augmented
   reality (AR), between the creation of one single world and the creation
   of multiple worlds in terms of the ``reality{''} of the augmented world
   created by the device.
   This work analyses what kind of relation between subjects and worlds are
   created by these two different kinds of worlds created from a
   phenomenological perspective.
   It will be clear how the production of such an augmented world cannot be
   solved by mere technical elements, but it has to deal with bigger
   problems.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-6887-9}},
Unique-ID = {{ISI:000349183500012}},
}

@inproceedings{ ISI:000346367800153,
Author = {Bibiloni, Toni and Mascaro, Miquel and Palmer, Pere and Oliver, Antoni},
Editor = {{Rocha, A and Fonseca, D and Redondo, E and Reis, LP and Cota, MP}},
Title = {{Augmented Reality on HbbTV, an Hypervideo approach}},
Booktitle = {{PROCEEDINGS OF THE 2014 9TH IBERIAN CONFERENCE ON INFORMATION SYSTEMS
   AND TECHNOLOGIES (CISTI 2014)}},
Series = {{Iberian Conference on Information Systems and Technologies}},
Year = {{2014}},
Note = {{9th Iberian Conference on Information Systems and Technologies (CISTI),
   Barcelona, SPAIN, JUN 18-21, 2014}},
Abstract = {{In this paper, an Augmented Reality system for the Connected TV is
   presented through a Hypervideo platform implementation. The Hypervideo
   platform consists of a back-office to manage audiovisual content and
   hot-spots, and an interactive video player based in HbbTV technology.
   The player lets the user get additional information of the points of
   interest which are displayed over the images. This project presents a
   useful platform to audiovisual production teams, letting them mix, in an
   easy way, these three technological concepts: interactive video,
   augmented reality and connected television. This paper concludes with
   some improvement possibilities and extension to other devices.}},
ISSN = {{2166-0727}},
ResearcherID-Numbers = {{Mascaro, Miguel/G-3393-2015
   Palmer Rodriguez, Pere/G-3098-2015}},
ORCID-Numbers = {{Mascaro, Miguel/0000-0001-9913-1825
   Palmer Rodriguez, Pere/0000-0001-5794-6858}},
Unique-ID = {{ISI:000346367800153}},
}

@inproceedings{ ISI:000346506400070,
Author = {Rao, Qing and Gruenler, Christian and Hammori, Markus and Chakraborty,
   Samarjit},
Book-Group-Author = {{IEEE}},
Title = {{Design Methods for Augmented Reality In-Vehicle Infotainment Systems}},
Booktitle = {{2014 51ST ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC)}},
Series = {{Design Automation Conference DAC}},
Year = {{2014}},
Note = {{51st ACM/EDAC/IEEE Design Automation Conference (DAC), San Francisco,
   CA, JUN 01-05, 2014}},
Organization = {{ACM; EDAC; IEEE}},
Abstract = {{We have experienced rapid development of augmented reality (AR) systems
   and platforms in the automotive industry. However, to bring AR into
   production cars, we still face a range of challenges to design an AR
   system that meets vehicle specific requirements. Based on our experience
   with an AR prototype car, we analyze the influence of augmented reality
   on the design of the in-vehicle electric/electronic (E/E) architecture.}},
DOI = {{10.1145/2593069.2602973}},
ISSN = {{0738-100X}},
ISBN = {{978-1-4503-2730-5}},
ORCID-Numbers = {{Chakraborty, Samarjit/0000-0002-0503-6235}},
Unique-ID = {{ISI:000346506400070}},
}

@inproceedings{ ISI:000343913000013,
Author = {Sarayeddine, K. and Mirza, K. and Benoit, P. and Hugel, X.},
Editor = {{Kazemi, AA and Kress, BC and Mendoza, EA and Murshid, SH and Javahiraly, N and Ishihara, AK}},
Title = {{Monolithic Light Guide Optics Enabling New User Experience for
   See-Through AR glasses}},
Booktitle = {{PHOTONICS APPLICATIONS FOR AVIATION, AEROSPACE, COMMERCIAL, AND HARSH
   ENVIRONMENTS V}},
Series = {{Proceedings of SPIE}},
Year = {{2014}},
Volume = {{9202}},
Note = {{Conference on Photonics Applications for Aviation, Aerospace,
   Commercial, and Harsh Environments V, San Diego, CA, AUG 18-21, 2014}},
Organization = {{SPIE}},
Abstract = {{This paper describes the performances of mold light guide based
   see-through optics for the production of AR glasses for commercial and
   professional applications. A monolithic thin mold light guide with
   surface structure mirror array extracts and project bright and large
   virtual image into the user eye of sight. The light guide thin form
   factor allows a new user experience with two possible positions for the
   virtual image in front of the user eye. A wireless AR glasses based on
   this concept will be described and demonstrated. A comparison with
   others light guide based technologies in term of Safety, Brightness
   efficiency and form factor will be presented and discussed.}},
DOI = {{10.1117/12.2064172}},
Article-Number = {{UNSP 92020E}},
ISSN = {{0277-786X}},
ISBN = {{978-1-62841-229-1}},
Unique-ID = {{ISI:000343913000013}},
}

@inproceedings{ ISI:000342765600009,
Author = {Olalde Azkorreta, Karle and Olmedo Rodriguez, Hector},
Editor = {{Zaphiris, P and Ioannou, A}},
Title = {{Augmented Reality Applications in the Engineering Environment}},
Booktitle = {{LEARNING AND COLLABORATION TECHNOLOGIES: TECHNOLOGY-RICH ENVIRONMENTS
   FOR LEARNING AND COLLABORATION, PT II}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2014}},
Volume = {{8524}},
Pages = {{83-90}},
Note = {{1st International Conference on Learning and Collaboration Technologies
   (LCT), Heraklion, GREECE, JUN 22-27, 2014}},
Abstract = {{In the area of engineering, we can move much in the way clients
   generally can interact with models or designs for new products, so we
   are developing various alternatives for visualization, such as Virtual
   and Augmented realities based on accurate models with no need of using
   specific software. In order to have a better and global knowledge of the
   possibilities we show in this paper the situation and capabilities of
   these technologies. From models developed with commercial programs and
   tools for industrial design, we propose a workflow to give everybody a
   chance to interact with these models. The sectors where these
   technologies are applied and the services offered are grouped in
   Industrial production systems and Learning of related disciplines. At
   the end conclusions will be given with every reference used. With
   everything, ideas for improving these technologies and the correspondent
   applications could be suggested to the reader.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-07485-6; 978-3-319-07484-9}},
ORCID-Numbers = {{olalde, karle/0000-0001-7978-2049
   Olmedo Rodriguez, Hector/0000-0003-0987-5949}},
Unique-ID = {{ISI:000342765600009}},
}

@inproceedings{ ISI:000335859300133,
Author = {Tuma, Zdenek and Tuma, Jiri and Knoflicek, Radek and Blecha, Petr and
   Bradac, Frantisek},
Editor = {{Katalinic, B}},
Title = {{The Process Simulation using by Virtual Reality}},
Booktitle = {{24TH DAAAM INTERNATIONAL SYMPOSIUM ON INTELLIGENT MANUFACTURING AND
   AUTOMATION, 2013}},
Series = {{Procedia Engineering}},
Year = {{2014}},
Volume = {{69}},
Pages = {{1015-1020}},
Note = {{24th DAAAM International Symposium on Intelligent Manufacturing and
   Automation, Univ Zadar, Zadar, CROATIA, OCT 23-26, 2013}},
Organization = {{DAAAM Int Assoc; Int Acad Engn; Vienna Univ Technol; Austrian Soc
   Engineers \& Architects; Vienna Univ Appl Sci Technikum; DAAAM, Danube
   Rectors Conf; DAAAM, Rectors \& Presidents Honor Comm}},
Abstract = {{Nowadays companies can solve production systems problems by variety of
   software solutions, but in practice it is known that it is often
   difficult to interpret these outputs, illustrate and to further
   integrate. One possibility is the use of augmented virtual reality for
   the planning of these systems. This article deals with the construction
   of the experimental sorting workplace as a model case of the production
   system. Weak points of solution are solved using augmented virtual
   reality, which helps to simulate the process in real time, in this case
   the virtual displayed product moving on belt conveyor before testing the
   real piece. (C) 2014 The Authors. Published by Elsevier Ltd.}},
DOI = {{10.1016/j.proeng.2014.03.084}},
ISSN = {{1877-7058}},
ORCID-Numbers = {{Blecha, Petr/0000-0003-4182-288X}},
Unique-ID = {{ISI:000335859300133}},
}

@inproceedings{ ISI:000335951100010,
Author = {Steckel, Kayla and Whittinghill, David},
Editor = {{Dolinsky, M and McDowall, IE}},
Title = {{Z-depth integration: a new technique for manipulating z-depth properties
   in composited scenes}},
Booktitle = {{ENGINEERING REALITY OF VIRTUAL REALITY 2014}},
Series = {{Proceedings of SPIE}},
Year = {{2014}},
Volume = {{9012}},
Note = {{Conference on Engineering Reality of Virtual Reality, San Francisco, CA,
   FEB 03-04, 2014}},
Organization = {{Soc Imaging Sci \& Technol; SPIE}},
Abstract = {{This paper presents a new technique in the production pipeline of asset
   creation for virtual environments called Z-Depth Integration (ZeDI).
   ZeDI is intended to reduce the time required to place elements at the
   appropriate z-depth within a scene. Though ZeDI is intended for use
   primarily in two-dimensional scene composition, depth-dependent
   ``flat{''} animated objects are often critical elements of augmented and
   virtual reality applications (AR/VR). ZeDI is derived from ``deep image
   compositing{''}, a capacity implemented within the OpenEXR file format.
   In order to trick the human eye into perceiving overlapping scene
   elements as being in front of or behind one another, the developer must
   manually manipulate which pixels of an element are visible in relation
   to other objects embedded within the environment's image sequence. ZeDI
   improves on this process by providing a means for interacting with
   procedurally extracted z-depth data from a virtual environment scene. By
   streamlining the process of defining objects' depth characteristics, it
   is expected that the time and energy required for developers to create
   compelling AR/VR scenes will be reduced. In the proof of concept
   presented in this manuscript, ZeDI is implemented for pre-rendered
   virtual scene construction via an AfterEffects software plug-in.}},
DOI = {{10.1117/12.2044809}},
Article-Number = {{90120A}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-9929-5}},
Unique-ID = {{ISI:000335951100010}},
}

@article{ ISI:000330259900018,
Author = {Tykkala, Tommi and Comport, Andrew I. and Kamarainen, Joni-Kristian and
   Hartikainen, Hannu},
Title = {{Live RGB-D camera tracking for television production studios}},
Journal = {{JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION}},
Year = {{2014}},
Volume = {{25}},
Number = {{1, SI}},
Pages = {{207-217}},
Month = {{JAN}},
Abstract = {{In this work, a real-time image-based camera tracker is designed for
   live television production studios. The major concern is to decrease
   camera tracking expenses by an affordable vision-based approach. First,
   a dense keyframe model of the static studio scene is generated using
   image-based dense tracking and bundle adjustment. Online camera tracking
   is then defined as registration problem between the current RGB-D
   measurement and the nearest keyframe. With accurate keyframe poses, our
   camera tracking becomes virtually driftless. The static model is also
   used to avoid moving actors in the scene. Processing dense RGB-D
   measurements requires special attention when aiming for real-time
   performance at 30 Hz. We derive a real-time tracker from our cost
   function for a low-end GPU. The system requires merely a RGB-D sensor,
   laptop and a low-end CPU. Camera tracking properties are compared with
   KinectFusion. Our solution demonstrates robust and driftless real-time
   camera tracking in a television production studio environment. (C) 2013
   Elsevier Inc. All rights reserved.}},
DOI = {{10.1016/j.jvcir.2013.02.009}},
ISSN = {{1047-3203}},
EISSN = {{1095-9076}},
ResearcherID-Numbers = {{Kamarainen, Joni-Kristian/G-4296-2014}},
Unique-ID = {{ISI:000330259900018}},
}

@inproceedings{ ISI:000377221106010,
Author = {Gaschler, Andre and Springer, Maximilian and Rickert, Markus and Knoll,
   Alois},
Book-Group-Author = {{IEEE}},
Title = {{Intuitive Robot Tasks with Augmented Reality and Virtual Obstacles}},
Booktitle = {{2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)}},
Series = {{IEEE International Conference on Robotics and Automation ICRA}},
Year = {{2014}},
Pages = {{6026-6031}},
Note = {{IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014}},
Organization = {{IEEE}},
Abstract = {{Today's industrial robots require expert knowledge and are not
   profitable for small and medium sized enterprises with their small lot
   sizes. It is our strong belief that more intuitive robot programming in
   an augmented reality robot work cell can dramatically simplify
   re-programming and leverage robotics technology in short production
   cycles. In this paper, we present a novel augmented reality system for
   defining virtual obstacles, specifying tool positions, and specifying
   robot tasks. We evaluate the system in a user study and, more
   specifically, investigate the input of robot end-effector orientations
   in general.}},
ISSN = {{1050-4729}},
ISBN = {{978-1-4799-3685-4}},
ORCID-Numbers = {{Rickert, Markus/0000-0001-6264-0888}},
Unique-ID = {{ISI:000377221106010}},
}

@article{ ISI:000327561100027,
Author = {Jimeno-Morenilla, Antonio and Luis Sanchez-Romero, Jose and Salas-Perez,
   Faustino},
Title = {{Augmented and Virtual Reality techniques for footwear}},
Journal = {{COMPUTERS IN INDUSTRY}},
Year = {{2013}},
Volume = {{64}},
Number = {{9, SI}},
Pages = {{1371-1382}},
Month = {{DEC}},
Abstract = {{The use of 3D imaging techniques has been early adopted in the footwear
   industry. In particular, 3D imaging could be used to aid commerce and
   improve the quality and sales of shoes. Footwear customization is an
   added value aimed not only to improve product quality, but also consumer
   comfort. Moreover, customisation implies a new business model that
   avoids the competition of mass production coming from new manufacturers
   settled mainly in Asian countries.
   However, footwear customisation implies a significant effort at
   different levels. In manufacturing, rapid and virtual prototyping is
   required; indeed the prototype is intended to become the final product.
   The whole design procedure must be validated using exclusively virtual
   techniques to ensure the feasibility of this process, since physical
   prototypes should be avoided.
   With regard to commerce, it would be desirable for the consumer to
   choose any model of shoes from a large 3D database and be able to try
   them on looking at a magic mirror. This would probably reduce costs and
   increase sales, since shops would not require storing every shoe model
   and the process of trying several models on would be easier and faster
   for the consumer.
   In this paper, new advances in 3D techniques coming from experience in
   cinema, TV and games are successfully applied to footwear. Firstly, the
   characteristics of a high-quality stereoscopic vision system for
   footwear are presented. Secondly, a system for the interaction with
   virtual footwear models based on 3D gloves is detailed. Finally, an
   augmented reality system (magic mirror) is presented, which is
   implemented with low-cost computational elements that allow a
   hypothetical customer to check in real time the goodness of a given
   virtual footwear model from an aesthetical point of view. (C) 2013
   Elsevier B.V. All rights reserved.}},
DOI = {{10.1016/j.compind.2013.06.008}},
ISSN = {{0166-3615}},
EISSN = {{1872-6194}},
ResearcherID-Numbers = {{Jimeno-Morenilla, Antonio/K-5544-2014
   }},
ORCID-Numbers = {{Jimeno-Morenilla, Antonio/0000-0002-3789-6475
   Sanchez-Romero, Jose-Luis/0000-0001-8766-2813}},
Unique-ID = {{ISI:000327561100027}},
}

@article{ ISI:000326978500007,
Author = {Gimlin, Debra L.},
Title = {{``TOO GOOD TO BE REAL{''}: The Obviously Augmented Breast in Women's
   Narratives of Cosmetic Surgery}},
Journal = {{GENDER \& SOCIETY}},
Year = {{2013}},
Volume = {{27}},
Number = {{6}},
Pages = {{913-934}},
Month = {{DEC}},
Abstract = {{Although consumers and physicians alike have long described the goal of
   aesthetic surgery as the production of an improved but still
   natural-looking body, interviews with women who had cosmetic surgery
   between 1990 and 2007 suggest that the artificial is becoming
   increasingly prevalent within consumers' narratives of breast
   enlargement. This article explores that change in relation to processes
   of conspicuous consumption, the growing cultural emphasis on continual
   self-transformation, and the increasing normalization of cosmetic
   modification. Following Fraser (2003), it treats consumers' accounts not
   as the reflection of reality or a true self but instead as indicators of
   the kinds of options, expressions, assumptions, and perspectives that
   are available for use in communication about cosmetic surgery. The
   analysis also draws on feminist writings about the social construction
   of breastedness in femininity. In so doing, it seeks to conceptualize
   the cultural significance of breasts that are too good to be real.}},
DOI = {{10.1177/0891243213493001}},
ISSN = {{0891-2432}},
EISSN = {{1552-3977}},
Unique-ID = {{ISI:000326978500007}},
}

@article{ ISI:000324878400024,
Author = {Schall, Gerhard and Zollmann, Stefanie and Reitmayr, Gerhard},
Title = {{Smart Vidente: advances in mobile augmented reality for interactive
   visualization of underground infrastructure}},
Journal = {{PERSONAL AND UBIQUITOUS COMPUTING}},
Year = {{2013}},
Volume = {{17}},
Number = {{7, SI}},
Pages = {{1533-1549}},
Month = {{OCT}},
Abstract = {{Many civil engineering tasks require to access geospatial data in the
   field and reference the stored information to the real-world situation.
   Augmented reality (AR), which interactively overlays 3D graphical
   content directly over a view of the world, can be a useful tool to
   visualize but also create, edit and update geospatial data representing
   real-world artifacts. We present research results on the next-generation
   field information system for companies relying on geospatial data,
   providing mobile workforces with capabilities for on-site inspection and
   planning, data capture and as-built surveying. To achieve this aim, we
   used mobile AR technology for on-site surveying of geometric and
   semantic attributes of geospatial 3D models on the user's handheld
   device. The interactive 3D visualizations automatically generated from
   production databases provide immediate visual feedback for many tasks
   and lead to a round-trip workflow where planned data are used as a basis
   for as-built surveying through manipulation of the planned data.
   Classically, surveying of geospatial objects is a typical scenario
   performed from utility companies on a daily basis. We demonstrate a
   mobile AR system that is capable of these operations and present first
   field trials with expert end users from utility companies. Our initial
   results show that the workflows of planning and surveying of geospatial
   objects benefit from our AR approach.}},
DOI = {{10.1007/s00779-012-0599-x}},
ISSN = {{1617-4909}},
EISSN = {{1617-4917}},
Unique-ID = {{ISI:000324878400024}},
}

@article{ ISI:000323705500005,
Author = {Diaz, Oscar and Arellano, Cristobal and Azanza, Maider},
Title = {{A Language for End-User Web Augmentation: Caring for Producers and
   Consumers Alike}},
Journal = {{ACM TRANSACTIONS ON THE WEB}},
Year = {{2013}},
Volume = {{7}},
Number = {{2}},
Month = {{MAY}},
Abstract = {{Web augmentation is to the Web what augmented reality is to the physical
   world: layering relevant content/layout/navigation over the existing Web
   to customize the user experience. This is achieved through JavaScript
   (JS) using browser weavers (e.g., Greasemonkey). To date, over 43
   million of downloads of Greasemonkey scripts ground the vitality of this
   movement. However, Web augmentation is hindered by being programming
   intensive and prone to malware. This prevents end-users from
   participating as both producers and consumers of scripts: producers need
   to know JS, consumers need to trust JS. This article aims at promoting
   end-user participation in both roles. The vision is for end-users to
   prosume (the act of simultaneously caring for producing and consuming)
   scripts as easily as they currently prosume their pictures or videos.
   Encouraging production requires more ``natural{''} and abstract
   constructs. Promoting consumption calls for augmentation scripts to be
   easier to understand, share, and trust upon. To this end, we explore the
   use of Domain-Specific Languages (DSLs) by introducing Sticklet.
   Sticklet is an internal DSL on JS, where JS generality is reduced for
   the sake of learnability and reliability. Specifically, Web augmentation
   is conceived as fixing in existing web sites (i.e., the wall) HTML
   fragments extracted from either other sites or Web services (i.e., the
   stickers). Sticklet targets hobby programmers as producers, and computer
   literates as consumers. From a producer perspective, benefits are
   threefold. As a restricted grammar on top of JS, Sticklet expressions
   are domain oriented and more declarative than their JS counterparts,
   hence speeding up development. As syntactically correct JS expressions,
   Sticklet scripts can be installed as traditional scripts and hence,
   programmers can continue using existing JS tools. As declarative
   expressions, they are easier to maintain, and amenable for optimization.
   From a consumer perspective, domain specificity brings understandability
   (due to declarativeness), reliability (due to built-in security), and
   ``consumability{''} (i.e., installation/enactment/sharing of Sticklet
   expressions are tuned to the shortage of time and skills of the target
   audience). Preliminary evaluations indicate that 77\% of the subjects
   were able to develop new Sticklet scripts in less than thirty minutes
   while 84\% were able to consume these scripts in less than ten minutes.
   Sticklet is available to download as a Mozilla add-on.}},
DOI = {{10.1145/2460383.2460388}},
Article-Number = {{9}},
ISSN = {{1559-1131}},
EISSN = {{1559-114X}},
ResearcherID-Numbers = {{Azanza, Maider/L-6400-2014
   Diaz, Oscar/D-2822-2011}},
ORCID-Numbers = {{Azanza, Maider/0000-0002-4537-1572
   Diaz, Oscar/0000-0003-1334-4761}},
Unique-ID = {{ISI:000323705500005}},
}

@article{ ISI:000317172600010,
Author = {Sekito, T. and Prayogo, T. B. and Dote, Y. and Yoshitake, T. and Bagus,
   I.},
Title = {{Influence of a community-based waste management system on people's
   behavior and waste reduction}},
Journal = {{RESOURCES CONSERVATION AND RECYCLING}},
Year = {{2013}},
Volume = {{72}},
Pages = {{84-90}},
Month = {{MAR}},
Abstract = {{An investigation was carried out concerning the effects of Community
   Based Waste Management (CBWM) systems on people's attitude toward waste
   management within (Semarang City) Indonesia and the waste flow in areas
   with CBWM, in order to identify its benefits and challenges.
   A questionnaire survey was performed in Bukit Kencana Jaya (BKJ) where
   CBWM had been previously implemented, as well as three areas currently
   practicing typical waste management: Graha Estetika (S1), Banteng
   Selatan area (S2), and Genuk Sari area (S3). The results indicated less
   occurrences of inappropriate waste handling behavior such as backyard
   burning and throwing waste on the road side or into the river in BKJ,
   when compared with other areas employing traditional waste management.
   The cross-correlation analysis showed a strong relationship between the
   income levels in areas Si and S3 and people's willingness to separate
   their waste together with a close correlation between education and
   willingness to cooperate in S3.
   From the waste flow analysis, it was found that a reduction in the order
   of 33\% could be achieved in household waste transported to landfill
   sites. In reality, however, the overall amount of waste delivered to
   landfill sites has augmented due to increases in collected waste.
   Compost market development and improvements in compost production are
   necessary to further reduce landfill waste. (C) 2013 Elsevier B.V. All
   rights reserved.}},
DOI = {{10.1016/j.resconrec.2013.01.001}},
ISSN = {{0921-3449}},
EISSN = {{1879-0658}},
Unique-ID = {{ISI:000317172600010}},
}

@inproceedings{ ISI:000345445900001,
Author = {Bluemel, Eberhard},
Editor = {{MartinGutierrez, J and Ginters, E}},
Title = {{Global Challenges and Innovative Technologies Geared toward New Markets:
   Prospects for Virtual and Augmented Reality}},
Booktitle = {{2013 INTERNATIONAL CONFERENCE ON VIRTUAL AND AUGMENTED REALITY IN
   EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2013}},
Volume = {{25}},
Pages = {{4-13}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Puerto de la Cruz, SPAIN, NOV 07-09, 2013}},
Organization = {{UnivLa Laguna; Univ Appl Sci, Sociotechn Syst Engn Inst Vidzeme}},
Abstract = {{Effective applied research is based on close collaboration between
   research and industry, which, taking the findings of basic research on
   customer demands as its starting point, creates new means to develop and
   market innovative products. What is more, growing demands for innovative
   and sustainable results of research and development are prompting the
   examination of global trends such as demographic change, growing
   megacities, rising energy consumption and increasing traffic and the
   resultant social challenges. These trends and increasing traffic in
   particular are giving rise to new fields of work, especially for digital
   technologies, as a social responsibility, e.g. on driver assistance and
   traffic control systems that increase safety. The social challenges are
   increasingly affecting markets and requiring new innovative products,
   efficient production processes and integrative forms of human resource
   development and training and qualification. The virtualization and
   digitization of objects and processes is becoming an enabler of the
   development of new strategies and concepts such as smart cities, green
   energy, electric vehicle networks, smart manufacturing and smart
   logistics. This paper examines means by which digital engineering and
   virtual and augmented reality technologies can support the creation of
   sustainable smart manufacturing and smart logistics processes as well as
   on-the-job training and qualification and knowledge transfer (C) 2013
   The Authors. Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2013.11.002}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000345445900001}},
}

@inproceedings{ ISI:000345445900007,
Author = {Salinas, Patricia and Gonzalez-Mendivil, Eduardo and Quintero, Eliud and
   Rios, Horacio and Ramirez, Hector and Morales, Sergio},
Editor = {{MartinGutierrez, J and Ginters, E}},
Title = {{The Development of a Didactic Prototype for the Learning of Mathematics
   Through Augmented Reality}},
Booktitle = {{2013 INTERNATIONAL CONFERENCE ON VIRTUAL AND AUGMENTED REALITY IN
   EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2013}},
Volume = {{25}},
Pages = {{62-70}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Puerto de la Cruz, SPAIN, NOV 07-09, 2013}},
Organization = {{UnivLa Laguna; Univ Appl Sci, Sociotechn Syst Engn Inst Vidzeme}},
Abstract = {{This work applies Augmented Reality technology in the educational
   process through a didactic prototype that promotes visualization skills
   related to the learning of mathematical content. An initial prototype
   has been designed and built with the purpose of arriving at 3
   dimensional objects performing specific actions, in space and time,
   executed with 2 dimensional objects. The AR production of mathematical
   objects with which student may interact offers the opportunity to
   mentally record the process through which they are generated, favoring
   visualization skills. In the initial academic phase, an analysis of the
   first three college calculus courses was carried out. The objective was
   the identification of a transversal content suitable to be developed in
   AR environment. Once this content was established and discussed, the
   conceptualization of the prototype was carried out, identifying first
   the platform of technological and human resources available for the
   project. The technical phase was focused on developing the AR technology
   prototype around the didactic design concept. The adjustment decisions
   in this process were based around the academic-technical integration
   meetings. A pilot experience for exploratory purposes was developed with
   Mathematics I for engineering students during May 2013. The aim was to
   describe the actions the prototype encourages from the students and to
   capitalize these results to determine limitations and reaches of this
   first prototype, from a didactically and technically point of view. The
   pilot experience confirms that AR technology in education increases the
   current motivation to learn by students. The work aims to study about
   the development of didactic resources that serve students in the
   learning of a visual and tangible mathematics. (C) 2013 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2013.11.008}},
ISSN = {{1877-0509}},
ResearcherID-Numbers = {{Quintero, Eliud/C-2633-2016
   Salinas, Patricia/C-6006-2016}},
ORCID-Numbers = {{Quintero, Eliud/0000-0003-1904-337X
   Salinas, Patricia/0000-0002-9909-6158}},
Unique-ID = {{ISI:000345445900007}},
}

@inproceedings{ ISI:000345445900021,
Author = {Souza-Concilio, Ilana de A. and Pacheco, Beatriz A.},
Editor = {{MartinGutierrez, J and Ginters, E}},
Title = {{The Development of Augmented Reality Systems in Informatics Higher
   Education}},
Booktitle = {{2013 INTERNATIONAL CONFERENCE ON VIRTUAL AND AUGMENTED REALITY IN
   EDUCATION}},
Series = {{Procedia Computer Science}},
Year = {{2013}},
Volume = {{25}},
Pages = {{179-188}},
Note = {{International Conference on Virtual and Augmented Reality in Education
   (VARE), Puerto de la Cruz, SPAIN, NOV 07-09, 2013}},
Organization = {{UnivLa Laguna; Univ Appl Sci, Sociotechn Syst Engn Inst Vidzeme}},
Abstract = {{Because Augmented Reality (AR) is known as a non-traditional interface,
   it arouses much interest from several researchers, due to the
   development of the technology and its applications, and to their social
   and cultural impacts. Research has shown that learning does occur
   applying AR to an educational context, but not how potential developers,
   as undergraduate students, are interested in AR and in which application
   areas. Thus, this article aims to show the interest of students from
   four undergraduate courses (Bachelors of Digital Design, Multimedia
   Production, Information Systems and Computer Science) to develop and use
   AR for many different applications. The proposal is to contribute to the
   research with a survey from an initial questionnaire about students'
   level of knowledge on the subject, their interest in the use of this
   technology and their intention to develop such systems. After analyzing
   the results, the goal is to indicate actions that may point ways to the
   collaborative development of relevant applications in computational
   terms and to stimulate the work with an Interaction Design that
   considers the syntactic thought of designer. (C) 2013 The Authors.
   Published by Elsevier B.V.}},
DOI = {{10.1016/j.procs.2013.11.022}},
ISSN = {{1877-0509}},
Unique-ID = {{ISI:000345445900021}},
}

@article{ ISI:000340974500006,
Author = {Vorlik, Petr},
Title = {{THE INTERIOR OF JESTED MOUNTAIN HOTEL AND TELEVISION TOWER}},
Journal = {{ARCHITEKTURA \& URBANIZMUS}},
Year = {{2013}},
Volume = {{47}},
Number = {{3-4}},
Pages = {{234-253}},
Abstract = {{This year will mark forty years since Jested Mountain Hotel and
   Television Tower first opened to great fanfare. A national cultural
   monument, built on the site of an old historical building that had
   burned down, the tower is a reflection of several currents in society at
   the time of its construction: the political thaw in Czechoslovakia, the
   social and cultural ferment of the `golden Sixties', efforts to break
   away from the industrialised, quantification-centred approach that
   dominated in civil engineering, and the powerful determination to make a
   very distinctive individual mark in an era when ownership, means, and
   objectives were otherwise collective. The structure represents the
   timeless union of a unique landscape environment, a congenial impulse,
   and the cohesive outlook of the artists involved. Today it is a symbol
   of the town and the region as a whole and provides eloquent testimony of
   the dreams of a particular generation of architects. The fame and
   general popularity of the tower have made it the subject of numerous
   studies, but surprisingly they have overlooked its remarkable interior
   design, which forms an integral part of the tower's overall physical and
   spiritual essence. The most familiar media image of this icon is as
   viewed from afar, an image that has taken precedence over the reality of
   experiencing a close human encounter with the architecture of the 1960s
   and 1970s.
   The experimental character of the tower, which Rostislav Svacha has
   described as a prime example of `the pragmatism of honest Czech
   engineering' and Miroslav Masak as `high tech by a handyman' is the
   product of the crucial cooperation between architect Karel Hubacek (1924
   - 2011) and a group of structural and civil engineers. However, the need
   to create an interior `tailor-made' to this structure led to the
   involvement of two long-time colleagues, the outstanding interior
   designer Otakar Binar (1931 -) and furnishings designer Karel Wunsch
   (1932 -). Their foremost goal was to bring together two barely
   compatible worlds: the tower structure, a clear, coherent, and resolute
   gesture in tune with the magnificence of the surrounding landscape, and
   a hotel interior, with the smaller-scale spatial layout it required.
   From the outset efforts to this end were centred on two unifying ideas:
   One was to create an uninterrupted panorama of the surroundings and
   apply the popular post-war theme of the inner landscape. The fluidity of
   space and the strange sensation of infinity inside the tower are
   augmented with the use of circular corridors and apertures, and by the
   island-like placement of solitary furniture pieces which do not rise in
   height above the level of the window ledges. The second idea was to
   establish a tension between the two poetic worlds of `earth and sky.' In
   the interior this was achieved by creating a contrast between the raw,
   robust character of the concrete core and floors and the apparent
   weightlessness of the ceiling and interior furnishings. The interior is
   thus an integral component in the very design of the tower itself, whose
   exterior expression similarly ties in with the surrounding landscape,
   the shape of the mountain, and the panoramic circumferential view - the
   tower's stone or concrete plinth (union with the earth) coalesces with
   the light, poetic, technicistic mass of its upper section (union with
   the sky).
   The interior Binar created, with its muted colour scheme and refined
   choice of objects and materials, celebrates the victory of man and
   technology over nature, the creation of a better, artistic, `artificial'
   nature (like the tower itself). Allusions to the rustic remain artfully
   covert and indirect, elegantly muted and light, moving from scenographic
   Brussels-concept variety to the very rawness of brutalism (like the
   popular Scandinavian work of that period).
   The decorative artwork designed by Karel Wunsch sought to bring out the
   welcoming atmosphere of the hotel, enrich it with archetypal motifs, and
   even tap into the visitor's subconscious - e.g. the furniture was placed
   so that the visitor's back was ever protected by the concrete building
   core of the tower and so that nothing ever impeded the view from the
   windows; the orange table linen recalled the warmth of a fire and its
   print (images of grape harvesting, picnics) stirred the appetite.
   However, Wunsch's concept was in its own way equally purposeful and,
   like Binar's work, reflected the post-war intersection of rationalism
   and a congenially humanised modernism. Wunsch also designed an
   undulating mirrored screen for Jested, as well as a uniform visual style
   (the hotel logo, the graphic design of the menus, invitations, and
   visiting cards) and the hotel's table service. That this work was
   extraordinary is borne out by the sad fact that pieces of the service
   went missing allegedly during the production process and then at an
   unchecked rate after the restaurant opened.
   The theme of an `artificial landscape' is even applied deep inside the
   interior of the tower - in the hotel hall and the entrance stairwell,
   the floor of which is covered with marble and the softly rounded walls
   with creamy white tiling designed by Devana Mirova and featuring an
   irregular relief suggestive of a bamboo thicket.
   Binar imbued the hotel rooms with a stylistic unity and tranquility
   using his H-series furniture, made out of three solid, black-varnished
   blockboards set perpendicular to each other; the vertical panels could
   be used to support a glass table top or some other H-series component,
   while the horizontal panels could support a bedframe and mattress, a
   chair seat, or could be used as a flat surface on which to place a
   suitcase or television set, etc. This visually simple, concentrated
   design was something that could be built even in the constrained
   circumstances of socialist-era furniture manufacturing. The soft,
   welcoming character and visual harmony of the rooms were further
   enhanced by the monochrome carpet, the walls wallpapered in a delicate
   striped and embossed pattern, and even the veneer interiors of all the
   cabinets. The sky-blue bed linen with white snowflakes designed by
   Wunsch created a dreamy atmosphere. The snow-white, tailor-made RAKO
   tiling, shaped corner bricks, and the hook and soap dish fittings in the
   bathrooms also warrant attention. Despite the deliberately poetic
   quality and muted tone of the rooms, many of the details used therein
   still alluded to the technicist character of the tower and contemporary
   building culture (aluminium casings, standardised components in the
   technical infrastructure, etc.).
   The interior of the hotel's single guest suite was truly a curiosity.
   Here the artists indulged in the opportunity to obtain and use
   historical furniture to lighten the orderly atmosphere of the tower. As
   a result, it was possible to find austere pieces of H-series furniture,
   essential technicist elements, a colourful Persian carpet, purple-grey
   wallpaper, Classical patterns, Romantic paintings and carved frames,
   and, most notably, Louis XVI style bedroom furniture side by side in
   this suite. With this the image of the structure as a Romantic `palace
   in the clouds,' detached from earthly everyday reality was complete.
   Paradoxically, the room most difficult to interpret is the entrance
   floor. Its unusual heterogeneity derives from the concentration of a
   complex array of various services and functions in one setting, as well
   as from the effort to give visitors a taste of what to expect from the
   tower's other interior space as they arrived at the hotel. And all this
   was cemented together by the mountain landscape visible through the full
   glass walls, topped off by the effort to `embrace' the guest in a warm,
   cosy interior.
   Art was an inseparable part of post-war Czech modern architecture, and
   at Jested it strikingly enhanced the interior design with poetic
   references to nature and to materials (the hammered metalwork of Milos
   Koska, Shooting Meteorites by Jaroslava Brychtova and Stanislav
   Libensky, ceramic tiling by Devana Mirova, the motif of a bright sun on
   a tapestry by Vladimir krecan) or to the countryside (Jaroslav Klapste's
   wrought-iron grille made out of agricultural tools used in bon-fires
   during traditional midsummer celebrations, Karel Wunsch's table linen,
   etc.). The artists accommodated the generally intense atmosphere and the
   objectives of the tower's architects and designed and made wholly
   original works in their respective fields.
   The functional infrastructure was characterised by a rational utility
   and the prevailing use of standard materials, components, and designs
   typical of the period in which the hotel was built. Nevertheless, the
   unusual shape of the ground plan, the size and unusual nature of the
   commission, and above all the generously democratic approach that Otakar
   Binar took to the project resulted in the creation of a number of
   extraordinary designs (the H-series furniture, the white RAKO tiling in
   the rooms of the staff, the built-in furniture).
   Currently the condition of the interior understandably reflects its four
   decades of intense use. The lack of investment and structural
   renovations during the 1970s and 1980s, the rather insensitive and
   negligent style of maintenance practised in the socialist era, but even
   the foresighted nature of the original craftsmanship have resulted in
   most of the features fortunately surviving in a singularly authentic
   state, albeit with various coats of paint, changes in colour scheme,
   minor damage, and some updates to obsolete technology, etc. In general
   furnishings connected with the structure and individual works of art
   have survived more or less intact. The furniture pieces, however, bear
   the marks of thoughtless renovations or in many cases have suffered
   large, irreversible losses (especially in the restaurant).
   A thoughtful approach, a feeling for a synergetic balance between
   landscape + structure + interior + art, the ability to collaborate with
   specialists and potential suppliers to find truly individual solutions
   and to determine a strategy for a future mixed-mode of uses (e.g. museum
   + original + mixed + new functions) can only reward the owner and
   operators: the competitiveness and long-term functional viability of
   Jested Mountain Hotel and Television Tower rest primarily on its
   uniqueness.
   Just as the tower structure was not just a celebration of technology and
   landscape, the culmination of the modernist movement in the Czech and
   international architectural scene, so too the interior fulfilled higher
   ambitions the overriding effort to achieve a balance between the
   panoramic view of the magnificent landscape and an attempt to create a
   warm, welcoming interior environment, topped off, in the spirit of
   contemporary endeavours, with some irrational elements. If Hubacek's
   structure represented `a reconciliation of landscape and technology',
   then Binar's and Wunsch's interior designs constituted `a reconciliation
   of landscape, technology, and man.'}},
ISSN = {{0044-8680}},
Unique-ID = {{ISI:000340974500006}},
}

@inproceedings{ ISI:000335680000014,
Author = {Chatzidimitris, Thomas and Kavakli, Evangelia and Economou, Maria and
   Gavalas, Damianos},
Book-Group-Author = {{IEEE}},
Title = {{Mobile Augmented Reality edutainment applications for cultural
   institutions}},
Booktitle = {{2013 FOURTH INTERNATIONAL CONFERENCE ON INFORMATION, INTELLIGENCE,
   SYSTEMS AND APPLICATIONS (IISA 2013)}},
Year = {{2013}},
Pages = {{75-78}},
Note = {{4th International Conference on Information, Intelligence, Systems and
   Applications (IISA), Piraeus, GREECE, JUL 10-12, 2013}},
Organization = {{IEEE; Biol \& Artificial Intelligence Fdn; Univ Piraeus, Dept Informat}},
Abstract = {{The paper focuses on current practice regarding the application of
   mobile Augmented Reality (AR) technologies for enabling learning in the
   context of cultural heritage. It also presents ARmuseum, an application
   developed for the Museum of Industrial Olive Oil Production in Lesvos
   (MBEL). Finally, it discusses a number of issues related to the
   evaluation of mobile AR applications for cultural institutions.}},
ISBN = {{978-1-4799-0770-0}},
Unique-ID = {{ISI:000335680000014}},
}

@inproceedings{ ISI:000334028200010,
Author = {Kun, Luis},
Book-Group-Author = {{IEEE}},
Title = {{ISTAS 2013: Invited Plenary Session ``Healthcare \& Public Health:
   Perspectives on Wearable Computing, Augmented Reality and the
   Veillances{''}}},
Booktitle = {{2013 IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGY AND SOCIETY (ISTAS)}},
Series = {{IEEE International Symposium on Technology and Society}},
Year = {{2013}},
Pages = {{72-73}},
Note = {{IEEE International Symposium on Technology and Society (ISTAS), Univ
   Toronto, Engn Bahen Ctr Informat Technol, Toronto, CANADA, JUN 27-29,
   2013}},
Organization = {{IEEE; Univ Toronto; IEEE Soc Social Implicat Technol; Univ Wollongong;
   Int Federat Med \& Biol Engn; Prod Safety Engn Soc; ACM Comp Soc; Epson;
   APX Labs; MetaView; Autographer; Streamfolio; buildAR; Uberveillance;
   Optinvent; Cisco; Singularity Weblog; Augmented Real Org; Augmate Corp;
   Infin AR; Inst Infocomm Res}},
Abstract = {{In the past decade during IEEE sponsored professional meetings(2),(3)
   the theme of ``Global Health Transformation through true
   Interoperability{''} was brought to the forefront in the inaugural
   keynotes. Some technologies that started with the monitoring of
   hemodynamic variables of astronauts by NASA in the 60s were further
   developed by the Department of Defense for the purposes of treating
   their injured in the battlefield via Telemedicine. By August 511, 1997
   President Clinton signed the first piece of legislation that was
   allowing the concepts of homecare to be tried to measure cost and
   medical effectiveness. With the development of Internet, the World Wide
   Web (WWW), social media, intelligent agents, mobile technology, sensors,
   and pieces of clothing containing them a new generation of devices have
   been created offering new possibilities for improvements particularly in
   areas such assist of living (for those suffering from chronic
   conditions), and homecare in general. The use of wearable computing in
   general and the use of augmented reality in the developed world in
   particular offer some unique opportunities to improve outcomes. In the
   21(st) Century and as the Health Care and Public Health infrastructure
   intersect deeper into the many Information Technology (IT) subfields,
   abundant and formidable changes can occur that will allow society to
   shift current systems into some where wellness and disease prevention
   will be the focus. Many changes can affect positively medical and cost
   effective outcomes as well as the elimination of medical errors and
   patient safety for example. In these arenas, with the convergence of
   science, technology and with Information Technology acting as a catalyst
   for change, health care systems around the world are slowly shifting
   from -hospital based{''} ones into distributed systems that include:
   hospitals, clinics, homecare systems with treatment and management of
   chronic diseases for the elderly via Internet, etc. In order to achieve
   such visions, multiple efforts have been tried for creating electronic
   health record as well as the information highway for their use. In the
   US the health system is very scattered and most hospital systems do not
   contain for example mental health, dental health and or vaccine registry
   information. On one hand through major medical research the emergence of
   clinical and health data repositories or ``Intelligent Data
   Warehouses{''} that not only include traditional clinical data, but also
   advanced imaging, molecular medicine, tissue micro-array analysis and
   other bioinformatics information is available. These increasingly
   multi-modality data warehouses are constantly updated, continuously
   expanded and populated with millions of records. Although these
   repositories of electronic information can be leveraged not only to
   improve point of care clinical decision-making for individual patients,
   they can also support population health chronic and infectious disease
   analytics (i.e., epidemiology and surveillance), cost efficient
   multi-center (e.g., and multi-country) clinical trials, and
   comprehensive post-market pharmaco-vigilance. On the other hand the
   integration of healthcare and public health is a major concern as well.
   Globalization (i.e., the interdependencies that each country has with
   many others) for example has raised the sense of awareness through ``the
   information highway{''}. In 2004 the total production of flu vaccines
   coming to the US from the UK's Chiron had to be thrown away
   (approximately in the range of 42 to 44 million vaccines).
   During and since 2007 the US public has learnt through successive media
   stories related to: the death of pets due to food-import contamination,
   children's toys imports containing lead paint, food contamination, drug
   contamination, drug ingredients contaminated, etc. During 2008 we heard
   about: People getting very sick from fish containing the ciguatera toxin
   and Tab / drinking water containing about 36 different medications,
   e.g., antibiotics, antidepressants, etc. As the northern hemisphere
   prepared for the second wave of the 2009 H1N1 Flu Pandemic (which was
   expected to start around October 2009) all nations could have benefited
   by having epidemiology and surveillance data from all southern
   hemisphere nations available for the production of more ``accurate{''}
   vaccines. In 2011 the European Union had to cut back in their
   consumption of vegetables and fruit because of an e-coli outbreak.
   Simultaneously the food from Asia in sonic cases was contaminated with
   radiation from the nuclear disaster caused by the combination of
   earthquake / tsunami at the Fukushima site. In South America the
   eruption of the volcano Puyehue in Chile closed all the airports in
   Uruguay, Argentina, Paraguay and the south of Brazil. All of these
   events resulted in major conflicts regarding world demand for food
   supplies. Still the perfect opportunity to transform our health care
   systems to a strategy of disease prevention and wellness is in the
   horizon. Using information technology as an enabler, we can encompass a
   wide range of opportunities that can start at the cellular, molecular
   and genetics levels and go as far as population health. Initial
   immunization studies show the level of antibody titers against viral
   diseases depends on the circadian time of inoculation. The concepts of
   chronobiology and chrono-therapeutics can be used to generate disease
   prevention strategies based on these circadian-rhythm dependencies.
   Just imagine how the public could also be better protected not only
   against environmental threats, water contamination, food borne diseases
   through the use of remote sensing data and a worldwide food enterprise
   architecture, but through alerts that could flow into a person through
   Wearable Computing, Augmented Reality and the Veillances. Data,
   Information, Knowledge and Wisdom could ``flow{''} into an individual
   alerting him/her that they need to immediately visit their doctor, or
   stop consuming certain products. Some examples of our current problem
   environment could change outcomes by using these tools:
   1. Getting the right information at the right time ---the steroid
   injection that they got for pain from laboratory x (in Massachusetts) is
   contaminated ( Just in the USA, between September 2012 and March 2013 at
   least 44 people have died and over 700 are contaminated from fungal
   meningitis according to the CDC) and their life may be at risk;
   2. Preventing potential water and or food poisoning --- on February
   4(th,), 2013, a report regarding the drinking water in many places
   within the State of California containing large amounts of Arsenic.
   Since we eat year round vegetables and fruits, livestock, poultry, etc.
   from that State, it may require the public to be cautious.
   As discovery from new research expands our knowledge about our body, its
   genome, and the cause-effect of new drugs, it also provides an
   opportunity to bring not only all these types of information to the
   forefront of the patient regardless where she /he may be at, but enable
   the transition from a system that has focused on disease to one that
   will focus on wellness through prevention and hopefully improve the
   quality of our lives.}},
ISSN = {{2158-3404}},
ISBN = {{978-1-4799-1242-1; 978-1-4799-0929-2}},
Unique-ID = {{ISI:000334028200010}},
}

@inproceedings{ ISI:000332829800045,
Author = {Salz, Jonah and Shiba, Masahito and Soga, Asako},
Book-Group-Author = {{IEEE}},
Title = {{Spectator Interaction with CG Animations in Noh-Style Performance:
   Hanging by a Thread}},
Booktitle = {{2013 INTERNATIONAL CONFERENCE ON CULTURE AND COMPUTING (CULTURE AND
   COMPUTING 2013)}},
Year = {{2013}},
Pages = {{173+}},
Note = {{International Conference on Culture and Computing (Culture and
   Computing), Kyoto, JAPAN, SEP 16-18, 2013}},
Abstract = {{How do you effectively use interactive technologies to involve
   spectators in a live performance without distracting from the atmosphere
   or storyline? We have been producing theatrical performances using
   computer graphics (CG) and interactive techniques. Our goal has been to
   use information technologies such as CG, augmented reality (AR), and
   interactive techniques in live stage performance. We sought to use
   interactive technology to involve spectators in a production employing
   projected screen imagery of CG characters in adaptations of Akutagawa
   Ryunosuke A Spider's Thread. This paper introduces the technology
   employed and resulting performance, focusing on one climate scene of
   spectator involvement in ``lottery{''}, as well as review of spectators'
   post-performance questionnaires.}},
DOI = {{10.1109/CultureComputing.2013.52}},
ISBN = {{978-0-7695-5047-3}},
Unique-ID = {{ISI:000332829800045}},
}

@inproceedings{ ISI:000331439800059,
Author = {Dubska, Marketa and Szentandrasi, Istvan and Zacharias, Michal and
   Herout, Adam},
Book-Group-Author = {{IEEE}},
Title = {{Poor Man's SimulCam: Real-Time And Effortless MatchMoving}},
Booktitle = {{2013 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2013}},
Pages = {{249-250}},
Note = {{12th IEEE and ACM International Symposium on Mixed and Augmented Reality
   - Arts, Media, and Humanities (ISMAR-AMH), Univ S Australia, City E
   Campus, Adelaide, AUSTRALIA, OCT 01-04, 2013}},
Organization = {{IEEE; ACM}},
Abstract = {{In this article, we propose an instant matchmoving solution for green
   screen. It uses a recent technique of planar uniform marker fields.
   Marker fields are an extension of planar markers used in augmented
   reality, offering better reliability and performance suitable for our
   task: tolerance to occlusion, speed of detection, and use of arbitrary
   low-contrast colors. We show that marker fields of shades of green (or
   blue or other color) can be used to obtain an instant and effortless
   camera pose estimation.
   We provide exemplar applications of the presented technique: virtual
   camera/simulcam and live storyboarding or shot prototyping. The
   matchmoving technique based on marker fields of shades of green is very
   computationally efficient - our measurements show that the matchmoving
   preview and living storyboard editing and recording can be easily done
   on today's ultramobile devices. Our technique is thus available to
   anyone at low cost and with easy setup, opening space for new levels of
   filmmakers' creative expression.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4799-2869-9}},
Unique-ID = {{ISI:000331439800059}},
}

@inproceedings{ ISI:000329495800112,
Author = {Nazir, Salman and Colombo, Simone and Manca, Davide},
Editor = {{Kraslawski, A and Turunen, I}},
Title = {{Testing and analyzing different training methods for industrial
   operators: an experimental approach}},
Booktitle = {{23 EUROPEAN SYMPOSIUM ON COMPUTER AIDED PROCESS ENGINEERING}},
Series = {{Computer-Aided Chemical Engineering}},
Year = {{2013}},
Volume = {{32}},
Pages = {{667-672}},
Note = {{23rd European Symposium on Computer Aided Process Engineering (ESCAPE),
   Lappeenranta, FINLAND, JUN 09-12, 2013}},
Abstract = {{Process industry is known for its complexity and sensitivity with
   critical procedures saturated with demanding human-machine interfaces
   that may induce human errors thus resulting in abnormal situations.
   Abnormal situations may lead to near misses and even to severe
   accidents, which can result in loss of production and even in casualties
   and fatalities. This paper aims at abridging the gap between the highly
   demanding human machine interfaces and the training methods employed in
   the process industry by experimentally analyzing the effectiveness of
   distinct training methods in a virtually simulated abnormal situation.
   The performance of operators is measured by means of suitable Key
   Performance Indicators (KPIs) applied to the specific case study. In
   particular, we analyze experimentally two distinct training methods
   based respectively on a Power Point presentation and a 3D virtual
   environment. The positive outcomes of this approach consist in
   increasing the reliability, cost effectiveness, environmental
   friendliness, and safety of the process. This work is the result of the
   interaction between chemical engineers and experimental psychologists,
   which may open new horizons to scientific research.}},
ISSN = {{1570-7946}},
ISBN = {{978-0-444-63234-0}},
ORCID-Numbers = {{Colombo, Simone/0000-0003-0397-1825
   Nazir, Salman/0000-0002-2058-6147}},
Unique-ID = {{ISI:000329495800112}},
}

@inproceedings{ ISI:000325093300051,
Author = {Woeldecke, Bjoern and Marinos, Dionysios and Geiger, Chris},
Editor = {{Lecuyer, A and Steinicke, F and Billinghurst, M}},
Title = {{Poster: MagicLensVS - Towards a Flexible Framework for Quick Setup of
   Visual Feedback in a Virtual Studio}},
Booktitle = {{2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI)}},
Year = {{2013}},
Pages = {{183-184}},
Note = {{IEEE Symposium on 3D User Interface, Orlando, FL, MAR 16-17, 2013}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Visualizat \& Graph Tech Comm; IEEE Comp Soc
   Visualizat \& Graph Tech Comm; Haption; Sig3DUI; Dassault Syst; Grand;
   3dvia; ASUS; Inria; Assoc Francaise Realite Virtuelle, Augmentee, Mixte
   \& Interact 3D; AMD; Im in VR}},
Abstract = {{In this paper, we present the current work in progress of the
   MagicLensVS, which is a flexible framework for visual feedback in a
   virtual studio environment. Our ambition is to facilitate the creation
   of richer content in TV productions by improving the interaction between
   actors and virtual objects. To make this possible, visual feedback
   techniques are needed for the involved staff to assist them with their
   work. The current result is the foundation of a framework for
   calibration and visualization of multiple mobile and stationary displays
   and tracking data. In this context, we also developed an initial
   prototype of a novel multitouch interaction technique which allows for
   quick calibration of extrinsic camera parameters.}},
ISBN = {{978-1-4673-6098-2}},
Unique-ID = {{ISI:000325093300051}},
}

@inproceedings{ ISI:000324243800036,
Author = {Kubac, Lukas and Benes, Filip and Kebo, Vladimir and Stasa, Pavel},
Editor = {{Petras, I and Podlubny, I and Kacur, J and Nawrocka, A and Sapinski, B}},
Title = {{RFID and Augmented Reality}},
Booktitle = {{PROCEEDINGS OF THE 2013 14TH INTERNATIONAL CARPATHIAN CONTROL CONFERENCE
   (ICCC)}},
Year = {{2013}},
Pages = {{186-191}},
Note = {{14th International Carpathian Control Conference (ICCC), Rytro, POLAND,
   MAY 26-29, 2013}},
Organization = {{IEEE; IEEE Czechoslovakia Sect; AGH Univ Sci \& Technol, Fac Mech Engn
   \& Robot, Dept Proc Control; Tech Univ Kosice, Fac Min, Ecol, Proc
   Control \& Geotechnol, Inst Control \& Informatizat Prod Proc; Tech Univ
   Ostrava (VSB), Fac Mech Engn, Dept Control Syst \& Instrumentat; Tech
   Univ Ostrava (VSB), Fac Min \& Geotechnol, Inst Econ \& Control Syst;
   Univ Miskolc, Dept Automat \& Commun Technol; Univ Craiova, Fac Automat,
   Comp \& Elect, Dept Automat Control}},
Abstract = {{Nowadays we are witnessing a deeper penetration of technological
   advances into our lives. Still stronger penetration of smart phones and
   tablets into daily life opens the door of advanced Augmented Reality
   application potential which has been so far used mainly for advertising
   and gaming purposes. Along with this trend, we follow the growing
   importance of radio frequency identification technology (RFID). RFID
   technology is designed mainly to gather information and data on the
   behavior and state of the monitored objects. Identification and
   localization of moving objects in space is necessary for effective
   management in production processes. The aim of our research is to find
   synergies in the use of augmented reality with the benefits provided by
   RFID tags.}},
ISBN = {{978-1-4673-4490-6}},
Unique-ID = {{ISI:000324243800036}},
}

@inproceedings{ ISI:000322535300013,
Author = {Margolis, Todd and Cornish, Tracy},
Editor = {{Dolinsky, M and McDowall, IE}},
Title = {{Vroom: Designing an augmented environment for remote collaboration in
   digital cinema production}},
Booktitle = {{ENGINEERING REALITY OF VIRTUAL REALITY 2013}},
Series = {{Proceedings of SPIE}},
Year = {{2013}},
Volume = {{8649}},
Note = {{Conference on Engineering Reality of Virtual Reality, Burlingame, CA,
   FEB 04-05, 2013}},
Organization = {{Soc Imaging Sci \& Technol (IS\&T); SPIE; Qualcomm Inc}},
Abstract = {{As media technologies become increasingly affordable, compact and
   inherently networked, new generations of telecollaborative platforms
   continue to arise which integrate these new affordances. Virtual reality
   has been primarily concerned with creating simulations of environments
   that can transport participants to real or imagined spaces that replace
   the ``real world{''}. Meanwhile Augmented Reality systems have evolved
   to interleave objects from Virtual Reality environments into the
   physical landscape. Perhaps now there is a new class of systems that
   reverse this precept to enhance dynamic media landscapes and immersive
   physical display environments to enable intuitive data exploration
   through collaboration.
   Vroom (Virtual Room) is a next-generation reconfigurable tiled display
   environment in development at the California Institute for
   Telecommunications and Information Technology (Calit2) at the University
   of California, San Diego. Vroom enables freely scalable digital
   collaboratories, connecting distributed, high-resolution visualization
   resources for collaborative work in the sciences, engineering and the
   arts. Vroom transforms a physical space into an immersive media
   environment with large format interactive display surfaces, video
   teleconferencing and spatialized audio built on a high-speed optical
   network backbone.
   Vroom enables group collaboration for local and remote participants to
   share knowledge and experiences. Possible applications include: remote
   learning, command and control, storyboarding, post-production editorial
   review, high resolution video playback, 3D visualization, screencasting
   and image, video and multimedia file sharing. To support these various
   scenarios, Vroom features support for multiple user interfaces (optical
   tracking, touch UI, gesture interface, etc.), support for directional
   and spatialized audio, giga-pixel image interactivity, 4K video
   streaming, 3D visualization and telematic production. This paper
   explains the design process that has been utilized to make Vroom an
   accessible and intuitive immersive environment for remote collaboration
   specifically for digital cinema production.}},
DOI = {{10.1117/12.2008587}},
Article-Number = {{UNSP 86490F}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-9422-1}},
Unique-ID = {{ISI:000322535300013}},
}

@inproceedings{ ISI:000342231600003,
Author = {Finkbeiner, Stefan},
Book-Group-Author = {{IEEE}},
Title = {{MEMS for automotive and consumer electronics}},
Booktitle = {{2013 PROCEEDINGS OF THE EUROPEAN SOLID-STATE DEVICE RESEARCH CONFERENCE
   (ESSDERC)}},
Series = {{Proceedings of the European Solid-State Device Research Conference}},
Year = {{2013}},
Pages = {{9-14}},
Note = {{43rd Conference on European Solid-State Device Research, Bucharest,
   ROMANIA, SEP 16-20, 2013}},
Organization = {{Infineon; Minist Educ Natl; Cadence Acad Network; Mentor Graph; Eniac;
   Univ Politechnica Din Bucuresti; Univ Tehnica Gheorghe Asachi; Ecole
   Polytechnique Federale De Lausanne; Univ Cambridge}},
Abstract = {{Micro-Electro-Mechanical Systems (MEMS) are sensing the environmental
   conditions and give input to electronic control systems. MEMS are
   miniature systems which usually combine tiny mechanical structures with
   electronic circuits. Typical MEMS structures have a size of a few
   micrometers. MEMS sensors make system reactions to human needs more
   intelligent, precise, and at much faster reaction rates than humanly
   possible. Today MEMS sensors can be found in nearly every motor vehicle,
   smart phone or laptop. Due to continuous product innovations, the
   sensors find their way into more and more applications in automotive and
   consumer electronics. According to IHS iSuppli an amount of 4.3 billion
   micromechanical sensors were sold in 2011 with an impressive increase to
   9.8 billion sensors in 2015 - a growth rate of 23\% per year! These
   growth rates are only possible with continuous efforts to improve the
   performance and to decrease the size, power consumption and costs of the
   sensors.
   Historically, these improvements have lead to the breakthrough to
   industrial mass production for MEMS. This was achieved over the last 20
   years by intense and successful development activities combined with the
   experience of volume production of billions of sensors.
   Since then, MEMS technology has enabled accelerometers, gyroscopes,
   geomagnetic sensors, barometric pressure sensors, inkjet nozzles or
   micro-mirrors for Digital-Light Processing (DLP) projection systems.
   Driving future applications in consumer electronics will be
   Human-Machine Interfaces (HMI), Augmented Reality (AR) and in-door
   navigation.}},
ISSN = {{1930-8876}},
ISBN = {{978-1-4799-0649-9}},
Unique-ID = {{ISI:000342231600003}},
}

@inproceedings{ ISI:000346798301025,
Author = {Hui, Vincent and Compeau, Matthew and Pu, Kevin and Arabian, Tricia},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{ELIMINATING VIRTUAL BARRIERS vertical bar AUGMENTED REALITY IN
   ARCHITECTURAL DESIGN THROUGH THE ARCH-VIZ PROJECT}},
Booktitle = {{EDULEARN13: 5TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES}},
Series = {{EDULEARN Proceedings}},
Year = {{2013}},
Pages = {{1137-1143}},
Note = {{5th International Conference on Education and New Learning Technologies
   (EDULEARN), Barcelona, SPAIN, JUL 01-03, 2013}},
Abstract = {{The use of computer modeling and simulation tools in design programs has
   become ubiquitous over the past two decades yet with such incredible
   advances, students remain detached from the real world of bringing their
   designs to reality. Though photorealistic imagery, high fidelity
   simulation, and hyper levels of detail are possible within the virtual
   work environment, the translation to real world conditions remains a
   significant barrier for students with even the greatest of digital media
   skill. This is most notable within the context of architectural design.
   To this day there are very few accessible tools that empower designers
   to posit their ideas into reality and ensure an iterative design process
   may emerge.
   This paper outlines the development and adoption of a prototype tool,
   tentatively dubbed Arch-Viz, that bridges this gap between the virtual
   and the real world contexts. Beta-tested within a second year
   architectural design studio in Canada's largest city, Toronto, the
   Arch-Viz project has allowed students to seamlessly transition from
   initial design of buildings in primitive, physical models to digital CAD
   models, and finally at full scale in the real world using an augmented
   reality system. By overlaying digital model information atop real world
   conditions using contrast codes and geo-location, the Arch-Viz project
   promises to be a design and production paradigm that designers, not
   exclusively architects, may adopt in the future.}},
ISSN = {{2340-1117}},
ISBN = {{978-84-616-3822-2}},
Unique-ID = {{ISI:000346798301025}},
}

@inproceedings{ ISI:000346798301148,
Author = {Kirner, Claudio and Kirner, Tereza Goncalves},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{DEVELOPMENT OF ONLINE EDUCATIONAL GAMES WITH AUGMENTED REALITY}},
Booktitle = {{EDULEARN13: 5TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES}},
Series = {{EDULEARN Proceedings}},
Year = {{2013}},
Pages = {{1950-1959}},
Note = {{5th International Conference on Education and New Learning Technologies
   (EDULEARN), Barcelona, SPAIN, JUL 01-03, 2013}},
Abstract = {{The Horizon Report, in its last three annual publications, divulged in
   2011, 2012, and 2013, pointed out games and augmented reality as
   technological trends in educational applications. However, the use of
   these technologies in education is facing difficulties, due to the
   requirement of deep technical knowledge for the production of such
   applications. Typically, educational applications are of general purpose
   and rarely allow adaptation, making teachers and students to simply
   become consumers of ready-made applications, which often is not really
   useful. This article intends to present that it is possible to change
   this situation, by means of strategies that give conditions to the
   teacher to be an adapter of educational applications or even a creator
   of them, even without deep technical knowledge. In this sense, an online
   educational game with augmented reality and adaptability has been
   implemented to illustrate this possibility. The game presented in this
   work focuses on the geometry area and uses augmented reality, exploring
   geometric solids generated by revolution of plane figures. The authoring
   tool used to develop the game is also presented, showing the features
   that make it suitable for use by teachers and students, in schools, at
   home, or anywhere that has an Internet connection. These features
   include visual interface, simplicity, adaptability of applications, and
   interaction with the mouse or with other ways of tangible interaction,
   as a marker. The game about geometry was evaluated by students of
   undergraduate courses and distance education, who participated in its
   review by filling out a questionnaire, after using the application. The
   results of this evaluation allowed the identification of strengths and
   weaknesses of the game, also indicating possible improvements.}},
ISSN = {{2340-1117}},
ISBN = {{978-84-616-3822-2}},
Unique-ID = {{ISI:000346798301148}},
}

@inproceedings{ ISI:000346798306044,
Author = {Hui, Vincent and Newman-Bremang, Kwame and Townsend, Scott},
Editor = {{Chova, LG and Martinez, AL and Torres, IC}},
Title = {{UNCONVENTIONAL {[}AR]TWORKS vertical bar A PROTOTYPE FOR A PEDAGOGICAL
   FRAMEWORK FOR TEMPORARY ART}},
Booktitle = {{EDULEARN13: 5TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES}},
Series = {{EDULEARN Proceedings}},
Year = {{2013}},
Pages = {{6301-6307}},
Note = {{5th International Conference on Education and New Learning Technologies
   (EDULEARN), Barcelona, SPAIN, JUL 01-03, 2013}},
Abstract = {{Unlike traditional cultural institutions such as museums, art galleries,
   and performing arts centers, current cultural discourse often exists and
   is developed in impromptu, unconventional, and temporal environments
   ranging from the virtual realm of online worlds to the charged dynamics
   of streets in the urban environment. Two extremes are at play. While
   established cultural facilities oversee curatorial discretion in
   permitting visitors to engage material often for a fee within a
   preordained timeframe (i.e. a theatrical production or exhibition
   opening), online platforms allow visitors to pore through the incredible
   amounts of information free of charge and other conventional
   constraints. Despite these polarities, the cultural activity emergent
   from street life and the cultural dynamics arising from urban
   environments has also remained a strong force in a society's cultural
   development, from street performers to Speakers' Corners. This has also
   been the trend in contemporary art. The rarified and hallowed world of
   art galleries and exhibition halls must now compete with a range of
   enthusiastic, ephemeral, and ever-changing work in settings such as
   street festivals to more formalized programs such as Nuit Blanche.
   Though such organizations are exceptionally potent in showcasing to not
   only the general public, but emerging artists and students, there has
   been little in the way of ensuring such short-lived events may be
   properly documented to serve as educational resources for future
   generations.
   This paper outlines the design, development, and prototyping of
   contemporary mobile computing, via an augmented reality app entitled
   {[}AoR]t Works, in not only reinforcing the documentation of these
   contemporary art works, but also in providing a robust and innovative
   way to understand the projects in the built environment. From guided
   tours and the layering of multiple temporary works upon a shared
   specific site in the urban environment, to interviews with installation
   artists and developmental materials, the framework of the {[}AR]t Works
   project serves as an excellent tool in not only preserving the creative
   works in the urban condition, but also in continuing the development of
   emergent artists and designers in the future.}},
ISSN = {{2340-1117}},
ISBN = {{978-84-616-3822-2}},
Unique-ID = {{ISI:000346798306044}},
}

@inproceedings{ ISI:000349067200027,
Author = {Martoch, Tomas and Kodym, Oldrich},
Book-Group-Author = {{SGEM}},
Title = {{PRODUCTION INFORMATION SYSTEMS BASED ON THE INTERNET OF THINGS}},
Booktitle = {{GEOCONFERENCE ON INFORMATICS, GEOINFORMATICS AND REMOTE SENSING -
   CONFERENCE PROCEEDINGS, VOL I}},
Series = {{International Multidisciplinary Scientific GeoConference-SGEM}},
Year = {{2013}},
Pages = {{207-212}},
Note = {{13th International Multidisciplinary Scientific Geoconference, SGEM
   2013, Albena, BULGARIA, JUN 16-22, 2013}},
Abstract = {{This paper describes some new perspectives on Information systems with
   utilization of Internet of Things technology. Hierarchical information
   system with distributed data source is discussed from point of view of
   dispatching and control systems (SCADA, HMI) and standardization
   process.
   The paper is complemented by the perspective of Internet of Things -
   Internet of Processes, Internet of Services with spin off to virtual
   reality presentation, especially usage of augmented reality, which can
   be used as display tool where the better understanding of process is
   demanded. Models and simulation of technological processes are discussed
   too.}},
ISSN = {{1314-2704}},
ISBN = {{978-954-91818-9-0}},
Unique-ID = {{ISI:000349067200027}},
}

@inproceedings{ ISI:000349067200034,
Author = {Benes, Filip and Kubac, Lukas and Stasa, Pavel and Kebo, Vladimir and
   Kodym, Oldrich},
Book-Group-Author = {{SGEM}},
Title = {{THE POTENTIAL OF RFID AND AUGMENTED REALITY}},
Booktitle = {{GEOCONFERENCE ON INFORMATICS, GEOINFORMATICS AND REMOTE SENSING -
   CONFERENCE PROCEEDINGS, VOL I}},
Series = {{International Multidisciplinary Scientific GeoConference-SGEM}},
Year = {{2013}},
Pages = {{257-264}},
Note = {{13th International Multidisciplinary Scientific Geoconference, SGEM
   2013, Albena, BULGARIA, JUN 16-22, 2013}},
Abstract = {{The article deals with synergies of augmented reality, and REED
   technologies that could be an integral part of control and monitoring
   systems in mining industry. Still stronger penetration of smart phones
   and tablets into daily life opens the door of advanced Augmented Reality
   application potential. Along with this trend, we follow the growing
   importance of radio frequency identification (RFID) technology. RFID
   technology is designed mainly to gather information and data on the
   behavior and state of the controlled and monitored objects.
   Identification and localization of moving objects in space is necessary
   for effective management in mining production processes. The aim of our
   research is to find synergies in the use of augmented reality with the
   benefits provided by RED tags. The first steps have been taken in the
   visualization of RFID antennas interrogation fields.}},
DOI = {{10.5593/SGEM2013/BB2.V1/S07.034}},
ISSN = {{1314-2704}},
ISBN = {{978-954-91818-9-0}},
Unique-ID = {{ISI:000349067200034}},
}

@inproceedings{ ISI:000368423200087,
Author = {Reffat, R. M. and Nofal, E. M.},
Editor = {{Grussenmeyer, P}},
Title = {{EFFECTIVE COMMUNICATION WITH CULTURAL HERITAGE USING VIRTUAL
   TECHNOLOGIES}},
Booktitle = {{XXIV INTERNATIONAL CIPA SYMPOSIUM}},
Series = {{International Archives of the Photogrammetry Remote Sensing and Spatial
   Information Sciences}},
Year = {{2013}},
Volume = {{40-5-W2}},
Pages = {{519-524}},
Note = {{24th International CIPA Symposium, Strasbourg, FRANCE, SEP 02-06, 2013}},
Abstract = {{Cultural heritage is neither static nor stable. There is a need to
   explore ways for effectively communicating with cultural heritage to
   tourists and society at large, in an age of immediacy, a time of
   multiple realities and to multi-cultural tourists. It is vital to
   consider cultural heritage as a creative and relational process where
   places and communities are constantly remade through creative
   performance. The paper introduces virtual technologies as an approach to
   attain effective communication with cultural heritage. This approach
   emphasizes the importance of ``user, content and context{''} in guiding
   the production of virtual heritage, as opposed to technology being the
   sole motivator. It addresses how these three issues in virtual heritage
   need to be transformed from merely representing quantitative data
   towards cultural information using the proposed effective communication
   triangle through representing meaningful relationships between cultural
   heritage elements, users and context. The paper offers a focused
   articulation of a proposed computational platform of ``interactive,
   personalized and contextual-based navigation{''} with Egyptian heritage
   monuments as a one step forward towards achieving effective
   communication with Egyptian cultural heritage.}},
ISSN = {{2194-9034}},
Unique-ID = {{ISI:000368423200087}},
}

@article{ ISI:000305851200009,
Author = {Erskine, R. J.},
Title = {{Vaccination Strategies for Mastitis}},
Journal = {{VETERINARY CLINICS OF NORTH AMERICA-FOOD ANIMAL PRACTICE}},
Year = {{2012}},
Volume = {{28}},
Number = {{2}},
Pages = {{257+}},
Month = {{JUL}},
Abstract = {{Prevention of exposure is the foundation of infectious disease control
   programs, including mastitis. The tenets of mastitis prevention are
   maintaining cows in a clean, dry, comfortable environment and ensuring
   that recommended milking practices are consistently followed. Under the
   proper circumstances, vaccination can augment a herd mastitis control
   program. However, vaccination is essentially an insurance policy to
   mitigate losses. Thus, veterinarians who counsel dairy producers on
   mastitis vaccination programs should be able to assess the need,
   evaluate the available vaccines that could help resolve the problem, and
   establish a program that balances applied immunology with logistical
   reality of the dairy operation.}},
DOI = {{10.1016/j.cvfa.2012.03.002}},
ISSN = {{0749-0720}},
Unique-ID = {{ISI:000305851200009}},
}

@article{ ISI:000306141200005,
Author = {Blumenthal, Hank and Xu, Yan},
Title = {{The Ghost Club Storyscape: Designing for Transmedia Storytelling}},
Journal = {{IEEE TRANSACTIONS ON CONSUMER ELECTRONICS}},
Year = {{2012}},
Volume = {{58}},
Number = {{2}},
Pages = {{190-196}},
Month = {{MAY}},
Abstract = {{One of the key questions about transmedia storytelling is how to design
   a participant's experience across different media so that it is
   connected and perceived as a whole. We extract four design connectors
   for building such relationships from current work in media studies,
   production literature, and practice. These proposed design components
   are mythology, canon, character and genre. The goal of these connectors
   is to create relationships that form a whole work from stand-alone
   parts. To test this approach we have designed and developed a group of
   connected digital media expressions, The Ghost Club Storyscape, to
   experiment with these four ingredients on multiple media.}},
DOI = {{10.1109/TCE.2012.6227412}},
ISSN = {{0098-3063}},
Unique-ID = {{ISI:000306141200005}},
}

@article{ ISI:000297780000001,
Author = {Pan, Zengxi and Polden, Joseph and Larkin, Nathan and Van Duin, Stephen
   and Norrish, John},
Title = {{Recent progress on programming methods for industrial robots}},
Journal = {{ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING}},
Year = {{2012}},
Volume = {{28}},
Number = {{2}},
Pages = {{87-94}},
Month = {{APR}},
Abstract = {{Although an automated flexible production cell is an intriguing prospect
   for small to median enterprises (SMEs) in current global market
   conditions, the complexity of programming remains one of the major
   hurdles preventing automation using industrial robots for SMEs. This
   paper provides a comprehensive review of the recent research progresses
   on the programming methods for industrial robots, including online
   programming, offline programming (OLP), and programming using Augmented
   Reality (AR). With the development of more powerful 3D CAD/PLM software,
   computer vision, sensor technology, etc. new programming methods
   suitable for SMEs are expected to grow in years to come. (C) 2011
   Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.rcim.2011.08.004}},
ISSN = {{0736-5845}},
EISSN = {{1879-2537}},
ORCID-Numbers = {{pan, zengxi/0000-0002-1788-2543}},
Unique-ID = {{ISI:000297780000001}},
}

@article{ ISI:000301448100019,
Author = {Sheil, Bob},
Title = {{Distinguishing Between the Drawn and the Made}},
Journal = {{ARCHITECTURAL DESIGN}},
Year = {{2012}},
Volume = {{82}},
Number = {{2, SI}},
Pages = {{136-141}},
Month = {{MAR-APR}},
Abstract = {{Here Bob Sheil, Director of Technology and Computing at the Bartlett
   School of Architecture and co-organiser of the 2011 Fabricate Conference
   at UCL, pulls back on the rush towards material computation. With the
   blurring of the projected image and the constructed artefact, there is
   the very real danger of reducing architectural production to a
   systematic industrial exercise. This fails to recognise the extent to
   which ideas and performance are transformed, developed and refined
   through the very process of making. Copyright (C) 2012 John Wiley \&
   Sons, Ltd.}},
DOI = {{10.1002/ad.1390}},
ISSN = {{0003-8504}},
EISSN = {{1554-2769}},
Unique-ID = {{ISI:000301448100019}},
}

@inproceedings{ ISI:000320454200042,
Author = {Galambos, Peter and Weidig, Christian and Baranyi, Peter and Aurich, Jan
   C. and Hamann, Bernd and Kreylos, Oliver},
Book-Group-Author = {{IEEE}},
Title = {{VirCA NET: A Case Study for Collaboration in Shared Virtual Space}},
Booktitle = {{3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS
   (COGINFOCOM 2012)}},
Year = {{2012}},
Pages = {{272-276}},
Note = {{3rd IEEE International Conference on Cognitive Infocommunications
   (CogInfoCom), Kosice, SLOVAKIA, DEC 02-05, 2012}},
Organization = {{IEEE}},
Abstract = {{To take up the challenge of global distributed companies, Manufacturing
   Engineering has to be accomplished in a worldwide collaborative way.
   Design and development of production processes and their execution are
   nowadays spread all over the world. To ensure quality standards and to
   create synergies between spatially distributed entities, distance
   collaboration tools must be provided to allow cooperation even over
   large distances. The Virtual Reality (VR) is thereby offering beneficial
   capabilities to exchange current planning stages, identify problems and
   solve them cooperatively. This paper introduces a new approach for
   distance collaboration, which enables users to work in a joint virtual
   space, nearly as if they were working together in the same place.
   Therefore two full-immersive CAVE-like systems are interconnected using
   the VirCA (Virtual Collaboration Arena) platform. The paper describes
   the requirements of Mechanical Engineers towards distance collaboration
   tools and the technical challenges solved with the enhanced VirCA
   framework. This working prototype is one premier application in the
   field of VR-enhanced spatially distributed collaboration. A typical use
   case scenario is provided to highlight the interaction and cooperation
   capabilities offered by VirCA NET.}},
ISBN = {{978-1-4673-5188-1; 978-1-4673-2891-3}},
Unique-ID = {{ISI:000320454200042}},
}

@inproceedings{ ISI:000319512400010,
Author = {Marner, Michael R. and Haren, Sam and Gardiner, Matthew and Thomas,
   Bruce H.},
Book-Group-Author = {{IEEE
   ACM}},
Title = {{Exploring Interactivity and Augmented Reality in Theater: A Case Study
   of Half Real}},
Booktitle = {{2012 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - ARTS, MEDIA, AND HUMANITIES}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2012}},
Note = {{11th IEEE and ACM International Symposium on Mixed and Augmented Reality
   (ISMAR), Georgia Inst Technol, Atlanta, GA, NOV 05-08, 2012}},
Organization = {{IEEE; ACM}},
Abstract = {{This paper presents a case study of Half Real, a live action,
   interactive theater show employing spatial augmented reality. Half Real
   is based on a murder investigation, where the live audience votes on how
   the investigation proceeds. Half Real immerses live actors into a
   virtual world projected onto the set. Using spatial augmented reality
   technology in theater brings new possibilities that would not be
   possible with simple video projection. Half Real models the set as a 3D
   virtual environment. Actors are tracked as they move about on stage,
   with the projected content responding to their movements. A real time AR
   system allows content to be generated procedurally. Half Real makes use
   of this by projecting vote options and results directly into the virtual
   environment. This paper describes Half Real, with a focus on the
   technology used to make the production possible. We describe the
   benefits of the techniques used and the challenges faced during
   production.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4673-4665-8; 978-1-4673-4663-4}},
ResearcherID-Numbers = {{Thomas, Bruce/A-1470-2008}},
ORCID-Numbers = {{Thomas, Bruce/0000-0002-9148-085X}},
Unique-ID = {{ISI:000319512400010}},
}

@inproceedings{ ISI:000319516900048,
Author = {Oikawa, Marina Atsumi and Almeida, Igor de Souza and Taketomi, Takafumi
   and Yamamoto, Goshiro and Miyazaki, Jun and Kato, Hirokazu},
Book-Group-Author = {{IEEE
   ACM}},
Title = {{Augmented Prototyping of 3D Rigid Curved Surfaces}},
Booktitle = {{2012 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2012}},
Pages = {{307-308}},
Note = {{11th IEEE and ACM International Symposium on Mixed and Augmented Reality
   (ISMAR), Georgia Inst Technol, Atlanta, GA, NOV 05-08, 2012}},
Organization = {{IEEE; ACM}},
Abstract = {{This paper presents an application of Augmented Reality (AR) in Rapid
   Prototyping (RP) of non-textured rigid curved surfaces. By enhancing the
   prototypes with AR, evaluation of its design and aesthetic concepts in
   real-time becomes easier, saving time and production costs. In our
   application, no fiducial markers are required and the CAD model used to
   build the prototype is applied in an edge-based tracking system
   specially designed to deal with curved shapes. Results from a pilot user
   study comparing the use of a 3D software and the proposed application
   are also presented.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4673-4662-7}},
ResearcherID-Numbers = {{Oikawa, Marina/B-3316-2014}},
Unique-ID = {{ISI:000319516900048}},
}

@inproceedings{ ISI:000319516900052,
Author = {Sausman, John and Samoylov, Alexei and Regli, Susan Harkness and Hopps,
   Meredith},
Book-Group-Author = {{IEEE
   ACM}},
Title = {{Effect of Eye and Body Movement on Augmented Reality in the
   Manufacturing Domain}},
Booktitle = {{2012 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR)
   - SCIENCE AND TECHNOLOGY}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2012}},
Pages = {{315+}},
Note = {{11th IEEE and ACM International Symposium on Mixed and Augmented Reality
   (ISMAR), Georgia Inst Technol, Atlanta, GA, NOV 05-08, 2012}},
Organization = {{IEEE; ACM}},
Abstract = {{Understanding the eye and body movements required to perform large
   vehicle assembly tasks is important for developing a mobile support
   system for mechanics, and tracking user movements with regard to the
   surrounding environment is critical for designing a wearable Augmented
   Reality (AR) systems. This poster summarizes a study measuring the eye
   and body movements of mechanics performing assembly activities in a live
   manufacturing environment. It reviews our quantitative analysis of eye
   movements and qualitative analysis of body movements and describes the
   implications of this data in terms of the feasibility and potential
   utility of using a mobile AR application to support manufacturing. We
   found that the mechanics' eye movements ranged over a slightly larger
   field than the eye movements reported in previous research because of
   constraints imposed by some body positions required in manufacturing
   tasks.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4673-4662-7}},
Unique-ID = {{ISI:000319516900052}},
}

@inproceedings{ ISI:000313296505241,
Author = {Fuerst, David and Stephan, Daniel and Augat, Peter and Schrempf, Andreas},
Book-Group-Author = {{IEEE}},
Title = {{Foam Phantom Development for Artificial Vertebrae used for Surgical
   Training}},
Booktitle = {{2012 ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE
   AND BIOLOGY SOCIETY (EMBC)}},
Series = {{IEEE Engineering in Medicine and Biology Society Conference Proceedings}},
Year = {{2012}},
Pages = {{5773-5776}},
Note = {{34th Annual International Conference of the IEEE
   Engineering-in-Medicine-and-Biology-Society (EMBS), San Diego, CA, AUG
   28-SEP 01, 2012}},
Organization = {{IEEE; Engn Med \& Biol Soc (EMBS); CAS; SMC; PubMed; MEDLINE}},
Abstract = {{Currently the surgical training of kyphoplasty and vertebroplasty is
   performed on patients or specimens. To improve patient safety, a project
   was initiated to develop an Augmented Reality simulator for the surgical
   training of these interventions. Artificial vertebral segments should be
   integrated to provide realistic haptic feedback. To reach this,
   resulting forces during needle insertions (trans- and extrapedicular)
   into formalin-fixed vertebral specimens were measured. The same
   insertion procedure was also performed on six customized polyurethane
   blocks with varying mechanical parameters. Based on the results of these
   measurements, a specific foam phantom was generated and the insertion
   force measured. Additionally a parametric model for the needle insertion
   into bone was designed calculating three characteristic parameters for
   all insertion measurements. The resulting insertion force for the foam
   phantom was comparable to the specimen measurements and the parametric
   model provided comprehensible characteristic parameters. Based on the
   resulting force during needle insertion into human vertebrae, a possible
   foam recipe for manufacturing artificial segments was found.
   Furthermore, the parametric model provides characteristic parameters for
   the assessment of phantoms as well as the development of its production
   process.}},
ISSN = {{1557-170X}},
ISBN = {{978-1-4577-1787-1}},
ResearcherID-Numbers = {{Augat, Peter/A-2051-2011}},
ORCID-Numbers = {{Augat, Peter/0000-0003-4805-2128}},
Unique-ID = {{ISI:000313296505241}},
}

@inproceedings{ ISI:000392840200019,
Author = {Felinto, Dalai and Zang, Aldo Rene and Velho, Luiz},
Book-Group-Author = {{IEEE}},
Title = {{Production Framework for Full Panoramic Scenes with Photorealistic
   Augmented Reality}},
Booktitle = {{2012 XXXVIII CONFERENCIA LATINOAMERICANA EN INFORMATICA (CLEI)}},
Year = {{2012}},
Note = {{38th Latin America Conference on Informatics (CLEI), Medellin, COLOMBIA,
   OCT 01-05, 2012}},
Organization = {{IEEE; Latin Amer Ctr Informat Studies; IEEE Colombia}},
Abstract = {{The novelty of our workflow is the end-to-end solution to combine
   captured panoramas and computer generated elements. This pipeline
   supports productions specially aiming at spherical displays (e.g.,
   fulldomes). Full panoramas have been used in computer graphics for
   years, yet their common usage lays on environment lighting and
   reflection maps for conventional displays. With a keen eye in what may
   be the next trend in the filmmaking industry, we address the
   particularities of those productions, proposing a new representation of
   the space by storing the depth together with the light maps, in a full
   panoramic light-depth map.}},
ISBN = {{978-1-4673-0793-2; 978-1-4673-0794-9}},
Unique-ID = {{ISI:000392840200019}},
}

@inproceedings{ ISI:000353000800020,
Author = {Arief, Ibrahim and McCallum, Simon and Hardeberg, Jon Yngve},
Book-Group-Author = {{IS\&T}},
Title = {{Realtime Estimation of Illumination Direction for Augmented Reality on
   Mobile Devices}},
Booktitle = {{COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS:
   TWENTIETH COLOR AND IMAGING CONFERENCE}},
Series = {{Color and Imaging Conference Final Program and Proceedings}},
Year = {{2012}},
Pages = {{111-116}},
Note = {{20th Color and Imagaing Conference on Color Science and Engineering
   Systems, Technologies, and Applications, Los Angeles, CA, NOV 12-16,
   2012}},
Organization = {{Soc Imag Sci \& Technol; Soc Informat Display; Adobe; Canon; Kodak; hp;
   LENMARK; xerox; KYOCERA}},
Abstract = {{Augmented reality simulations aims to provide realistic blending between
   real world and virtual objects. One of the important factors for
   realistic augmented reality is correct illumination simulation. Mobile
   augmented reality systems is one of the best options for introducing
   augmented reality to the mass market due to its low production cost and
   ubiquitousness. In mobile augmented reality systems, the ability to
   correctly simulate in realtime the illumination direction that matches
   the illumination direction of the real world is limited. Developing a
   mobile augmented reality systems with the ability to estimate
   illumination direction presents a challenge due to low computation power
   and dynamically changing environment. In this paper; we described a new
   method that we have developed for realtime illumination direction
   estimation for mobile augmented reality systems, using analysis of
   shadow produced by a reference object that doubles as a 3D augmented
   reality marker. The implementation of the method could estimate the
   direction of a single strong light source in a controlled environment
   with a very good degree of accuracy, with angular error averaging lower
   than 0.038 radians. The current implementation achieved 2.1 FPS
   performance in a low-end Android mobile device, produced proper
   estimation within 15 seconds using a uniform surface, and demonstrated
   scalability potential.}},
ISSN = {{2166-9635}},
ISBN = {{978-0-89208-303-9}},
ORCID-Numbers = {{McCallum, Simon/0000-0003-3667-4544}},
Unique-ID = {{ISI:000353000800020}},
}

@inproceedings{ ISI:000337164500097,
Author = {Meza, S. and Turk, Z. and Dolenc, M.},
Editor = {{Gudnason, G and Scherer, R}},
Title = {{Augmenting reality with model information: Roles and opportunities}},
Booktitle = {{EWORK AND EBUSINESS IN ARCHITECTURE, ENGINEERING AND CONSTRUCTION}},
Year = {{2012}},
Pages = {{741-745}},
Note = {{9th European Conference on Product and Process Modelling, Reykjavik,
   ICELAND, JUL 25-27, 2012}},
Abstract = {{Today design information often takes the form of building information
   models (BIM). The physical reality of construction projects, however, is
   out there on the job site. It is on the job site where the PR of
   construction projects and the information from project documentation
   meet. A process inverse to the process of modeling is occurring.
   Establishing the relationship between these two aspects of construction
   has so far been exclusively the domain of human effort not assisted much
   by information technology. Many construction errors occur when the
   information in project documentation is poorly transferred to physical
   reality either because the information is misunderstood or misused.
   There have been numerous attempts to try to minimize these errors that
   focus mainly on the production of higher and higher quality
   documentation and presentations. This however has not been able to solve
   the access problems to relevant information on field which is often
   difficult. In recent years, however progress has been made in field of
   mobile devices. Now that they are suitable for augmented reality (AR)
   technology, virtual BIM models can be integrated into live picture of
   the real environment. This may facilitate the access to relevant
   information and with that better use, visualization and interpretation
   of project documentation can be achieved. The AR technology is not new,
   but this is still relatively unexplored in the field of AEC (Wang,
   2011). In this paper we present the theoretical framework for evaluating
   the role of augmented reality in construction. We propose that its main
   role is to facilitate the mapping process that occurs between the
   ``symbol{''} and ``reality{''} nodes of the meaning triangle and then
   further elaborate on the specific locations in the construction
   processes where augmented reality can be applied.}},
ISBN = {{978-0-415-62128-1}},
Unique-ID = {{ISI:000337164500097}},
}

@inproceedings{ ISI:000399355100115,
Author = {Cheng, Shun-Wen and Chiang, Chih-Bin and Su, Yi-Feng and Hsu, Jih-Tao},
Book-Group-Author = {{ITE/SID}},
Title = {{Augmented Reality Head-Up-Display}},
Booktitle = {{IDW/AD `12: PROCEEDINGS OF THE INTERNATIONAL DISPLAY WORKSHOPS, PT 2}},
Series = {{IDW-International Display Workshops}},
Year = {{2012}},
Volume = {{19}},
Number = {{2}},
Pages = {{1273-1275}},
Note = {{19th International Display Workshops / Asia Display 2012 (IDW/AD `12),
   Kyoto, JAPAN, DEC 04-07, 2012}},
Organization = {{Inst Image Informat \& Television Engineers; Soc Informat Display}},
Abstract = {{We developed an augmented reality heads-up display system in this study.
   That displays integrated messages including overlapped image of lane
   marking and information of preceding vehicles on 5 meters in front of
   windshield. The system will also be verified for its feasibility through
   software simulation and prototype production.}},
ISSN = {{1883-2490}},
Unique-ID = {{ISI:000399355100115}},
}

@incollection{ ISI:000289444700005,
Author = {Thomas, Graham},
Editor = {{Zelkowitz, MV}},
Title = {{Virtual Graphics for Broadcast Production}},
Booktitle = {{ADVANCES IN COMPUTERS, VOL 82}},
Series = {{Advances in Computers}},
Year = {{2011}},
Volume = {{82}},
Pages = {{165-216}},
Abstract = {{This chapter looks at the technology involved in the mixing of 3D
   graphics with broadcast video in real time. This is essentially the
   application of augmented reality techniques in the context of TV
   production. Examples of the use of ibis technology include virtual
   graphics used for presenting election results, and graphics overlaid on
   a sports pitch to indicate distances. Whilst similar techniques are
   commonly used in films, these often require extensive post-production;
   this chapter focuses specifically on approaches that can be used live,
   which is a common requirement for TV, particularly in news and sport.
   Following a brief review of the history of virtual graphics in TV, the
   technology used in each stage of the production process is examined,
   starting with the camera and lens. Some of the important characteristics
   of broadcast video are discussed, and the need for lens calibration is
   explained. To maintain accurate alignment of the virtual graphics and
   the real scene, the motion of the camera must be tracked accurately, and
   methods for achieving this are reviewed. The requirements for
   high-quality rendering of graphics are then discussed, looking
   particularly at the differences from rendering for applications such as
   computer games. The process of keying graphics into an image using
   chroma-key is then examined in detail. It can be difficult for actors or
   presenters to work with virtual objects in a studio, unless there is
   some way for them to see what is going on, so methods of providing
   visual feedback are presented. Some specific issues related to the use
   of virtual graphics for sports are then discussed, including methods for
   tracking camera motion and keying graphics onto areas such as grass or
   sand. The chap:er concludes with a short discussion of an alternative
   approach to combining graphics and live action, in which graphical
   representations of real objects and people are created from live video,
   and placed into a 3D model, allowing the scene to be rendered from a
   viewpoint that is not tied to the location of the camera.}},
DOI = {{10.1016/B978-0-12-385512-1.00005-0}},
ISSN = {{0065-2458}},
ISBN = {{978-0-12-385512-1}},
Unique-ID = {{ISI:000289444700005}},
}

@inproceedings{ ISI:000306308800045,
Author = {Odenthal, Barbara and Mayer, Marcel Ph. and Kabuss, Wolfgang and Kausch,
   Bernhard and Schlick, Christopher M.},
Editor = {{Duffy, VG}},
Title = {{An Empirical Study of Disassembling Using an Augmented Vision System}},
Booktitle = {{DIGITAL HUMAN MODELING}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2011}},
Volume = {{6777}},
Pages = {{399-408}},
Note = {{3rd International Conference on Digital Human Modeling(ICDHM)/14th
   International Conference on Human-Computer Interaction (HCI), Orlando,
   FL, JUL 09-14, 2011}},
Abstract = {{Within the Cluster of Excellence ``Integrative Production Technology for
   High-Wage Countries{''} of RWTH Aachen University a numerical control
   unit and its ergonomic human-machine interface are developed for a
   robotized production unit. In order to cope with novel systems, the
   human operator will have to meet new challenges regarding the work
   requirements. Therefore, based on a first prototype of an augmented
   vision system (AVS) assisting the human operator in error detection the
   system is enhanced in order to deal with the task of error correction.
   Laboratory tests have been performed to find a preferable solution to
   support the human operator in disassembling of the erroneous object in
   order to correct the detected error in cooperation with the robot.
   Significant effects of the supporting mode regarding human assembly time
   will be presented.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-642-21798-2; 978-3-642-21799-9}},
Unique-ID = {{ISI:000306308800045}},
}

@inproceedings{ ISI:000303491800047,
Author = {Macaes, Gustavo and Pimenta, Waldir and Carvalho, Elizabeth},
Editor = {{Rocha, A and Goncalves, R and Cota, MP and Reis, LP}},
Title = {{Using Augmented Reality Virtual Assistants to Teach the Traditional
   Leather Tanning Process}},
Booktitle = {{SISTEMAS E TECNOLOGIAS DE INFORMACAO, VOL I}},
Year = {{2011}},
Pages = {{313+}},
Note = {{6th Iberian Information Systems and Technologies Conference, Chaves,
   PORTUGAL, JUN 15-18, 2011}},
Abstract = {{The leather tanning process carries a high cultural value in Guimaraes
   city. In some areas of Portugal, most of the society and its history are
   somehow interlaced with the history of the leather and all the
   associated processes of its production. There is a great lack of a
   ``vivid{''} memory about the leather tanning process and its social
   implications. References to it in Guimaraes city can be reduced to text
   and poor quality pictures. On the other hand, it is important to
   transmit to future generations the valuable role of the leather tanning
   in the local culture. At this point, the use of augmented reality
   techniques can help to illustrate interactively, expressively and with a
   compelling degree of immersion how this process used to be done, and
   help to preserve its memory. This project consisted in the development
   and implementation of an augmented reality application to young
   audiences that illustrates the ancient leather tanning process
   step-by-step. The resulting visualizations offer an impressive education
   experience that help to transfer a significant culture value of the
   Guimaraes city.}},
ISBN = {{978-989-96247-4-0}},
Unique-ID = {{ISI:000303491800047}},
}

@article{ ISI:000289573800007,
Author = {Zhang, J. and Ong, S. K. and Nee, A. Y. C.},
Title = {{RFID-assisted assembly guidance system in an augmented reality
   environment}},
Journal = {{INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH}},
Year = {{2011}},
Volume = {{49}},
Number = {{13}},
Pages = {{3919-3938}},
Abstract = {{RFID technology provides an invisible `visibility' to the end user for
   tracking and monitoring any objects that have been tagged. Research on
   the application of RFID in assembly lines for overall production
   monitoring and control has been reported recently. This paper presents a
   novel research on implementing the RFID technology in the application of
   assembly guidance in an augmented reality environment. Aiming at
   providing just-in-time information rendering and intuitive information
   navigation, methodologies of applying RFID, infrared-enhanced computer
   vision, and inertial sensor is discussed in this paper. A prototype
   system is established, and two case studies are presented to validate
   the feasibility of the proposed system.}},
DOI = {{10.1080/00207543.2010.492802}},
Article-Number = {{PII 924567072}},
ISSN = {{0020-7543}},
EISSN = {{1366-588X}},
Unique-ID = {{ISI:000289573800007}},
}

@article{ ISI:000288666000003,
Author = {Lapenta, Francesco},
Title = {{Geomedia: on location-based media, the changing status of collective
   image production and the emergence of social navigation systems}},
Journal = {{VISUAL STUDIES}},
Year = {{2011}},
Volume = {{26}},
Number = {{1, SI}},
Pages = {{14-24}},
Abstract = {{The increased computational power of portable devices such as smart
   phones and laptops, and their integration with widely available global
   positioning systems, are opening the way for a new range of
   location-based applications that integrate and coordinate users'
   mediated interactions and data exchanges with other users' live
   geographical positions. This user-generated information, shared on
   navigable live virtual maps such as Google Latitude, Foursquare and
   Gowalla, illustrates the increasing use of location-based applications
   and the Web to create, assemble and disseminate personal information (in
   the form of images, sounds and text) to enable shared experiences of
   individually and socially relevant spaces and events. The new virtual
   maps, in which this information is visually blurred and merged,
   represent the emergence of a new paradigm in the visualisation of space.
   The article elaborates on the fundamental social and perceptual shifts
   that are being operated today by these new technologies and software
   applications that the author refers to as geomedia. Geomedia are not new
   media per se, but platforms that merge existing electronic media + the
   Internet + location-based technologies (or locative media) + AR
   (Augmented Reality) technologies in a new mode of digital composite
   imaging, data association and socially maintained data exchange and
   communication. In the article the author examines the early adoption of
   such new geolocation-based technologies and develops a theoretical
   analysis of the ontological and epistemological shifts that characterise
   their contemporary evolution, patterns of production and exchange, and
   the unique form of geolocational digital re-aggregation of which digital
   images are now a part.}},
DOI = {{10.1080/1472586X.2011.548485}},
Article-Number = {{PII 934929118}},
ISSN = {{1472-586X}},
Unique-ID = {{ISI:000288666000003}},
}

@inproceedings{ ISI:000289118700007,
Author = {An, Jun and Fan, JinSong and Hua, Rui and Feng, DaPeng},
Editor = {{Han, JT and Jiang, ZY and Jiao, S}},
Title = {{Augmented Product Modeling Technique in New Product Development}},
Booktitle = {{ADVANCED MANUFACTURING TECHNOLOGY, PTS 1, 2}},
Series = {{Advanced Materials Research}},
Year = {{2011}},
Volume = {{156-157}},
Pages = {{36+}},
Note = {{International Conference on Advances in Materials and Manufacturing
   Processes, Shenzhen, PEOPLES R CHINA, NOV 06-08, 2010}},
Organization = {{Univ Wollongong; NE Univ; Univ Sci \& Technol Beijing; Hebei Polytechn
   Univ; Hong Kong Ind Technol Res Ctr}},
Abstract = {{Product modeling or prototype is an important part of new product
   development. After comparing the characteristics of physical model,
   digital prototype, and virtual prototype in new development product
   design, we propose to build augmented products model based on Augmented
   Reality technology. It has the characteristics of real-time
   interactivity, short production cycles, real feeling as physical
   prototype, and small equipment investment. Two model construction
   techniques are highlighted in the system developed by ARToolKit used as
   a development platform in the construction of augmented model. One is a
   direct construction technique based on OpenGL, and the other is an
   indirect construction technique based on 3D software and OpenGL,the
   virtual model is integrated into real scene in ARToolKit. Finally,
   implementations for the two methods are described in detail and examples
   are given, which indicates that the proposed augmented product modeling
   technique is practicable and feasible.}},
DOI = {{10.4028/www.scientific.net/AMR.156-157.36}},
ISSN = {{1022-6680}},
ISBN = {{978-0-87849-205-3}},
Unique-ID = {{ISI:000289118700007}},
}

@inproceedings{ ISI:000302737500064,
Author = {Zhang, Shou-xiang},
Editor = {{Zhilin, Z and Wang, P}},
Title = {{Augmented Reality on Longwall Face for Unmanned Mining}},
Booktitle = {{ADVANCES IN SCIENCE AND ENGINEERING, PTS 1 AND 2}},
Series = {{Applied Mechanics and Materials}},
Year = {{2011}},
Volume = {{40-41}},
Number = {{1 \& 2}},
Pages = {{388-391}},
Note = {{World-Association-of-Science-Engineering Global Congress on Science
   Engineering (GCSE 2010), Yantai, PEOPLES R CHINA, NOV 27-28, 2010}},
Organization = {{World Assoc Sci Engn}},
Abstract = {{An unmanned mining technology for the fully mechanized longwall face
   automation production is proposed and studied. The essential technology
   will bring the longwall face production into visualization through the
   Virtual Reality (VR) and Augmented Reality (AR) union. Based on the
   visual theoretical model of the longwall face, the combination of
   virtual and reality, the real-time interactive and the 3D registration
   function were realized. The Key technology and Alpha channel are used to
   the combination of the real long wall face and the virtual user.}},
DOI = {{10.4028/www.scientific.net/AMM.40-41.388}},
ISSN = {{1660-9336}},
ISBN = {{978-0-87849-212-1}},
Unique-ID = {{ISI:000302737500064}},
}

@inproceedings{ ISI:000394889900001,
Author = {Gadensgaard, Dan and Bourne, David Alan},
Editor = {{Galis, A and Dillenseger, B}},
Title = {{Human/Robot Multi-initiative Setups for Assembly Cells}},
Booktitle = {{PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTONOMIC AND
   AUTONOMOUS SYSTEMS (ICAS 2011)}},
Year = {{2011}},
Pages = {{1-6}},
Note = {{7th International Conference on Autonomic and Autonomous Systems (ICAS),
   Venice, ITALY, MAY 22-27, 2011}},
Organization = {{IARIA}},
Abstract = {{New products and small batch production entail a disproportionate amount
   of time is spent setting up automated assembly tasks. We have designed
   and implemented an automation tool to radically reduce this time. The
   setup for assembly automation involves: assembly planning, fixture tool
   selection and positioning as well as part loading. This automation tool
   provides the robot with the ability to provide a human operator with
   precise and convenient instructions to follow through augmented reality,
   while at the same time allowing the robot to read information supplied
   by the human operator's actions. In this way, a complex setup task can
   be collaboratively executed, while allowing both the robot and the human
   to do what each does best.}},
ISBN = {{978-1-61208-134-2}},
Unique-ID = {{ISI:000394889900001}},
}

@article{ ISI:000280510900008,
Author = {Stork, Sonja and Schuboe, Anna},
Title = {{Human cognition in manual assembly: Theories and applications}},
Journal = {{ADVANCED ENGINEERING INFORMATICS}},
Year = {{2010}},
Volume = {{24}},
Number = {{3}},
Pages = {{320-328}},
Month = {{AUG}},
Abstract = {{Human cognition in production environments is analyzed with respect to
   various findings and theories in cognitive psychology This theoretical
   overview describes effects of task complexity and attentional demands on
   both mental workload and task performance as well as presents
   experimental data on these topics A review of two studies investigating
   the benefit of augmented reality and spatial cueing in an assembly task
   is given Results demonstrate an improvement in task performance with
   attentional guidance while using contact analog highlighting
   Improvements were obvious in reduced performance times and eye fixations
   as well as in increased velocity and acceleration of reaching and
   grasping movements These results have various implications for the
   development of an assistive system. Future directions in this line of
   applied research are suggested The introduced methodology illustrates
   how the analysis of human information processes and psychological
   experiments can contribute to the evaluation of engineering applications
   (C) 2010 Elsevier Ltd All rights reserved}},
DOI = {{10.1016/j.aei.2010.05.010}},
ISSN = {{1474-0346}},
Unique-ID = {{ISI:000280510900008}},
}

@article{ ISI:000277747800003,
Author = {Kim, Seungjun and Dey, Anind K.},
Title = {{AR interfacing with prototype 3D applications based on user-centered
   interactivity}},
Journal = {{COMPUTER-AIDED DESIGN}},
Year = {{2010}},
Volume = {{42}},
Number = {{5, SI}},
Pages = {{373-386}},
Month = {{MAY}},
Abstract = {{Augmented Reality (AR) has been acclaimed as one of the promising
   technologies for advancing future UbiComp (Ubiquitous Computing)
   environments. Despite a myriad of AR applications and its influence on
   the human-computer interaction field, end products that integrate AR are
   less commonplace than expected. This is due to a lack of being able to
   forecast in which direction mainstream standardization of AR-oriented
   platform components will be framed. It is mainly due to a focus on
   technology issues in implementing reasonable AR solutions, which also
   results in difficulty in initiating AR research and creating prototype
   test-beds. Thus, this paper provides a comprehensive review of AR
   prototyping trends and AR research activities. Through the technical
   review of a de facto AR prototyping method, we remark upon the key
   elements of AR techniques, and then present an alternative view of the
   AR environment centered on end-user advantages in interaction, which is
   characterized by three features: intuitive observation, informative
   visualization, and immersive interaction. In addition, we believe that
   these features can be used to motivate the integration of AR technology
   into custom-built 3D applications. In this paper, we propose a
   conceptual schema and an architectural framework for generic AR
   prototyping. On the basis of these, a video see-through AR interface is
   integrated into three prototype 3D applications in 3 different domains:
   engineering systems, geospace, and multimedia. As the case studies for
   validating our integration, we present three sample AR applications; (a)
   an AR-interfaced 3D CAE (Computer-Aided Engineering) simulation
   test-bed, (b) a two-stage distributed Traveler Guidance Service (TGS)
   test-bed based on a GIS database and AR, and (c) a haptically-enhanced
   broadcasting test-bed for AR-based 3D media production. For each
   application, a description of the test-bed implementation, demonstration
   of the feasibility and usefulness and AR-specific technical challenges
   are included in this paper. (C) 2008 Elsevier Ltd. All rights reserved.}},
DOI = {{10.1016/j.cad.2008.10.009}},
ISSN = {{0010-4485}},
EISSN = {{1879-2685}},
Unique-ID = {{ISI:000277747800003}},
}

@inproceedings{ ISI:000358297400041,
Author = {Thomas, Vincent and Daniel, Sylvie and Pouliot, Jacynthe},
Editor = {{Kolbe, TH and Konig, G and Nagel, C}},
Title = {{3D MODELING FOR MOBILE AUGMENTED REALITY IN UNPREPARED ENVIRONMENT}},
Booktitle = {{5TH INTERNATIONAL CONFERENCE ON 3D GEOINFORMATION}},
Series = {{International Archives of the Photogrammetry Remote Sensing and Spatial
   Information Sciences}},
Year = {{2010}},
Volume = {{38-4}},
Number = {{W15}},
Pages = {{190}},
Note = {{5th International Conference on 3D GeoInformation, Berlin, GERMANY, NOV
   03-04, 2010}},
Organization = {{Int Soc Photogrammetry \& Remote Sensing}},
Abstract = {{The emergence of powerful mobile smartphones, with embedded components
   (camera, GPS, accelerometers, digital compass), triggered a lot of
   interest in the mobile augmented reality (AR) community and new AR
   applications relying on these devices are beginning to reach the general
   public. In order to achieve a rich augmentation in terms of immersion
   and interactions, these mobile AR applications generally require a 3D
   model of the real environment to provide accurate positioning or to
   manage occlusions. However, the availability of these 3D models based on
   real spatial data is limited, restraining the capacity of these
   applications to be used anywhere, anytime. To overcome such limits, we
   developed a framework dedicated to the fast and easy production of 3D
   models. The proposed solution has been designed for the specific context
   of mobile augmented reality applications in unprepared environment and
   tested on iPhone.}},
ISSN = {{2194-9034}},
Unique-ID = {{ISI:000358297400041}},
}

@inproceedings{ ISI:000318781700104,
Author = {Giro, Hector},
Editor = {{Chova, LG and Belenguer, DM and Torres, IC}},
Title = {{MEYEMEDIA\&I AUGMENTED MEDIA IN ARCHITECTURAL DESIGN}},
Booktitle = {{EDULEARN10: INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES}},
Series = {{EDULEARN Proceedings}},
Year = {{2010}},
Pages = {{721-728}},
Note = {{2nd International Conference on Education and New Learning Technologies
   (EDULEARN), Barcelona, SPAIN, JUL 05-07, 2010}},
Abstract = {{Many architects, whether they are well-known or not, have developed
   essential architectural concepts and created significant works of
   architecture. The cultural implication for society, but specially their
   significance in relation to the architectural practice is enormous.
   Most of these designers did not make use of the currently so called new
   media to explore and elaborate their design ideas.
   Every design process is for all architects a process of `conversation
   with oneself'. Visualization media facilitate this process and make it
   even possible. The media record the different moments along the whole
   design process and, as a result, these visual records provide the
   designer with the necessary feedback.
   Departing from the actual state of the art regarding architectural
   visualization, but specifically avoiding the limitations of the
   exclusive use of computer modeling and rendering, the students at our
   department review and explore those ideas.
   But the context we experience architecture is changing. Not only for
   designers but also for an extensive public within our society, the
   visual media play nowadays an immense role.
   Moreover, we stay, meet and chat more and more within virtual spaces.
   How does this all relate to the exploration of architecture?
   mEYEmedia\&I is the name of the Minor offered by the Department of Media
   Studies of the Faculty of Architecture at the Delft University of
   Technology in the Netherlands.
   The Department of Media Studies and its students explore the role the
   diverse available media play during the complete design process.
   Students get also trained in the different communication and
   visualization media.
   In this paper we further elaborate the contents of the Minor:
   mEYEmedia\&I is about communication, about different ways, analogue and
   digital, to develop, evaluate and communicate design ideas.
   During the minor, important concepts and works of architecture are
   revisited by the designers themselves, now `reincarnated' in
   contemporary students. They explore and take advantage of the
   opportunities and limitations of the various at present available
   techniques.
   The combination of all these visual media -we introduce here the name
   augmented media for it-allows designers to explore space in many new,
   different ways and to better compose, develop and communicate their
   design ideas.
   In addition to the media training, the students mainly work on a media
   production. Making use of an augmented reality-like approach, they
   perform research on techniques that combine images of the real world
   with analogue and digital representations.}},
ISSN = {{2340-1117}},
ISBN = {{978-84-613-9386-2}},
Unique-ID = {{ISI:000318781700104}},
}

@inproceedings{ ISI:000320093200037,
Author = {Willmann, Rita T. and Woessner, Uwe},
Book-Group-Author = {{ASME}},
Title = {{AUGMENTED REALITY VISUALIZATION OF AUTOMOBILE AIR CONDITIONING USING
   OPTICAL TRACKING TOOLS}},
Booktitle = {{PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL
   CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE
   2010, VOL 1, PTS A AND B}},
Year = {{2010}},
Pages = {{399-406}},
Note = {{ASME Internationl Design Engineering Technical Conferences / Computers
   and Information in Engineering Conference, Montreal, CANADA, AUG 15-18,
   2010}},
Organization = {{Amer Soc Mech Engineers, Design Engn Div; Amer Soc Mech Engineers, Comp
   \& Informat Engn Div}},
Abstract = {{Virtual prototyping allows us to reduce the expensive production of real
   prototypes to a minimum and shorten vehicle development phases.
   Augmented Reality (AR) visualization is a demonstrative and intuitive
   tool in order to overlay physical prototypes with virtual content and
   thus comprehend complex relationships quickly. Further, AR technologies
   can intensify the collaboration between specialists with different
   expert knowledge and support common decision making during reviews
   meetings. However, the existing work processes, software tools and
   predefined regulations do not permit the use of AR tools in all
   automotive areas. In this work, a prototypical AR application, based on
   optical tracking tools, was set up in a real automotive environment and
   evaluated in terms of its applicability for CFD simulation data in the
   passenger compartment. The examination provides valuable information
   about environmental conditions, requirements from end users as well as
   the integration in existing work processes. The results are a basis for
   future improvements in order to offer a seamless and automated workflow
   in an early state of the development process and for maintenance.}},
ISBN = {{978-0-7918-4409-0}},
Unique-ID = {{ISI:000320093200037}},
}

@inproceedings{ ISI:000279807800097,
Author = {Yin, Chuantao and David, Bertrand and Chalon, Rene},
Editor = {{Li, WH and Zhou, JH}},
Title = {{Use your mobile computing devices to learn Contextual mobile learning
   system design and case studies}},
Booktitle = {{2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND
   INFORMATION TECHNOLOGY, VOL 2}},
Year = {{2009}},
Pages = {{440-444}},
Note = {{2nd IEEE International Conference on Computer Science and Information
   Technology, Beijing, PEOPLES R CHINA, AUG 08-11, 2009}},
Organization = {{IEEE}},
Abstract = {{in recent years, with the rapid development of mobile computing
   technologies, a new learning style-mobile learning has exploded
   everywhere in our society, which is considered as an essential learning
   style in the future. This paper presents a mobile learning system taking
   into account learning context, which is also called contextual mobile
   learning. With the help of this system, we can learn just in time in our
   daily lives whenever we need to learn, using mobile computing devices
   like Tablet PCs and PDAs. The main principles and the development
   process such as production of learning units and contextualization
   process are presented. Two case studies are introduced to apply the
   system in concrete scenarios.}},
DOI = {{10.1109/ICCSIT.2009.5234816}},
ISBN = {{978-1-4244-4518-9}},
Unique-ID = {{ISI:000279807800097}},
}

@inproceedings{ ISI:000274846800154,
Author = {Yin, Chuantao and David, Bertrand and Chalon, Rene},
Editor = {{Liu, H and Zheng, XG}},
Title = {{A Contextual Mobile Learning System for Mastering Domestic and
   Professional Equipments}},
Booktitle = {{2009 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE \& EDUCATION, VOLS 1
   AND 2, PROCEEDINGS}},
Year = {{2009}},
Pages = {{773-779}},
Note = {{IEEE International Symposium on IT in Medicine and Education, Jinan,
   PEOPLES R CHINA, AUG 14-16, 2009}},
Organization = {{IEEE Beijing Sect; Shandong Normal Univ; Lanzhou Univ; Xiamen Univ;
   Henan Univ Technol; Wuhan Univ Technol; E China Normal Univ; Birmingham
   City Univ; Univ So Queensland}},
Abstract = {{The rapid development of mobile communication and mobile devices offers
   the opportunity to develop mobile learning systems that are able to
   assist us in our daily lives or professional situations. This paper
   presents a contextual mobile learning system framework, which allows us
   to learn mastering domestic and professional equipments on using mobile
   devices like Tablet PC, PDA or Smartphone. Just in time learning,
   learning and doing, and collaborative learning theories are
   appropriately blended for offering more effective task-centered learning
   experiences in our approach. The main principles and development process
   such as contextualization with RFID and production of learning units are
   introduced. At the end, a concrete learning scenario experiment for
   computer maintenance is evaluated.}},
DOI = {{10.1109/ITIME.2009.5236318}},
ISBN = {{978-1-4244-3929-4}},
Unique-ID = {{ISI:000274846800154}},
}

@inproceedings{ ISI:000278419000005,
Author = {Carreras, Anna and Sora, Carles},
Editor = {{Grasset, R and Disalvo, C and Pair, J and Bolter, J}},
Title = {{Coupling digital and physical worlds in an AR magic show performance:
   lessons learned}},
Booktitle = {{2009 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY - ARTS,
   MEDIA, AND HUMANITIES}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2009}},
Pages = {{25-28}},
Note = {{8th IEEE International Symposium on Mixed and Augmented Reality,
   Orlando, FL, OCT 19-22, 2009}},
Organization = {{IEEE}},
Abstract = {{``Magic for a Pixeloscope{''} is a one hour show conceived to be
   represented in a theater scenario that merges mixed and augmented
   reality (MR/AR) and full-body interaction with classical magic to create
   new tricks. The show was conceived by an interdisciplinary team composed
   by a magician, two interaction designers, a theater director and a stage
   designer. The magician uses custom based hardware and software to create
   new illusions which are a starting point to explore new language for
   magical expression. In this paper we introduce a conceptual framework
   used to inform the design of different tricks; we explore the design and
   production of some tricks included in the show and we describe the
   feedback received on the world premiere and some of the conclusions
   obtained.}},
DOI = {{10.1109/ISMAR-AMH.2009.5336729}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4244-5464-8}},
ResearcherID-Numbers = {{Sora, Carles/B-5682-2015}},
ORCID-Numbers = {{Sora, Carles/0000-0003-2761-2384}},
Unique-ID = {{ISI:000278419000005}},
}

@inproceedings{ ISI:000274012700023,
Author = {Oh, Juhyun and Nam, Seungjin and Sohn, Kwanghoon},
Editor = {{Fritz, M and Schiele, B and Piater, JH}},
Title = {{Practical Pan-Tilt-Zoom-Focus Camera Calibration for Augmented Reality}},
Booktitle = {{COMPUTER VISION SYSTEMS, PROCEEDINGS}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2009}},
Volume = {{5815}},
Pages = {{225+}},
Note = {{7th International Conference on Computer Vision Systems, Liege, BELGIUM,
   OCT 13-15, 2009}},
Abstract = {{While high-definition cameras with automated zoom lenses are widely used
   in broadcasting and film productions, there have been no practical
   calibration methods working without special hardware devices. We propose
   a practical method to calibrate pan-tilt-zoom-focus cameras, which takes
   advantages from both pattern-based and rotation-based calibration
   approaches. It uses patterns whose positions are only roughly known a
   priori, with several image samples taken at different rotations. The
   proposed method can find the camera view's translation along the optical
   axis caused by zoom and focus operations, which has been neglected in
   most rotation-based algorithms. We also propose a practical focus
   calibration technique that is applicable even when the image is too
   defocused for the patterns to be detected. The proposed method is
   composed of two separate procedures - zoom calibration and focus
   calibration. Once the calibration is done for all zoom settings with a
   fixed focus setting, the remaining focus calibration is fully automatic.
   We show the accuracy of the proposed method by comparing it to the
   algorithm most widely used in computer vision. The proposed algorithm
   works also well for real cameras with translation offsets.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-642-04666-7}},
Unique-ID = {{ISI:000274012700023}},
}

@inproceedings{ ISI:000281966900121,
Author = {Wilhelm, Jay P. and Panther, Chad and Pertl, Franz A. and Smith, James
   E.},
Book-Group-Author = {{ASME}},
Title = {{MOMENTUM ANALYTICAL MODEL OF A CIRCULATION CONTROLLED VERTICAL AXIS WIND
   TURBINE}},
Booktitle = {{ES2009: PROCEEDINGS OF THE ASME 3RD INTERNATIONAL CONFERENCE ON ENERGY
   SUSTAINABILITY, VOL 2}},
Year = {{2009}},
Pages = {{1009-1017}},
Note = {{3rd International Conference on Energy Sustainability, San Francisco,
   CA, JUL 19-23, 2009}},
Organization = {{ASME, Adv Energy Syst Div; ASME, Solar Energy Div}},
Abstract = {{A possible method for analytically modeling a CC-VAWT (Circulation
   Controlled Vertical Axis Wind Turbine) is the momentum model, based upon
   the conservation of momentum principal. This model can consist of a
   single or multiple stream tubes and/or upwind and downwind partitions. A
   large number of stream tubes and the addition of the partition can
   increase the accuracy of the model predictions.
   The CC-VAWT blade has blowing slots located on the top and bottom
   trailing edges and have the capability to be site controlled in multiple
   sections along the span of the blade. The turbine blade, augmented to
   include circulation control capabilities, replaces the sharp trailing
   edge of a standard airfoil with a rounded surface located adjacent to
   the blowing slots. Circulation control (CC), along with a rounded
   trailing edge, induces the Coanda effect, entraining the flow field near
   the blowing slots thus preventing or delaying separation. Ultimately,
   circulation control adds momentum due to the mass flow of air coming out
   of the blowing slots, but is negligible compared to the momentum of the
   free stream air passing through the area of the turbine. In order to
   design for a broader range of operating speeds that will take advantage
   of circulation control, an analytical model of a CC-VAWT is helpful. The
   analytical modeling of a CC-VAWT could provide insight into the range of
   operational speeds in which circulation control is beneficial. The
   ultimate goal is to increase the range of operating speeds where the
   turbine produces power. Improvements to low-speed power production and
   the elimination or reduction of startup assistance could be possible
   with these modifications.
   Vertical axis wind turbines are typically rated at a particular ratio of
   rotational to wind speed operating range. In reality, however, wind
   speeds arc variant and stray from the operating range causing the power
   production of a wind turbine to suffer. These turbines, unless designed
   specifically for low speed operation, may require rotational startup
   assistance. The added lift due to circulation control at low wind
   speeds, under certain design conditions, will allow the CC-VAWT to
   produce more power than a conventional VAWT of the same size.
   Circulation control methods, such as using blowing slots on the trailing
   edge are modeled as they are applied to a VAWT blade. A preliminary
   CC-VAWT was modeled using a standard NACA 0018 airfoil, modified to
   include blowing slots and a rounded trailing edge. This paper describes
   an analytical momentum model that can be used to predict the preliminary
   performance of a CC-VAWT.}},
ISBN = {{978-0-7918-4890-6}},
Unique-ID = {{ISI:000281966900121}},
}

@inproceedings{ ISI:000265071000056,
Author = {Ennakr, Said and Domingues, Christophe and Benchikh, Laredj and Otmane,
   Samir and Mallem, Malik},
Editor = {{Beji, L and Otmane, S and Abichou, A}},
Title = {{Towards Robot teaching based on Virtual and Augmented Reality Concepts}},
Booktitle = {{INTELLIGENT SYSTEMS AND AUTOMATION}},
Series = {{AIP Conference Proceedings}},
Year = {{2009}},
Volume = {{1107}},
Pages = {{337-341}},
Note = {{2nd Mediterranean Conference on Intelligent Systems and Automation (CISA
   2009), Zarzis, TUNISIA, MAR 23-25, 2009}},
Organization = {{Univ Evry Val d Essonne; Natl Sci Res Ctr; Polytechn Sch Tunisia;
   Tunisian Minist Higher Educat Sci Res \& Technol}},
Abstract = {{A complex system is a system made up of a great number of entities in
   local and simultaneous interaction. Its design requires the
   collaboration of engineers of various complementary specialties, so that
   it is necessary to invent new design methods. Indeed, currently the
   industry loses much time between the moment when the product model is
   designed and when the latter is serially produced on the lines of
   factories. This production is generally ensured by automated and more
   often robotized means. A deadline is thus necessary for the development
   of the automatisms and the robots work on a new product model. In this
   context we launched a study based on the principle of the mechatronics
   design in Augmented Reality-Virtual Reality. This new approach will
   bring solutions to problems encountered in many application scopes, but
   also to problems involved in the distance which separates the offices
   from design of vehicles and their production sites. This new approach
   will minimize the differences of errors between the design model and
   real prototype.}},
ISSN = {{0094-243X}},
ISBN = {{978-0-7354-0642-1}},
ResearcherID-Numbers = {{MALLEM, Malik/P-6389-2017
   }},
ORCID-Numbers = {{MALLEM, Malik/0000-0002-2471-7028
   Otmane, Samir/0000-0003-2221-4264}},
Unique-ID = {{ISI:000265071000056}},
}

@article{ ISI:000272947100003,
Author = {Aurich, J. C. and Ostermayer, D. and Wagenknecht, C. H.},
Title = {{Improvement of manufacturing processes with virtual reality-based CIP
   workshops}},
Journal = {{INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH}},
Year = {{2009}},
Volume = {{47}},
Number = {{19}},
Pages = {{5297-5309}},
Abstract = {{The Continuous Improvement Process (CIP) is a well-established method to
   improve manufacturing processes. A typical CIP workshop, carried out by
   a group of workers and engineers directly in production, often causes
   unwanted downtimes. Furthermore, improvements have to be realised
   without reliability testing. Virtual Reality (VR) provides a powerful
   means to support CIP workshops. This paper introduces the concept of a
   VR-based CIP workshop. User interfaces are proposed to integrate
   additional elements, e. g. findings of augmented reality, into VR. This
   allows meeting specific demands of different participants involved in a
   CIP workshop. The proposed concept is validated based on an industrial
   use case.}},
DOI = {{10.1080/00207540701816569}},
ISSN = {{0020-7543}},
ResearcherID-Numbers = {{Aurich, Jan C/M-7546-2017}},
ORCID-Numbers = {{Aurich, Jan C/0000-0001-7063-9334}},
Unique-ID = {{ISI:000272947100003}},
}

@inproceedings{ ISI:000280732200089,
Author = {Yin, Chuantao and David, Bertrand and Chalon, Rene},
Editor = {{Remenyi, D}},
Title = {{A Contextual Mobile Learning System in our Daily Lives and Professional
   Situations}},
Booktitle = {{PROCEEDINGS OF THE 8TH EUROPEAN CONFERENCE ON E-LEARNING}},
Year = {{2009}},
Pages = {{703-711}},
Note = {{8th European Conference on e-Learning, Univ Bari, Bari, ITALY, OCT
   29-30, 2009}},
Abstract = {{The rapid development of mobile technologies and new learning theories
   offer opportunities for developing mobile learning systems. Recently,
   contextual or context-aware mobile learning has become a special focus,
   as the learning context is a crucial factor for determining learning
   content and learning objective, or for enhancing learning experiences.
   What interested us is to apply contextual mobile learning theories to
   our daily lives and professional situations. We designed a contextual
   mobile learning system based on IMERA (Mobile Interaction in Augmented
   Reality Environment) platform, with MOCOCO (Mobility, Contextualization,
   and Cooperation) features. The system framework is introduced in this
   paper. The production of learning units using IML-SCORM and LOM
   standards is the starting point. We used RFID technologies to produce
   contextualization phases. CTTE (Concur Task Tree environment) tool was
   used for analyzing and modeling tasks. Mobile devices and peripherals
   were properly considered and configured according to learning activities
   and tasks. We suggest that learning methods should be properly
   considered and adapted based on learning activities, context, devices,
   etc. In our system, learning activities are very closely related to
   tasks. Just in time learning, learning and doing, and collaborative
   learning were appropriately blended into our approach to offer more
   effective task-centered learning experiences. In actual practice, we
   propose a learning strategy based on three main steps: before the task,
   during the task, after the task. The contextual mobile learning system
   was applied in two case studies: (1) Computer Hardware Maintenance
   Scenario: we proposed a solution that uses mobile devices (Tablet PC or
   PDA) and augmented reality accessories (see-through Head Mounted
   Display) to provide just in time learning opportunities, when users
   experience difficulties in carrying out computer hardware maintenance
   tasks. (2) HSHB (Healthy Spirit in Healthy Body) project aimed at
   assisting people in selecting dishes in university refectory or
   self-service restaurants according to nutritional composition
   information and personal preferences offered by mobile devices like PDA
   or Smartphone. Primary experiments and evaluations were carried out in
   our laboratory. Usability and acceptability of system and devices
   together with efficiency and satisfaction of learning activity were the
   main factors assessed by questionnaire forms. Some useful viewpoints
   provided by the participants are detailed in this paper.}},
ISBN = {{978-1-906638-52-8}},
Unique-ID = {{ISI:000280732200089}},
}

@inproceedings{ ISI:000270531200066,
Author = {Odenthal, Barbara and Mayer, Marcel Ph. and Kabuss, Wolfgang and Kausch,
   Bernhard and Schlick, Christopher M.},
Editor = {{Shumaker, R}},
Title = {{An Empirical Study of Assembly Error Detection Using an Augmented Vision
   System}},
Booktitle = {{VIRTUAL AND MIXED REALITY, PROCEEDINGS}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2009}},
Volume = {{5622}},
Pages = {{596-604}},
Note = {{3rd International Conference on Virtual and Mixed Reality held at the
   HCI International 2009, San Diego, CA, JUL 19-24, 2009}},
Abstract = {{Within the Cluster of Excellence ``Integrative Production Technology for
   High-Wage Countries{''} of RWTH Aachen University a numerical control
   unit and its ergonomic human-machine interface are developed for a
   robotized production unit. In order to cope with novel systems. the
   human operator will have to meet new challenges regarding the work
   requirements. Therefore, a first prototype of an augmented vision system
   to assist the human operator is developed dealing with the task of error
   detection and identification in an assembly object. Laboratory tests
   have been performed to find a preferable Solution to display
   information.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-642-02770-3}},
Unique-ID = {{ISI:000270531200066}},
}

@article{ ISI:000259961600002,
Author = {Amditis, Angelos and Karaseitanidis, Ioannis and Bimpas, Matthaios and
   Blach, Roland},
Title = {{Future scenarios of mixed reality: the INTUITION roadmap scenarios}},
Journal = {{VISUAL COMPUTER}},
Year = {{2008}},
Volume = {{24}},
Number = {{11}},
Pages = {{935-940}},
Month = {{NOV}},
Note = {{4th INTUITION International Conference and Workshop, Athens, GREECE, OCT
   04-05, 2007}},
Abstract = {{INTUITION is a Network of Excellence that aims to integrate the European
   research efforts on the scientific and technological field of Virtual
   and Mixed Reality. To perform that, a series of activities have taken
   place in order to gather knowledge regarding actors and research
   profiles, projects and research results, products and patents. Having a
   clear view of research needs and technology trends the Network has
   envisioned the research goals that need to be pursued within the years
   to come. The starting point is a set of visionary scenarios which set
   out the picture for the technological and scientific advances that need
   to take place. Within this paper a set of indicative scenarios on a
   higher and descriptive level are provided and the way they contribute to
   the roadmap definition is explained. With this report we want to share
   these scenarios and our initial thoughts to stimulate a broader
   discussion and invite people from all relevant backgrounds to enter the
   knowledge creation process. The paper is a collective production of the
   INTUITION Consortium.}},
DOI = {{10.1007/s00371-008-0293-1}},
ISSN = {{0178-2789}},
Unique-ID = {{ISI:000259961600002}},
}

@article{ ISI:000253522600003,
Author = {Behera, Ardhendu and Lalanne, Denis and Ingold, Rolf},
Title = {{DocMIR: An automatic document-based indexing system for meeting
   retrieval}},
Journal = {{MULTIMEDIA TOOLS AND APPLICATIONS}},
Year = {{2008}},
Volume = {{37}},
Number = {{2}},
Pages = {{135-167}},
Month = {{APR}},
Abstract = {{This paper describes the DocMIR system which captures, analyzes and
   indexes automatically meetings, conferences, lectures, etc. by taking
   advantage of the documents projected (e.g. slideshows, budget tables,
   figures, etc.) during the events. For instance, the system can
   automatically apply the above-mentioned procedures to a lecture and
   automatically index the event according to the presented slides and
   their contents. For indexing, the system requires neither specific
   software installed on the presenter's computer nor any conscious
   intervention of the speaker throughout the presentation. The only
   material required by the system is the electronic presentation file of
   the speaker. Even if not provided, the system would temporally segment
   the presentation and offer a simple storyboard-like browsing interface.
   The system runs on several capture boxes connected to cameras and
   microphones that records events, synchronously. Once the recording is
   over, indexing is automatically performed by analyzing the content of
   the captured video containing projected documents and detects the scene
   changes, identifies the documents, computes their duration and extracts
   their textual content. Each of the captured images is identified from a
   repository containing all original electronic documents, captured
   audio-visual data and metadata created during post-production. The
   identification is based on documents' signatures, which hierarchically
   structure features from both layout structure and color distributions of
   the document images. Video segments are finally enriched with textual
   content of the identified original documents, which further facilitate
   the query and retrieval without using OCR. The signature-based indexing
   method proposed in this article is robust and works with low-resolution
   images and can be applied to several other applications including
   real-time document recognition, multimedia IR and augmented reality
   systems.}},
DOI = {{10.1007/s11042-007-0137-4}},
ISSN = {{1380-7501}},
EISSN = {{1573-7721}},
ORCID-Numbers = {{Behera, Ardhendu/0000-0003-0276-9000}},
Unique-ID = {{ISI:000253522600003}},
}

@inproceedings{ ISI:000261519200001,
Author = {Bannat, Alexander and Gast, Juergen and Rigoll, Gerhard and Wallhoff,
   Frank},
Editor = {{Letia, IA}},
Title = {{Event Analysis and Interpretation of Human Activity for Augmented
   Reality-based Assistant Systems}},
Booktitle = {{2008 IEEE 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTER
   COMMUNICATION AND PROCESSING, PROCEEDINGS}},
Series = {{IEEE International Conference on Intelligent Computer Communication and
   Processing ICCP}},
Year = {{2008}},
Pages = {{1-8}},
Note = {{IEEE 4th International Conference on Intelligent Computer Communication
   and Processing, Cluj Napoca, ROMANIA, AUG 28-30, 2008}},
Organization = {{IEEE}},
Abstract = {{In this paper a concept and its implementation of an ergonomic cognitive
   assistant system for supporting human workers at complex assembly tasks
   in industrial environments is introduced. Depending on the level of the
   user's product knowledge this mixed-initiative system follows and gains
   knowledge from the human worker's construction steps while it is also
   able to automatically give hints and instruct the worker whenever
   needed. The presented agent bases on a closed human-machine interaction
   loop consisting of the multimodal perception of the worker's action, the
   comparison with the system's knowledge about the production task, and
   the displaying of the adequate next assembly instruction step. First
   experimental results of the assistant system are demonstrated on a
   simplified use case with the construction of a small toy car using
   augmented reality display techniques.}},
DOI = {{10.1109/ICCP.2008.4648347}},
ISSN = {{2065-9946}},
ISBN = {{978-1-4244-2673-7}},
Unique-ID = {{ISI:000261519200001}},
}

@inproceedings{ ISI:000257506800027,
Author = {Park, Hong-Seok and Choi, Hung-Won and Park, Jin-Woo},
Book-Group-Author = {{ICROS/KOMMA}},
Title = {{Augmented reality based cockpit module assembly system}},
Booktitle = {{2008 INTERNATIONAL CONFERENCE ON SMART MANUFACTURING APPLICATION}},
Year = {{2008}},
Pages = {{130-135}},
Note = {{International Conference on Smart Manufacturing Application, Goyangsi,
   SOUTH KOREA, APR 09-11, 2008}},
Abstract = {{Because of global competition, most of automobile manufacturer try to
   reduce the cost and time for the implementation of manufacturing system.
   The AR technology as a new man-machine interface introduces a noteworthy
   perspective for a new manufacturing system. Because virtual objects are
   superimposed to real scene, system planner can design and validate the
   new system without modeling the surrounding environment of production
   domain during short process planning time.
   In this paper, the architecture of AR browser is introduced and the
   optimal environment parameters for practical application of AR system
   are determined through lots of tests. Moreover, many methods such as
   multi-marker coordinate system, partition of virtual objects and so on,
   are proposed in order to solve the problems suggested from the initial
   practical test. Based on these tests and results, the test bed of a
   cockpit module assembly system is configured and operation program for
   cockpit module assembly is generated using the AR system.}},
DOI = {{10.1109/ICSMA.2008.4505627}},
ISBN = {{978-89-950038-8-6}},
ORCID-Numbers = {{Park, Hong Seok/0000-0002-8382-4843}},
Unique-ID = {{ISI:000257506800027}},
}

@inproceedings{ ISI:000260993200015,
Author = {Tuemler, Johannes and Mecke, Ruediger and Schenk, Michael and Huckauf,
   Anke and Doil, Fabian and Paul, Georg and Pfister, Eberhard A. and
   Boeckelmann, Irina and Roggentin, Anja},
Editor = {{Livingston, MA and Bimber, O and Saito, H}},
Title = {{Mobile Augmented Reality in Industrial Applications: Approaches for
   Solution of User-Related Issues}},
Booktitle = {{7TH IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY 2008,
   PROCEEDINGS}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2008}},
Pages = {{87+}},
Note = {{7th IEEE International Symposium on Mixed and Augmented Reality,
   Cambridge, ENGLAND, SEP 15-18, 2008}},
Organization = {{IEEE Comp Soc, VGTC; ACM}},
Abstract = {{Augmented Reality (AR) uses computer-generated virtual information to
   enhance the user's information access. While numerous previous studies
   have demonstrated the large potential of AR to improve industrial
   processes by enhancing product quality and reducing production times it
   is still unclear if and how long term usage of such AR technology
   produces stress and strain. This paper presents an approach to use the
   analysis of Heart Rate Variability to objectively measure current user
   strain during different work tasks. Results of a user study comparing
   strain during an AR supported and a non-AR supported work task in a
   laboratory setting are presented and discussed.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4244-2840-3}},
Unique-ID = {{ISI:000260993200015}},
}

@inproceedings{ ISI:000260993200017,
Author = {Schall, Gerhard and Mendez, Erick and Schmalstieg, Dieter},
Editor = {{Livingston, MA and Bimber, O and Saito, H}},
Title = {{Virtual Redlining for Civil Engineering in Real Environments}},
Booktitle = {{7TH IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY 2008,
   PROCEEDINGS}},
Series = {{International Symposium on Mixed and Augmented Reality}},
Year = {{2008}},
Pages = {{95-98}},
Note = {{7th IEEE International Symposium on Mixed and Augmented Reality,
   Cambridge, ENGLAND, SEP 15-18, 2008}},
Organization = {{IEEE Comp Soc, VGTC; ACM}},
Abstract = {{Field workers of utility companies are regularly engaged in outdoor
   tasks such as network planning and inspection of underground
   infrastructure. Redlining is the term used for manually annotating
   either printed paper maps or a 2D geographic information system on a
   notebook computer taken to the field. Either of these approaches
   requires finding the physical location to be annotated on the physical
   or digital map. In this paper, we describe a mobile Augmented Reality
   (AR) system capable of supporting virtual redlining. The AR
   visualization delivered by the system is constructed from data directly
   extracted from a GIS used in day-to-day production by utility companies.
   We also report on encouraging trials and interviews performed with
   professional field workers from the utility sector.}},
ISSN = {{1554-7868}},
ISBN = {{978-1-4244-2840-3}},
Unique-ID = {{ISI:000260993200017}},
}

@inproceedings{ ISI:000255679500012,
Author = {Sitnik, Robert and Pasko, Slawomir and Karaszewski, Maciej and
   Witkowski, Marcin},
Editor = {{McDowall, IE and Dolinsky, M}},
Title = {{Internet virtual studio: Low-cost augmented reality system for WebTV}},
Booktitle = {{ENGINEERING REALITY OF VIRTUAL REALITY 2008}},
Series = {{Proceedings of SPIE}},
Year = {{2008}},
Volume = {{6804}},
Note = {{Conference on Engineering Reality of Virtual Reality 2008, San Jose, CA,
   JAN 31, 2008}},
Organization = {{SPIE; IS\&T, Soc Imaging Sci \& Technol}},
Abstract = {{In this paper a concept of a Internet Virtual Studio as a modem system
   for production of news, entertainment, educational and training material
   is proposed. This system is based on virtual studio technology and
   integrated with multimedia data base. Its was developed for web
   television content production. In successive subentries the general
   system architecture, as well as the architecture of modules one by one
   is discussed. The authors describe each module by presentation of a
   brief information about work principles and technical limitations. The
   presentation of modules is strictly connected with a presentation of
   their capabilities. Results produced by each of them are shown in the
   form of exemplary images. Finally, exemplary short production is
   presented and discussed.}},
DOI = {{10.1117/12.765914}},
Article-Number = {{68040E}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-6976-2}},
ResearcherID-Numbers = {{Witkowski, Marcin/C-1810-2015
   }},
ORCID-Numbers = {{Witkowski, Marcin/0000-0001-6435-4164}},
Unique-ID = {{ISI:000255679500012}},
}

@inproceedings{ ISI:000256582000057,
Author = {Pentenrieder, Katharina and Meier, Peter},
Editor = {{Braz, J and Nune, NJ and Pereira, JM}},
Title = {{Registration approaches for Augmented Reality - A crucial aspect for
   successful industrial application}},
Booktitle = {{GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON
   COMPUTER GRAPHICS THEORY AND APPLICATIONS}},
Year = {{2008}},
Pages = {{426+}},
Note = {{3rd International Conference on Computer Graphics Theory and
   Applications, Funchal, PORTUGAL, JAN 22-25, 2008}},
Organization = {{Inst Syst \& Technol Informat, Control \& Commun; Univ Madeira;
   Eurographics; Fund Ciencia \& Tecnol}},
Abstract = {{In the past years, a variety of Augmented Reality (AR)-based
   applications were created, aiming to support industrial processes.
   Although these first demonstrator applications or prototypes cover all
   parts of the industrial product process - design, planning and
   production, service and maintenance - only a few of them actually turned
   into established and applied solutions. Reasons for this lack of
   acceptance are - amongst others - their insufficient usability and
   accuracy.
   One crucial step in the accuracy chain for an Augmented Reality system
   is the registration of real and virtual world. This paper presents
   different approaches for industrial registration, which are being
   investigated in the context of an Augmented Reality based factory
   planning application. The resulting toolbox promises to be helpful and
   valuable for general application in industrial AR. To support the choice
   for an optimal registration method for a given scenario, the toolbox is
   currently being evaluated according to usability and accuracy criteria.
   The current state of this evaluation as well as future planned studies
   are also outlined here.}},
ISBN = {{978-989-8111-20-3}},
Unique-ID = {{ISI:000256582000057}},
}

@article{ ISI:000267267500003,
Author = {McCormack, Deborah C. and Irving, Duncan H. B. and Brocklehurst, Simon
   H. and Rarity, Frank},
Title = {{Glacial geomorphological mapping of Coire Mhic Fhearchair, NW Scotland:
   The contribution of a high-resolution ground based LiDAR survey}},
Journal = {{JOURNAL OF MAPS}},
Year = {{2008}},
Volume = {{4}},
Number = {{2}},
Pages = {{315-331}},
Note = {{Annual Discussion Meeting of the Quaternary-Research-Association,
   ENGLAND, JAN 08-10, 2008}},
Organization = {{Quaternary Res Assoc}},
Abstract = {{Terrestrial Light Detection and Ranging (tLiDAR) surveys are valuable
   supplements to existing geomorphological mapping techniques, providing
   information which is of considerable interest to palaeoclimatologists
   and glaciologists. Fieldwork observations, and the interpretation of
   aerial photographs and digital elevation models, have been augmented by
   the study of 3D digital models produced from tLiDAR data, and have led
   to the production of a detailed geomorphological map at a scale of
   1:10,000. A 2 km(2) study was carried out in Coire Mhic Fhearchair (NW
   Scotland), a cirque landform which was covered by an ice-sheet at the
   Last Glacial Maximum, and experienced localised ice flow during
   subsequent deglaciation and readvances. The combined map includes
   glacial (moraines, striae, and depositional lineations) and paraglacial
   features (debris fans) which have been observed using some or all of the
   above methods. In addition to this, tLiDAR has been used in conjunction
   with colour photography to provide a `virtual reality' observational
   tool at resolutions of up to 50 mm, with great potential for the
   detailed study of glacial geomorphology on the sub-km scale.}},
DOI = {{10.4113/jom.2008.1033}},
ISSN = {{1744-5647}},
ResearcherID-Numbers = {{Brocklehurst, Simon/G-4127-2014
   }},
ORCID-Numbers = {{Brocklehurst, Simon/0000-0002-2466-056X}},
Unique-ID = {{ISI:000267267500003}},
}

@inproceedings{ ISI:000256581900050,
Author = {Stoessel, Christian and Wiesbeck, Mathey and Stork, Sonja and Zaeh,
   Michael F. and Schuboe, Anna},
Editor = {{Mitsuishi, M and Ueda, K and Kimura, F}},
Title = {{Towards optimal worker assistance: Investigating cognitive processes in
   manual assembly}},
Booktitle = {{MANUFACTURING SYSTEMS AND TECHNOLOGIES FOR THE NEW FRONTIER}},
Year = {{2008}},
Pages = {{245+}},
Note = {{41st CIRP Conference on Manufacturing Systems, Univ Tokyo, Tokyo, JAPAN,
   MAY 26-28, 2008}},
Organization = {{CIRP; JSPE}},
Abstract = {{The integration of cognitive systems in currently humanly dominated,
   manual assembly environments is the core issue of the project ACIPE
   (Adaptive Cognitive Interaction in Production Environments). This paper
   presents a novel concept of workbench augmentation for adaptive human
   worker observation and guidance. An increase in worker performance is
   expected from a cognitive assistance system integrated into the
   workbench, which can support the worker via context sensitive,
   adaptively generated instructions at the right time, location and with
   appropriate content. In order to assist the worker adequately, a deeper
   understanding of mental workload and related cognitive processes and
   limitations during manual assembly is needed. The augmented workbench
   serves both as a research tool for detecting cognitive bottlenecks in
   manual assembly, as well as an implementation platform for the worker
   assistance system, leading to a more efficient manual assembly
   performance.}},
DOI = {{10.1007/978-1-84800-267-8\_50}},
ISBN = {{978-1-84800-266-1}},
Unique-ID = {{ISI:000256581900050}},
}

@inproceedings{ ISI:000253310600039,
Author = {Saaski, Juha and Salonen, Tapio and Hakkarainen, Mika and Siltanen,
   Sanni and Woodward, Charles and Lempiainen, Juhani},
Editor = {{Ratchev, S and Koelemeijer, S}},
Title = {{Integration of design and assembly using augmented reality}},
Booktitle = {{MICRO-ASSEMBLY TECHNOLOGIES AND APPLICATIONS}},
Series = {{International Federation for Information Processing}},
Year = {{2008}},
Volume = {{260}},
Pages = {{395+}},
Note = {{4th International Precision Assembly Seminar, Chamonix, FRANCE, FEB
   10-13, 2008}},
Organization = {{IFIP TC 5, WG 5 5}},
Abstract = {{This paper presents a methodology and a system for augmented reality
   aided assembly work. We concentrate in particular on the requirements on
   information processing and data flow for implementing augmented assembly
   systems in real life production environments. A pilot case with an
   augmented assembly task at the Finnish tractor company Valtra is
   described.}},
ISSN = {{1571-5736}},
ISBN = {{978-0-387-77402-2}},
Unique-ID = {{ISI:000253310600039}},
}

@inproceedings{ ISI:000256791000001,
Author = {Encarnacao, Jose Luis},
Editor = {{Araujo, HJ}},
Book-Author = {{Ranchordas, AN}},
Title = {{Augmented reality for industrial applications in design, production and
   maintenance}},
Booktitle = {{VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON
   COMPUTER VISION THEORY AND APPLICATIONS, VOL 1}},
Year = {{2008}},
Pages = {{IS5-IS6}},
Note = {{3rd International Conference on Computer Vision Theory and Applications,
   Funchal, PORTUGAL, JAN 22-25, 2008}},
Organization = {{Inst Syst \& Technol Informat, Control \& Commun; Univ Madeira}},
Abstract = {{Computer graphics established as basic technology for the design of
   human-computer-interfaces. During the nineties the development of
   immersive I/O devices for Virtual Reality had been the major concern.
   Nowadays, computer graphics and technologies deriving from mobile
   computing and computer vision melt into Augmented Reality to create new
   forms of human-computer-interaction. Growing competition in industry
   induces increasing product complexity, larger number of product
   variations, always shorter product life cycles, and, therefore, the need
   for maximal efficiency in design, production and maintenance. So far,
   increasing product complexity has been compensated with always more
   information and training. But it is foreseeable that the gap between
   product complexity and existing knowledge of engineers and technicians
   cannot be bridged with such conventional methods for much longer.
   Projects like ARVIKA and ARTESAS therefore seek for new techniques based
   on Augmented Reality overlaying the real environment of engineers and
   technicians with digital information to support them in the areas of
   design, production and maintenance.}},
ISBN = {{978-989-8111-21-0}},
Unique-ID = {{ISI:000256791000001}},
}

@inproceedings{ ISI:000256791600001,
Author = {Encarnacao, Jose Luis},
Editor = {{Ranchordas, AN and Araujo, HJ}},
Title = {{Augmented Reality for industrial applications in design production and
   maintenance}},
Booktitle = {{VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON
   COMPUTER VISION THEORY AND APPLICATIONS, VOL 2}},
Year = {{2008}},
Pages = {{IS5-IS6}},
Note = {{3rd International Conference on Computer Vision Theory and Applications,
   Funchal, PORTUGAL, JAN 22-25, 2008}},
Organization = {{Inst Syst \& Technol Informat, Control \& Commun; Univ Madeira}},
Abstract = {{Computer graphics established as basic technology for the design of
   human-computer-interfaces. During the nineties the development of
   immersive I/O devices for Virtual Reality had been the major concern.
   Nowadays, computer graphics and technologies deriving from mobile
   computing and computer vision melt into Augmented Reality to create new
   forms of human-computer-interaction.
   Growing competition in industry induces increasing product complexity,
   larger number of product variations, always shorter product life cycles,
   and, therefore, the need for maximal efficiency in design, production
   and maintenance. So far, increasing product complexity has been
   compensated with always more information and training. But it is
   foreseeable that the gap between product complexity and existing
   knowledge of engineers and technicians cannot be bridged with such
   conventional methods for much longer. Projects like ARVIKA and ARTESAS
   therefore seek for new techniques based on Augmented Reality overlaying
   the real environment of engineers and technicians with digital
   information to support them in the areas of design, production and
   maintenance.}},
ISBN = {{978-989-8111-21-0}},
Unique-ID = {{ISI:000256791600001}},
}

@inproceedings{ ISI:000263199600003,
Author = {Karhela, Tommi and Liinasuo, Marja and Paljakka, Matti},
Editor = {{Vaha, P and Salkari, I and Alahuhta, P and Leviakangas, P}},
Title = {{Mixed-reality techniques to support a new type of service business in
   industrial operation and maintenance}},
Booktitle = {{VTT SYMPOSIUM ON SERVICE SCIENCE, TECHNOLOGY AND BUSINESS}},
Series = {{VTT SYMPOSIA}},
Year = {{2008}},
Volume = {{253}},
Pages = {{32-42}},
Note = {{VTT Symposium on Service Science, Technology and Business, Espoo,
   FINLAND, NOV, 2008}},
Organization = {{VTT}},
Abstract = {{Traditionally, industrial facilities such as process plants have been
   maintained by the plant owner's organisation. As the plants have become
   more complex and the demands of production performance have become
   higher, the outsourcing of plant maintenance activities and combining
   them to performance consulting has become attractive, thus opening a new
   market for industrial services. This has resulted in major changes in
   the work and responsibilities of the maintenance engineer. The change
   has in turn set new demands for software products and opened new
   software business opportunities. VTT has international state-of-the-art
   expertise in industrial software architectures, Augmented Reality, video
   stream processing and human-technology interaction. Using this
   expertise, we have developed a novel concept for providing each
   stakeholder intuitive access to the right information in the very
   location on the plant floor where that information is needed. The
   concept involves video-stream based user interfaces, mobile devices and
   location-aware information services.}},
ISSN = {{0357-9387}},
ISBN = {{978-951-38-6329-6}},
Unique-ID = {{ISI:000263199600003}},
}

@article{ ISI:000208118900001,
Author = {Felsberg, Michael and Koch, Reinhard},
Title = {{Editorial for the special issue on markerless real-time tracking for
   augmented reality image synthesis}},
Journal = {{JOURNAL OF REAL-TIME IMAGE PROCESSING}},
Year = {{2007}},
Volume = {{2}},
Number = {{2-3, SI}},
Pages = {{67-68}},
Month = {{NOV}},
Abstract = {{Augmented reality is a growing field, with many diverse applications
   ranging from TV and film production, to industrial maintenance,
   medicine, education, entertainment and games. The central idea is to add
   virtual objects into a real scene, either by displaying them in a
   see-through head-mounted display, or by superimposing them on an image
   of the scene captured by a camera. Depending on the application, the
   added objects might be virtual characters in a TV or film production,
   instructions for repairing a car engine, or a reconstruction of an
   archaeological site. For the effect to be believable, the virtual
   objects must appear rigidly fixed to the real world, which requires the
   accurate measurement in real-time of the position of the camera or the
   user's head. Present technology cannot achieve this without resorting to
   systems that require a significant infrastructure in the operating
   environment, severely restricting the range of possible applications.}},
DOI = {{10.1007/s11554-007-0047-8}},
ISSN = {{1861-8200}},
Unique-ID = {{ISI:000208118900001}},
}

@article{ ISI:000248752500006,
Author = {Kampmeier, J. and Cucera, A. and Fritzsche, L. and Brau, H. and
   Duthweiler, M. and Lang, G. K.},
Title = {{Potentials of monocular augmented reality technology in automobile
   production}},
Journal = {{KLINISCHE MONATSBLATTER FUR AUGENHEILKUNDE}},
Year = {{2007}},
Volume = {{224}},
Number = {{7}},
Pages = {{590-596}},
Month = {{JUL}},
Abstract = {{Introduction: Augmented reality (AR) technologies can enrich the real
   environment with visual data, which has potential benefits for
   optimising the operator's working process. It offers the possibility to
   provide context-sensitive information independently of the user's
   location and position. Data are presented to the dominant eye on a
   semi-transparent mirror using a head-mounted display (HMD) unit that
   works with retinal laser technology. In this study the potential
   benefits and drawbacks of this new AR technology were evaluated.
   Materials and
   Methods: 45 participants without any visual impairment were randomly
   assigned to 3 groups and completed a variety of tasks during a simulated
   working day. Group 1 received conventional working aids (paper-based
   documents) to support the task processing. Group 2 additionally wore an
   HMD unit that was switched off. Group 3 wore a functioning HMD without
   any additional aids. Evaluation was carried out by means of a
   standardised questionnaire (BMS) and a concentration test ({''}d2
   Aufmerk-samkeits-Belastungs-Test{''}).
   Results: No significant differences between the 3 groups were found in
   terms of mental strain, concentration-test performance and physical or
   mental complaints reported in a follow-up interview. Around 20\% of the
   subjects noticed a higher pressure and blurred vision in both eyes as
   well as headaches. Half of the participants complained about
   deficiencies concerning the ergonomic hardware design of the AR system.
   Discussion: Changes in objective ophthalmological investigation
   parameters were not observed. Subjects reported reduced acceptance of
   the HMD based on non-ophthalmological reasons, for example, the weight
   of the unit or the length of the cable. However, for some specific
   working tasks, advantages in process optimisation and operator support
   were observed.}},
DOI = {{10.1055/s-2007-963359}},
ISSN = {{0023-2165}},
Unique-ID = {{ISI:000248752500006}},
}

@inproceedings{ ISI:000253933000024,
Author = {Affonso, Elaine Parra and Sementille, Antonio Carlos},
Editor = {{Brooks, T and Ikei, Y and Petersson, E and Haller, M and Kim, GJ and Noma, H}},
Title = {{Support on the remote interaction for augmented reality system}},
Booktitle = {{17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE,
   ICAT 2007, PROCEEDINGS}},
Year = {{2007}},
Pages = {{190-196}},
Note = {{17th International Conference on Artificial Reality and Telexistence,
   Esbjerg, DENMARK, NOV 28-30, 2007}},
Organization = {{Aalborg Univ Esbjerg; Virtual Real Soc Japan; SoundScapes; KPMG; Teknisk
   Landsforbund; Thuesen Bodker \& Jaeger; LEGO; Sydvestjysk
   Udviklingsforum; IBM; Varde Erhvervs OG Turistrad; arKaos; VRLOGIC;
   EXPLANAR; ZEN; Art Abilitation; LEDA; ICVR}},
Abstract = {{This article presents a support on the remote interaction for
   utilization in augmented reality systems based on ARToolkit. It utilizes
   the multicast communication in order to improve the scalability of
   distributed environment. This support may be utilized in production of
   specific applications pointed to distance education, training and
   entertainment. The validity of support happened with the implementation
   of a prototype and realization of tests for communication latency
   analysis and frames per second rate.}},
ISBN = {{978-0-7695-3056-7}},
Unique-ID = {{ISI:000253933000024}},
}

@inproceedings{ ISI:000252357704111,
Author = {Wallhoff, F. and Ablassmeier, M. and Bannat, A. and Buchta, S. and
   Rauschert, A. and Rigoll, G. and Wiesbeck, M.},
Book-Group-Author = {{IEEE}},
Title = {{Adaptive human-machine interfaces in cognitive production environments}},
Booktitle = {{2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5}},
Year = {{2007}},
Pages = {{2246+}},
Note = {{IEEE International Conference on Multimedia and Expo (ICME 2007),
   Beijing, PEOPLES R CHINA, JUL 02-05, 2007}},
Organization = {{IEEE Signal Proc Soc; IEEE Circuits \& Syst Soc; IEEE Commun Soc; IEEE
   Comp Soc}},
Abstract = {{This article presents an integrated framework for multi-modal adaptive
   cognitive technical systems to guide, assist and observe human workers
   in complex manual assembly environments. The demand for highly flexible
   construction facilities obviously contradicts longer training and
   preparation phases of human workers.
   By giving context-aware building instructions over retina displays,
   text-to-speech commands or acoustical signals, a non-specialized
   industrial stand-by men in a production task can precisely be alloted to
   execute the next processing step without any previous knowledge. Using
   non-invasive gesture recognizers and object detectors the human worker
   can be observed in order to track the production line and initiate the
   subsequent step in the interaction loop.
   Aiming at testing and evaluating the desired human-machine interfaces
   and its capabilities a virtual working place together with a concrete
   use case is introduced.}},
ISBN = {{978-1-4244-1016-3}},
Unique-ID = {{ISI:000252357704111}},
}

@inproceedings{ ISI:000255993700138,
Author = {Stork, S. and Stoessel, C. and Mueller, H. J. and Wiesbeck, A. and Zaeh,
   M. F. and Schuboe, A.},
Book-Group-Author = {{IEEE}},
Title = {{A neuroergonomic approach for the investigation of cognitive processes
   in interactive assembly environments}},
Booktitle = {{2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN
   INTERACTIVE COMMUNICATION, VOLS 1-3}},
Year = {{2007}},
Pages = {{745+}},
Note = {{16th IEEE International Symposium on Robot and Human Interactive
   Communication, Cheju Isl, SOUTH KOREA, AUG 26-29, 2007}},
Organization = {{IEEE}},
Abstract = {{The present article describes a scenario and respective neuro-cognitive
   psychological methods for the investigation of human-machine interaction
   in a factory context. Due to a growing demand for flexible production
   systems, adaptive interfaces for the optimal support of workers in
   manufacturing become increasingly relevant. Interacting in a complex
   production environment requires the acting person to filter multiple
   sources of information, to attentively select relevant information, to
   integrate perceptual information with action goals, to monitor these in
   working memory and to control the appropriate response actions.
   Cognitive control mechanisms in this multi-task situation will be
   analyzed in a research project on the basis of a neuroergonomic
   approach. The underlying attentional selection mechanisms and mental
   workload limitations are investigated in an assembly line scenario,
   where human performance and physiological parameters are assessed while
   the operator is performing an assembly task. In this scenario,
   instructions are presented via Augmented Reality systems, allowing for
   the presentation of task-relevant information at any time during the
   action sequence. Additionally, the production environment is simulated
   by a video projection of a typical factory surrounding. By
   experimentally varying task complexity and action goals, constraints on
   user interface design and human-machine interaction will be derived.}},
ISBN = {{978-1-4244-1634-9}},
Unique-ID = {{ISI:000255993700138}},
}

@article{ ISI:000247958700001,
Author = {Gallo, Emmanuel and Tsingos, Nicolas and Lemaitre, Guillaume},
Title = {{3D-audio matting, postediting, and rerendering from field recordings}},
Journal = {{EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING}},
Year = {{2007}},
Abstract = {{We present a novel approach to real-time spatial rendering of realistic
   auditory environments and sound sources recorded live, in the field.
   Using a set of standard microphones distributed throughout a real-world
   environment, we record the sound field simultaneously from several
   locations. After spatial calibration, we segment from this set of
   recordings a number of auditory components, together with their
   location. We compare existing time delay of arrival estimation
   techniques between pairs of widely spaced microphones and introduce a
   novel efficient hierarchical localization algorithm. Using the
   high-level representation thus obtained, we can edit and rerender the
   acquired auditory scene over a variety of listening setups. In
   particular, we can move or alter the different sound sources and
   arbitrarily choose the listening position. We can also composite
   elements of different scenes together in a spatially consistent way. Our
   approach provides efficient rendering of complex soundscapes which would
   be challenging to model using discrete point sources and traditional
   virtual acoustics techniques. We demonstrate a wide range of possible
   applications for games, virtual and augmented reality, and audio visual
   post production.}},
DOI = {{10.1155/2007/47970}},
Article-Number = {{47970}},
ISSN = {{1687-6180}},
Unique-ID = {{ISI:000247958700001}},
}

@inproceedings{ ISI:000246520400043,
Author = {Mottura, S. and Greci, L. and Travaini, E. and Vigano, G. and Sacco, M.},
Editor = {{Krause, FL}},
Title = {{MagicMirror \& FootGlove: A new system for the customized shoe try-on}},
Booktitle = {{FUTURE OF PRODUCT DEVELOPMENT}},
Year = {{2007}},
Pages = {{441+}},
Note = {{17th CIRP Design Conference, Berlin, GERMANY, MAR 26-28, 2007}},
Organization = {{CIRP; Berliner Kreis Wissensch Forum Produktentwick eV; UGS; Dassault
   Syst; IBM; PTC; InMediasP; PROSTEP; Inst Produkt \& Konstrukt; VRL; Tech
   Univ Berlin, Inst Werzeugmaschinen \& Fabrikbetrieb; PACE}},
Abstract = {{Some times, when you have the experience in a shop to buy shoes, it
   happens that you cannot find your preferred model. Starting from this
   simple problem, a new concept of shoes shop model comes out: the
   customer doesn't use a pre-built set of product samples but he can
   digitally customize in the shop the shoes, try-on the shoes in augmented
   reality and then order their realization. This type of approach opens
   new ways to the shop concept moving from concept of mass production to
   the idea of mass customization. In this field ITIA is carrying on,
   inside the CEC-Made-Shoe Project, some research activities finalized to
   the support of the try-on process of customized shoes with two systems,
   called MagicMirror (MM) and FootGlove (FG), for the feelings of wearing
   shoes. In this article, last results and improvements to MM and FG
   prototypes are presented.}},
DOI = {{10.1007/978-3-540-69820-3\_43}},
ISBN = {{978-3-540-69819-7}},
Unique-ID = {{ISI:000246520400043}},
}

@inproceedings{ ISI:000248198700017,
Author = {Sisodia, Ashok and Bayer, Michael and Townley-Smith, Paul and Nash,
   Brian and Little, Jay and Cassarly, William and Gupta, Anurag},
Editor = {{Brown, RW and Reese, CE and Marasco, PL and Harding, TH}},
Title = {{Advanced helmet mounted display (AHMD)}},
Booktitle = {{HEAD- AND HELMET-MOUNTED DISPLAYS XII: DESIGN AND APPLICATIONS}},
Series = {{Proceedings of SPIE}},
Year = {{2007}},
Volume = {{6557}},
Note = {{Conference on Head- and Helmet - Mounted Displays XII - Design and
   Applications, Orlando, FL, APR 10-11, 2007}},
Abstract = {{Due to significantly increased U.S. military involvement in deterrent,
   observer, security, peacekeeping and combat roles around the world, the
   military expects significant future growth in the demand for deployable
   virtual reality trainers with networked simulation capability of the
   battle space visualization process. The use of I-BAD technology in
   simulated virtual environments has been initiated by the demand for more
   effective training tools. The AHMD overlays computer-generated data
   (symbology, synthetic imagery, enhanced imagery) augmented with actual
   and simulated visible environment. The AHMD can be used to support
   deployable reconfigurable training solutions as well as traditional
   simulation requirements, UAV augmented reality, air traffic control and
   Command, Control, Communications, Computers, Intelligence, Surveillance,
   and Reconnaissance (C4ISR) applications. This paper will describe the
   design improvements implemented for production of the AHMD System.}},
DOI = {{10.1117/12.723765}},
Article-Number = {{65570N}},
ISSN = {{0277-786X}},
ISBN = {{978-0-8194-6679-2}},
Unique-ID = {{ISI:000248198700017}},
}

@inproceedings{ ISI:000248531100126,
Author = {Schlegel, T. and Srinivasan, A. and Foursa, M. and Bogen, M. and
   Narayanan, R. and d'Angelo, D. and Haidegger, G. and Mezgar, I. and
   Canou, J. and Salle, D. and Meo, F. and Ibarbia, J. Agirre and
   Praturlon, A. Herrmann},
Editor = {{Jacko, JA}},
Title = {{INT-MANUS: Interactive production control in a distributed environment}},
Booktitle = {{HUMAN-COMPUTER INTERACTION, PT 4, PROCEEDINGS: HCI APPLICATIONS AND
   SERVICES}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2007}},
Volume = {{4553}},
Pages = {{1150+}},
Note = {{12th International Conference on Human-Computer Interaction (HCI
   International 2007), Beijing, PEOPLES R CHINA, JUL 22-27, 2007}},
Abstract = {{The European research project INT-MANUS embedded in the I{*}PROMS
   European network of excellence addresses the increasing demand for
   flexibility and adaptivity, which is summarized by rapid
   reconfigurations of complete factories as well as related aspects in
   Human Computer Interaction (HCI), Software, and Production Systems. The
   project's main goal is to develop a new technology for the production
   plants of the future, the Smart Connected Control Platform (SCCP). This
   platform allows controlling a factory with the help of an open
   distributed learning agent platform that integrates machines, robots,
   and human personnel.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-540-73109-2}},
Unique-ID = {{ISI:000248531100126}},
}

@article{ ISI:000238321700012,
Author = {Kim, N and Woo, W and Kim, GJ and Park, CM},
Title = {{3-D virtual studio for natural inter-{''}Acting{''}}},
Journal = {{IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART A-SYSTEMS AND
   HUMANS}},
Year = {{2006}},
Volume = {{36}},
Number = {{4}},
Pages = {{758-773}},
Month = {{JUL}},
Abstract = {{Virtual studios have long been used in commercial broadcasting. However,
   most virtual studios are based on ``blue screen{''} technology, and its
   two-dimensional (2-D) nature restricts the user from making natural
   three-dimensional (3-D) interactions. Actors have to follow prewritten
   scripts and pretend as if directly interacting with the synthetic
   objects. This often creates an unnatural and seemingly uncoordinated
   output. In this paper, we introduce an improved virtual-studio framework
   to enable actors/users to interact in 3-D more naturally with the
   synthetic environment and objects. The proposed system uses a stereo
   camera to first construct a 3-D environment (for the actor to act in), a
   multiview camera to extract the image and 3-D information about the
   actor, and a real-time registration and rendering software for
   generating the final output. Synthetic 3-D objects can be easily
   inserted and rendered, in real time, together with the 3-D environment
   and video actor for natural 3-D interaction. The enabling of natural 3-D
   interaction would make more cinematic techniques possible including live
   and spontaneous acting. The proposed system is not limited to broadcast
   production, but can also be used for creating virtual/augmented-reality
   environments for training and entertainment.}},
DOI = {{10.1109/TSMCA.2005.855752}},
ISSN = {{1083-4427}},
ResearcherID-Numbers = {{Woo, Woontack/C-3696-2012}},
Unique-ID = {{ISI:000238321700012}},
}

@inproceedings{ ISI:000244443800065,
Author = {Eissele, Mike and Siemoneit, Oliver and Ertl, Thomas},
Book-Group-Author = {{IEEE}},
Title = {{Transition of mixed, virtual, and augmented reality in smart production
   environments - An interdisciplinary view}},
Booktitle = {{2006 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1
   AND 2}},
Year = {{2006}},
Pages = {{382+}},
Note = {{IEEE Conference on Robotics, Automation and Mechatronics, Bangkok,
   THAILAND, JUN 07-09, 2006}},
Organization = {{IEEE}},
Abstract = {{The advancing desire of companies to provide their customers highly
   individualized products so as to gain sustainable advantages over their
   competitors has unavoidably deep effects on the production process.
   Although augmented and virtual reality is a quite common topic of
   research, in order to meet these demands, the analysis of the seamless
   transition of different reality-states like real reality, augmented
   reality, augmented virtuality, and virtual reality within one and the
   same production task is a often neglected subject. In a broad and
   interdisciplinary approach we want to draw the attention of the research
   community on this, set the scene and explore the potential benefits and
   problems. Technical, epistemological, and philosophical as well as
   economic aspects are discussed. A prototype is presented as well as the
   results of a first explorative user test to prove the proposed concept.}},
ISBN = {{978-1-4244-0024-9}},
Unique-ID = {{ISI:000244443800065}},
}

@inproceedings{ ISI:000245508500010,
Author = {Eliens, A.},
Editor = {{McDowell, P}},
Title = {{Odyssee - Explorations in mixed reality theatre using DirectX9}},
Booktitle = {{GAMEON-NA 2006: 2ND INTERNATIONAL NORTH-AMERICAN CONFERENCE ON
   INTELLIGENT GAMES AND SIMULATION}},
Year = {{2006}},
Pages = {{62-64}},
Note = {{2nd International North-American Conference on Intelligent Games and
   Simulation, Naval Postgrad Sch, Monterey, CA, SEP 19-20, 2006}},
Organization = {{ETI; EUROSIS; Ghent Univ; UBISOFT; Larian Studios; GAME PIPE; GRAM}},
Abstract = {{In this paper we will discuss our experiences in developing a mixed
   reality application for a theatre production of the Odyssee. The Odyssee
   is a wellknown account of the travels of Ulysse leaving Troje, in 24
   episodes ending in his return to Ithaca and his reunion with Penelope.
   The actual theatre production, which is performed in temporarily empty
   office buildings, takes 12 parts which are played in 12 successive rooms
   through which the audience, subdivided in small groups, is guided one
   room after another for about five minutes per room. The initial idea was
   to have a large number of see-through goggles and augment the actual
   performance with additional information using text and images. In the
   course of the project, however, we had to scale down our ambitions, and
   we ended up using simple LCD-projection goggles with a low-resolution
   camera, for which we developed a mixed reality application, on the
   DirectX platform, using video capture projection in 3D with text and
   images. What we will describe here covers our final application, the
   criteria and guidelines we used in our production, as well as what may
   in retrospect be characterized as our explorations of DirectX.}},
ISBN = {{978-90-77381-29-8}},
Unique-ID = {{ISI:000245508500010}},
}

@article{ ISI:000234952100013,
Author = {Kim, S and Cha, J and Kim, J and Ryu, J and Eom, S and Mahalik, NP and
   Ahn, B},
Title = {{A novel test-bed for immersive and interactive broadcasting production
   using augmented reality and haptics}},
Journal = {{IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS}},
Year = {{2006}},
Volume = {{E89D}},
Number = {{1}},
Pages = {{106-110}},
Month = {{JAN}},
Note = {{14th International Conference on Artificial Reality and Telexistence
   (ICAT 2004), Seoul, SOUTH KOREA, NOV 30-DEC 02, 2004-2005}},
Abstract = {{In this paper, we demonstrate an immersive and interactive broadcasting
   production system with a new haptically enhanced multimedia broadcasting
   chain. The system adapts Augmented Reality (AR) techniques, which merges
   captured videos and virtual 3D media seamlessly through multimedia
   streaming technology, and haptic interaction technology in near
   real-time. In this system, viewers at the haptic multimedia client can
   interact with AR broadcasting production transmitted via communication
   network. We demonstrate two test applications, which show that the
   addition of AR- and haptic-interaction to the conventional audio-visual
   contents can improve immersiveness and interactivity of viewers with
   rich contents service.}},
DOI = {{10.1093/ietisy/e89-d.1.106}},
ISSN = {{0916-8532}},
Unique-ID = {{ISI:000234952100013}},
}

@inproceedings{ ISI:000238089300145,
Author = {Seo, Jinseok and Kim, Namgyu and Kim, Gerard J.},
Editor = {{Pan, ZG and Diener, H and Jin, XG and Gobel, S and Li, L}},
Title = {{Designing interactions for augmented reality based educational contents}},
Booktitle = {{TECHNOLOGIES FOR E-LEARNING AND DIGITAL ENTERTAINMENT, PROCEEDINGS}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2006}},
Volume = {{3942}},
Pages = {{1188-1197}},
Note = {{1st International Conference on Technologies for E-Learning and Digital
   Entertainment (Edutainment 2006), Hangzhou, PEOPLES R CHINA, APR 16-19,
   2006}},
Organization = {{Zhejiang Univ, DEARC, Sch Comp Sci; China Soc Image \& Graph, VR Comm;
   Zhejiang Prov, Hangzhou Natl Animat Base; Zhejiang Univ, State Key Lab
   CAD\&CG; INI GraphicsNet; Int Journal Virtual Real; IFIF SG 16
   Entertainment Comp; Nat Sci Fdn China; Peking Univ, Natl Lab Machine
   Percept; Bhihang Univ, Key Lab VR Tech MOE; Sun Yatsen Univ, Inst Comp
   Applicat; Hangzhou Dianzi Univ; Nanjing Normal Univ; Hong Kong Polytechn
   Univ}},
Abstract = {{This paper presents guidelines for designing interactions for augmented
   reality (AR) based contents for education. The guidelines stems directly
   from our experience in designing, implementing and validating an AR
   based contents for teaching the concept of ``circulation of water.{''}
   We describe the production and validation process that starts with a
   careful analysis of whether AR is (can be) appropriate for the target
   educational material. In particular, where possible, the direct tangible
   3D manipulation is applied to the important interaction points to imbue
   the ``hands-on{''} experience. The resulting contents were successfully
   put to use in real classrooms and usability and educational effects
   study is under way.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-33423-8}},
Unique-ID = {{ISI:000238089300145}},
}

@article{ ISI:000229537900006,
Author = {Dangelmaier, W and Fischer, M and Gausemeier, J and Grafe, M and
   Matysczok, C and Mueck, B},
Title = {{Virtual and augmented reality support for discrete manufacturing system
   simulation}},
Journal = {{COMPUTERS IN INDUSTRY}},
Year = {{2005}},
Volume = {{56}},
Number = {{4}},
Pages = {{371-383}},
Month = {{MAY}},
Note = {{International Working Conference on Integration in Production
   Management, Karlsruhe, GERMANY, OCT, 2003}},
Organization = {{IFIP WG 5 7}},
Abstract = {{Nowadays companies operate in a difficult environment: the dynamics of
   innovations increase and product life cycles become shorter. Furthermore
   products and the corresponding manufacturing processes get more and more
   complex. Therefore, companies need new methods for the planning of
   manufacturing systems. One promising approach in this context is digital
   factory/virtual production-the modeling and analysis of computer models
   of the planned factory with the objective to reduce time and costs, For
   the modeling and analysis various simulation methods and programs have
   been developed. They are a highly valuable support for planning and
   visualizing the manufacturing system. But there is one major
   disadvantage: only experienced and long trained experts are able to
   operate with these programs. The graphical user interface is very
   complex and not intuitive to use. This results in an extensive and
   error-prone modeling of complex simulation models and a time-consuming
   interpretation of the simulation results.
   To overcome these weak points, intuitive and understandable man-machine
   interfaces like augmented and virtual reality can be used. This paper
   describes the architecture of a system which uses the technologies of
   augmented and virtual reality to support the planning process of complex
   manufacturing systems. The proposed system assists the user in modeling,
   the validation of the simulation model, and the subsequent optimization
   of the production system. A general application of the VR- and
   AR-technologies and of the simulation is realized by the development of
   appropriate linking and integration mechanisms. For the visualization of
   the arising 3D-data within the VR- and AR-environments. a dedicated
   3D-rendering library is used, (C) 2005 Published by Elsevier B.V.}},
DOI = {{10.1016/j.compind.2005.01.007}},
ISSN = {{0166-3615}},
EISSN = {{1872-6194}},
Unique-ID = {{ISI:000229537900006}},
}

@article{ ISI:000227221800001,
Author = {Johnston, DJ and Fleury, M and Downton, AC and Clark, AF},
Title = {{Real-time positioning for augmented reality on a custom parallel machine}},
Journal = {{IMAGE AND VISION COMPUTING}},
Year = {{2005}},
Volume = {{23}},
Number = {{3}},
Pages = {{271-286}},
Month = {{MAR 1}},
Abstract = {{Augmented Reality (AR) is frequently implemented using vision processing
   for target recognition, but performance that is simultaneously robust
   and real-time is still elusive for larger frame sizes. The processing
   requirements of a particular AR system developed at the University of
   Essex (the Video Positioning System) were analysed. It has been found
   that the critical region-based processing steps could be parallelised,
   despite the resulting complex accumulation of intermediate results. The
   paper presents the parallel algorithms involved and the performance
   achieved. Comparison is made with more traditional edge-based systems,
   which may execute somewhat faster but are not as robust. The success of
   the parallelisation overcomes this performance limitation, and suggests
   a future production route. (C) 2003 Elsevier B.V.. All rights reserved.}},
DOI = {{10.1016/j.imavis.2003.08.002}},
ISSN = {{0262-8856}},
Unique-ID = {{ISI:000227221800001}},
}

@inproceedings{ ISI:000233395400034,
Author = {Barakonyi, I and Schmalstieg, D},
Editor = {{Kishino, F and Kitamura, Y and Kato, H and Nagata, N}},
Title = {{Augmented reality agents in the development pipeline of computer
   entertainment}},
Booktitle = {{ENTERTAINMENT COMPUTING - ICEC 2005}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2005}},
Volume = {{3711}},
Pages = {{345-356}},
Note = {{4th International Conference on Entertainment Computing (ICEC 2005),
   Sanda, JAPAN, SEP 16-21, 2005}},
Organization = {{Int Federat Informat Proc; Informat Proc Soc Japan; Kwansei Gakuin Univ;
   Embassy France in Japan; Commemorat Org Japan World Expansit 70; Tsutomu
   Nakauchi Fdn; Support Ctr Adv Telecommun Technol Ctr; Hyogo Prefecture}},
Abstract = {{Augmented reality (AR) has recently stepped beyond the usual scope of
   applications like machine maintenance, military training and production,
   and has been extended to the realm of entertainment including computer
   gaming. This paper discusses the potential AR environments offer for
   embodied animated agents, and demonstrates several advanced immersive
   content and scenario authoring techniques in AR through example
   applications.}},
ISSN = {{0302-9743}},
ISBN = {{3-540-29034-6}},
Unique-ID = {{ISI:000233395400034}},
}

@inproceedings{ ISI:000231052700013,
Author = {Sarwal, A and Baker, C and Filipovic, D},
Editor = {{Rash, CE}},
Title = {{Head-worn display-based augmented reality system for manufacturing}},
Booktitle = {{Helmet- and Head-Mounted Displays X: Technologies and Applications}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2005}},
Volume = {{5800}},
Pages = {{115-122}},
Note = {{Conference on Helmet- and Head-Mounted Displays X, Orlando, FL, MAR
   28-29, 2005}},
Organization = {{SPIE}},
Abstract = {{This system provides real-time guidance for training and problem-solving
   on production-line machinery. A prototype of a wearable, real-time,
   video guidance, interactive system for use in manufacturing, has been
   developed and demonstrated. Anticipated benefits are: relatively
   inexperienced personnel can provide machine servicing and the dependency
   on the vendor to repair or maintain equipment is significantly reduced.
   Additionally, servicing, training or part change-over schedules can be
   exercised more predictably and with less training. This approach
   utilizes Head Worn Display or Head Mounted Display (HMD) technology that
   can be readily adapted for various machines on the factory floor with
   training steps for a new location. Such a system can support various
   applications in manufacturing such as direct video guiding or applying
   scheduled maintenance and training to effectively resolve servicing
   emergencies and reduce machine downtime. It can also provide training of
   inexperienced operators and maintenance personnel. The gap between
   production line complexity and ability of production personnel to
   effectively maintain equipment is expected to widen in the future and
   advanced equipment will require complex servicing procedures that are
   neither well documented nor user-friendly. This system offers benefits
   in increased manufacturing equipment availability by facilitating
   effective servicing and training and can interface to a server system
   for additional computational resources on an as-needed basis. This
   system utilizes markers to guide the user and enforces a well defined
   sequence of operations. It performs augmentation of information on the
   display in order to provide guidance in real-time.}},
DOI = {{10.1117/12.603142}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-5785-X}},
Unique-ID = {{ISI:000231052700013}},
}

@inproceedings{ ISI:000233695600007,
Author = {Melchior, F and Laubach, T and de Vries, D},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Authoring and user interaction for the production of wave field
   synthesis content in an augmented reality system}},
Booktitle = {{International Symposium on Mixed and Augmented Reality, Proceedings}},
Year = {{2005}},
Pages = {{48-51}},
Note = {{4th IEEE/ACM International Symposium on Mixed and Augmented Reality (
   ISMAR 2005), Vienna, AUSTRIA, OCT 05-08, 2005}},
Organization = {{IEEE; ACM; IEEE Comp Soc; XSENS; NOKIA; Trivisio; SIEMENS; Engn Syst
   Technol; INTERSENSE; Fdn Stift}},
Abstract = {{Wave field synthesis (WFS) enables the accurate reproduction of a sound
   field for a large listening area with correct characteristics for each
   listener position. An exact perspective on the synthesized wave field is
   provided for every listener. Therefore, WFS-technology is ideally suited
   to be combined with augmented reality systems, where every user
   perceives his own visual perspective of a given scene. This paper
   presents a concept for authoring and user interaction for the production
   of wave field synthesis content in an augmented reality system. Also,
   the implementation of a prototype WFS-AR System based on ARToolkit is
   explained.}},
ISBN = {{0-7695-2459-1}},
Unique-ID = {{ISI:000233695600007}},
}

@inproceedings{ ISI:000233695600015,
Author = {Lee, W and Park, J},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{Augmented foam: A tangible augmented reality for product design}},
Booktitle = {{INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS}},
Year = {{2005}},
Pages = {{106-109}},
Note = {{4th IEEE/ACM International Symposium on Mixed and Augmented Reality (
   ISMAR 2005), Vienna, AUSTRIA, OCT 05-08, 2005}},
Organization = {{IEEE; ACM; IEEE Comp Soc; XSENS; NOKIA; Trivisio; SIEMENS; Engn Syst
   Technol; INTERSENSE; Fdn Stift}},
Abstract = {{Computer Aided Design applications have become designers' inevitable
   tools for expressing and simulating innovative ideas and concepts.
   However, replacing traditional materials and mock-ups with 3D CAD
   systems, designers are faced with the intangibility problem, unable to
   physically interact with test products in early stages of design
   process. As a touchable and graspable interface based on 3D CAD data, we
   propose Augmented Foam, which applies Augmented Reality technologies to
   physical blue foams. Using Augmented Foam, a blue foam mock-up is
   overlaid with a 3D virtual object, which is rendered with the same CAD
   model used for mock-up production. We presented a method to correct
   occlusions of the virtual products by user's hand Augmented Foam was
   tested for a mug design and a cleaning robot design. Designers were able
   to inspect and evaluate the design alternatives interactively and
   efficiently.}},
ISBN = {{0-7695-2459-1}},
Unique-ID = {{ISI:000233695600015}},
}

@inproceedings{ ISI:000233695600037,
Author = {Shin, M and Kim, BS and Park, J},
Book-Group-Author = {{IEEE Comp Soc}},
Title = {{AR storyboard: An augmented reality based interactive storyboard
   authoring tool}},
Booktitle = {{International Symposium on Mixed and Augmented Reality, Proceedings}},
Year = {{2005}},
Pages = {{198-199}},
Note = {{4th IEEE/ACM International Symposium on Mixed and Augmented Reality (
   ISMAR 2005), Vienna, AUSTRIA, OCT 05-08, 2005}},
Organization = {{IEEE; ACM; IEEE Comp Soc; XSENS; NOKIA; Trivisio; SIEMENS; Engn Syst
   Technol; INTERSENSE; Fdn Stift}},
Abstract = {{In early stages of production, storyboards are used for visually
   describing the story and the script. In this paper, an Augmented Reality
   based storyboard-authoring tool is introduced Proposed tool is
   easy-to-use, and provides intuitive interface for scene composition and
   camera pose/motion control. Using AR Storyboard, non-experienced users
   may compose 3D scenes for a storyboard using interfaces in his/her real
   environments.}},
ISBN = {{0-7695-2459-1}},
Unique-ID = {{ISI:000233695600037}},
}

@inproceedings{ ISI:000231416200108,
Author = {Mueck, B and Hower, M and Franke, W and Dangelmaier, W},
Editor = {{Abraham, A and Dote, Y and Furuhashi, T and Koppen, M and Ohuchi, A and Ohsawa, Y}},
Title = {{Augmented reality applications for warehouse logistics}},
Booktitle = {{Soft Computing as Transdisciplinary Science and Technology}},
Series = {{ADVANCES IN SOFT COMPUTING}},
Year = {{2005}},
Pages = {{1053-1062}},
Note = {{4th IEEE International Workshop on Soft Computing as Transdisciplinary
   Science and Technology (WSTST 05), Muroran Inst Technol, Muroran, JAPAN,
   2005}},
Organization = {{IEEEE Syst Man \& Cybernet Soc; World Federat Soft Comp; European Soc
   Fuzzy Log \& Technol; Japan Soc Promot Sci; Soc Instrumentat \& Control
   Engineers; Transdisciplinary Federat Sci \& Technol; JSPS Int Meeting
   Series; Life Oriented Software Lab}},
Abstract = {{The costs for material flow and logistics generate a major part of the
   prime costs for a product. Thereby warehouse and distribution logistics
   take an outstanding position in inner- and outer operational supply
   chain. Under the circumstances that on average 2/3rd of the operational
   costs for logistics are accounted for warehouse management tasks, it is
   clear evidently that these costs hove a decisive influence on the
   competitive position of a company. As part of a cooperative project of
   the ``Logistics \& Assembly Systems{''} of Siemens AG, one of the
   leading companies in logistics and production automation, and the
   department for Computer Integrated Manufacturing of the University, of
   Paderborn, the worlds first Augmented Reality based picking system was
   developed in the labs at Heinz Nixdorf Institute Paderborn. The
   prototype that emanated from the development process has been approved
   in extensive tests under laboratory conditions. The evaluation of the
   test results verified the potential to improve the work,flow and picking
   efficiency with an Augmented Reality based picking system.}},
ISSN = {{1615-3871}},
ISBN = {{3-540-25055-7}},
Unique-ID = {{ISI:000231416200108}},
}

@inproceedings{ ISI:000222801300080,
Author = {Lourakis, MIA and Argyros, AA},
Book-Group-Author = {{ieee computer society}},
Title = {{Vision-based camera motion recovery for augmented reality}},
Booktitle = {{COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS}},
Year = {{2004}},
Pages = {{569-576}},
Note = {{Computer Graphics International Conference (CGI 2004), Crete, GREECE,
   JUN 16-19, 2004}},
Organization = {{SCI}},
Abstract = {{We address the problem of tracking the 3D position and orientation of a
   camera, using the images it acquires while moving freely in unmodeled,
   arbitrary environments. This task has a broad spectrum of useful
   applications in domains such as augmented reality and video post
   production. Most of the existing methods for vision-based camera
   tracking are designed to operate in a batch, off-line mode, assuming
   that the whole video sequence to be tracked is available before tracking
   commences. Typically, such methods operate non-causally, processing
   video frames backwards and forwards in time as they see fit.
   Furthermore, they resort to optimization in very high dimensional
   spaces, a process that is computationally intensive. For these reasons,
   batch methods are inapplicable to tracking in on-line, time-critical
   applications such as video see-through augmented reality. This paper
   puts forward a novel feature-based approach for camera tracking. The
   proposed approach operates on images continuously as they are acquired,
   has realistic computational requirements and does not require
   modifications of the environment. Sample experimental results
   demonstrating the feasibility of the approach on video images are also
   provided.}},
DOI = {{10.1109/CGI.2004.1309266}},
ISBN = {{0-7695-2171-1}},
ORCID-Numbers = {{Lourakis, Manolis/0000-0003-4596-5773
   Argyros, Antonis/0000-0001-8230-3192}},
Unique-ID = {{ISI:000222801300080}},
}

@inproceedings{ ISI:000222342300050,
Author = {Ozbek, CS and Giesler, B and Dillmann, R},
Editor = {{Woods, AJ and Merritt, JO and Benton, SA and Bolas, MT}},
Title = {{Jedi training: Playful evaluation of head-mounted augmented reality
   display systems}},
Booktitle = {{STEREOSCOPIC DISPLAYS AND VIRTUAL REALITY SYSTEMS XI}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2004}},
Volume = {{5291}},
Pages = {{454-463}},
Note = {{Conference on Stereoscopic Displays and Virtual Reality Systems XI, San
   Jose, CA, JAN 19-22, 2004}},
Organization = {{Soc Imaging Sci \& Technol; SPIE}},
Abstract = {{A fundamental decision in building augmented reality (AR) systems is how
   to accomplish the combining of the real and virtual worlds.' Nowadays
   this key question boils down to the two alternatives video-see-through
   (VST) vs. optical-see-through (OST). Both systems have advantages and
   disadvantages in areas like production-simplicity, resolution,
   flexibility in composition strategies, field of view etc. To provide
   additional decision criteria for high dexterity, accuracy tasks and
   subjective user-acceptance a gaming environment was programmed that
   allowed good evaluation of hand-eye coordination, and that was inspired
   by the Star Wars movies. During an experimentation session with more
   than thirty participants a preference for optical-see-through glasses in
   conjunction with infra-red-tracking was found. Especially the
   high-computational demand for video-capture, processing and the
   resulting drop in frame rate emerged as a key-weakness of the
   VST-system.}},
DOI = {{10.1117/12.527945}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-5194-0}},
Unique-ID = {{ISI:000222342300050}},
}

@article{ ISI:000182527700001,
Author = {Park, C and Ahn, SC and Kwon, YM and Kim, HG and Ko, H and Kim, T},
Title = {{Gyeongju VR theater: A journey into the breath of Sorabol}},
Journal = {{PRESENCE-TELEOPERATORS AND VIRTUAL ENVIRONMENTS}},
Year = {{2003}},
Volume = {{12}},
Number = {{2}},
Pages = {{125-139}},
Month = {{APR}},
Abstract = {{We have built the world's largest virtual reality (VR) theater for the
   Gyeongju World Culture EXPO 2000. The VR theater is characterized by a
   huge shared VR space with tightly coupled user inputs from 651 audience
   members in real time. The shared 3D virtual environment is augmenting
   the physical audience space in harmony. Large computer-generated passive
   stereo images on a huge cylindrical screen provide the sensation of
   visual immersion. The theater also provides 3D audio, vibration, and
   olfactory display as well as the keypads for each of the audience
   members to interactively control the virtual environment. This paper
   introduces the issues raised and addressed during the design of a
   versatile VR theater, the production process, and the presentation
   techniques using the versatile display and interaction capability of the
   future theater.}},
DOI = {{10.1162/105474603321640905}},
ISSN = {{1054-7460}},
Unique-ID = {{ISI:000182527700001}},
}

@inproceedings{ ISI:000230168400029,
Author = {Grunvogel, SM and Schwichtenberg, S},
Editor = {{Mehdi, Q and Gough, N and Natkin, S}},
Title = {{A system for creating simple character behaviours}},
Booktitle = {{GAME-ON 2003: 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND
   SIMULATION}},
Year = {{2003}},
Pages = {{180-184}},
Note = {{4th International Conference on Intelligent Games and Simulation, IEE,
   London, ENGLAND, NOV 19-21, 2003}},
Organization = {{EUROSIS; Univ Wolverhampton; ISA; Binary Illus; CNAM; GIGnews com; Ghent
   Univ; Modelbenders; Nottingham Trent Univ; Sheffield Univ; MOVE Inst;
   Univ Paisley; Warthog}},
Abstract = {{We introduce a real-time character animation system which is currently
   used in an augmented reality environment for the fast creation of simple
   character behaviour. By placing and manipulating commands on a timeline,
   the overall choreography of the characters' movement is created. The
   movement of the character is controlled by subtasks which model reactive
   behaviour and control the dynamic motions model for the production of
   the animation.}},
ISBN = {{90-77381-05-8}},
Unique-ID = {{ISI:000230168400029}},
}

@inproceedings{ ISI:000223178200016,
Author = {Woolard, A and Lalioti, V and Hedley, N and Julien, J and Hammond, M and
   Carrigan, N},
Book-Group-Author = {{IEEE}},
Title = {{Using ARToolkit to prototype future entertainment scenarios}},
Booktitle = {{IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP}},
Year = {{2003}},
Pages = {{69-70}},
Note = {{2nd IEEE International Augmented Reality Toolkit Workshop, Waseda Univ.
   Nishi Waseda Campus, Tokyo, JAPAN, OCT   07, 2003}},
Organization = {{IEEE Singapore Sect}},
Abstract = {{This demonstration poster illustrates the potential application of
   augmented reality (AR) in creation of future interactive entertainment
   experiences. It describes the production of prototypes using ARToolkit
   that use physically manipulated AR within television broadcast
   production and in home entertainment for children.}},
DOI = {{10.1109/ART.2003.1320430}},
ISBN = {{0-7803-8240-4}},
Unique-ID = {{ISI:000223178200016}},
}

@inproceedings{ ISI:000188415500089,
Author = {Wenzel, S and Bernhard, J and Jessen, U},
Editor = {{Chick, SE and Sanchez, PJ and Ferrin, D and Morrice, DJ}},
Title = {{A taxonomy of visualization techniques for simulation in production and
   logistics}},
Booktitle = {{PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2}},
Year = {{2003}},
Pages = {{729-736}},
Note = {{36th Winter Simulation Conference, NEW ORLEANS, LA, DEC 07-10, 2003}},
Organization = {{Amer Stat Assoc; IEEE Comp Soc; IEEE SMC; Inst Ind Engineers; INFORMS,
   Coll Simulat; NIST; Soc Modeling \& Simulat Int}},
Abstract = {{Simulation has become one of the most important techniques with regard
   to manufacturing and logistics systems. During modeling and
   experimenting simulation input and output data have to be presented to
   different target groups which range from simulation experts and factory
   planners to representatives of company management, and for different
   tasks and specific purposes. Different kinds of visualization techniques
   are used to present the simulation data, from static techniques as
   charts and layout plans to dynamic techniques as 2-D or 3-D animation as
   well as Virtual or Augmented Reality. But often, non-expressive and
   non-effective visualizations prevent the understanding of simulation
   output. This paper presents a taxonomy of visualization techniques for
   simulation in production and logistics and outlines how to use this
   taxonomy as a base for decision support to select the right
   visualization technique for specific target groups.}},
DOI = {{10.1109/WSC.2003.1261489}},
ISBN = {{0-7803-8131-9}},
Unique-ID = {{ISI:000188415500089}},
}

@inproceedings{ ISI:000222545600102,
Author = {Beu, A and Quaet-Faslem, P and Koller, F},
Editor = {{Strasser, H and Kluth, K and Rausch, H and Bubb, H}},
Title = {{User-centered development of cross platform user interfaces for
   industrial production}},
Booktitle = {{QUALITY OF WORK AND PRODUCTS IN ENTERPRISES OF THE FUTURE}},
Year = {{2003}},
Pages = {{445-448}},
Note = {{Annual Spring Conference of the GfA/17th Annual Conference of the
   International-Society-for-Occupational-Ergonomics-and-Safety (ISOES),
   Munich, GERMANY, MAY 07-AUG 09, 2003}},
Organization = {{Fdn Gesell Arbeitswissensch; Int Soc Occupat Ergonom \& Safety}},
Abstract = {{ARVIKA is a project which aims at the practical deployment of Augmented
   Reality (AR) as a tool for real users with real service and maintenance
   tasks. Since the user interface is seen as a crucial factor for the
   success of this technology, it is a major aspect within the project.
   With AR being a new technology without elaborated concepts for layout
   and functionality of a user interface, its realization requires the
   development of completely new interaction concepts and techniques for
   information presentation. Therefore ARVIKA follows a user-centered
   design process exploring the design space systematically. Based on
   empirical data, design decisions are taken in the course of an iterative
   process. A special requirement is the support of different platforms
   i.e. head mounted displays (HMD) and handheld devices.}},
ISBN = {{3-935089-68-6}},
Unique-ID = {{ISI:000222545600102}},
}

@inproceedings{ ISI:000186635100046,
Author = {Woolard, A and Lalioti, V and Hedley, N and Carrigan, N and Hammond, M
   and Julien, J},
Book-Group-Author = {{IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY}},
Title = {{Case studies in application of augmented reality in future media
   production}},
Booktitle = {{SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED
   REALITY, PROCEEDINGS}},
Year = {{2003}},
Pages = {{294-295}},
Note = {{2nd IEEE/ACM International Symposium on Mixed and Augmented Reality,
   TOKYO, JAPAN, OCT 07-10, 2003}},
Organization = {{IEEE Comp Soc, Tech Comm Wearable Informat Syst; IEEE Comp Soc, Task
   Force Human Cent Informat Syst; SIGMAR, Vitual Real Soc Japan; ACM
   SIGGRAPH, SIGCHI; Inst Elect, Informat, \& Communicat Engineers; Soc
   Instrument \& Control Engineers; Informat Proc Soc Japan; Japanese Soc
   Artif Intelligence; Robotics Soc Japan; Human Interface Soc; Japan Soc
   Mech Engineers}},
Abstract = {{In this application-based poster, we describe three case studies about
   potential applications of augmented reality (AR) in the broadcasting and
   entertainment industry. The poster covers the potential impact on BBC's
   principal objectives to `entertain, educate and inform' in a variety of
   environments such as broadcast studios, classrooms and in the home.}},
DOI = {{10.1109/ISMAR.2003.1240727}},
ISBN = {{0-7695-2006-5}},
Unique-ID = {{ISI:000186635100046}},
}

@inproceedings{ ISI:000182378400039,
Author = {Park, C and Kim, IJ and Ahn, SC and Ko, H and Kwon, YM and Kim, HG},
Editor = {{Pan, ZG and Shi, JY}},
Title = {{The design and implementation of Kyongju VR theatre}},
Booktitle = {{THIRD INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND ITS APPLICATION IN
   INDUSTRY}},
Series = {{PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)}},
Year = {{2003}},
Volume = {{4756}},
Pages = {{286-293}},
Note = {{3rd International Conference on Virtual Reality and Its Application in
   Industry, HANGZHOU, PEOPLES R CHINA, APR 09-12, 2002}},
Organization = {{China Soc Image \& Graph; Eurographics; VR Soc Japan; Korean Assoc VR;
   IEEE CS Beijing; Nat Sci Fdn China}},
Abstract = {{Recently we have built the largest Virtual Reality (VR) theatre in the
   world for the Kyongju World Culture EXPO 2000. Unlike single user VR
   systems, the VR theatre is characterized by a single shared screen and
   controlled by several hundreds of people in the audience. The large
   computer-generated stereo images displayed by the huge cylindrical
   screen provide the feeling of immersion into 3D virtual environment that
   is augmented by the physical theatre space. In addition to the visual
   immersion, the theatre provides 3D audio, vibration and olfactory
   display as well as keypads for each and everyone in the audience in
   their seats interactively control the virtual environment. This paper
   introduces the issues raised and addressed during the design of making
   the VR theatre, production process and presentation techniques using the
   versatile display and interaction capabilities of the theatre.}},
DOI = {{10.1117/12.498006}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-4519-3}},
Unique-ID = {{ISI:000182378400039}},
}

@article{ ISI:000177711500006,
Author = {Merians, AS and Jack, D and Boiau, R and Tremaine, M and Burdea, GC and
   Adamovich, SV and Recce, M and Poizner, H},
Title = {{Virtual reality-augmented rehabilitation for patients following stroke}},
Journal = {{PHYSICAL THERAPY}},
Year = {{2002}},
Volume = {{82}},
Number = {{9}},
Pages = {{898-915}},
Month = {{SEP}},
Abstract = {{Background and Purpose. Recent evidence indicates that intensive massed
   practice may be necessary to modify neural organization and effect
   recovery of motor skills in patients following stroke. Virtual reality
   (VR) technology has the capability of creating ail interactive,
   motivating environment in which practice intensity and feedback can be
   manipulated to create individualized treatments to retrain movement.
   Case Description. Three patients (NIL, LE, and DK), who were in the
   chronic phase following stroke, participated in a 2-week training
   ;program (31/2, hours a day) including dexterity tasks oil real objects
   and VR exercises. The VR simulations were targeted for range of motion,
   movement speed, fractionation, and force production. Outcomes. NIL's
   function was the most impaired at the beginning of the intervention, but
   showed improvement in the thumb and fingers in range of motion and speed
   of movement, LE improved in fractionation and range of motion of his
   thumb and fingers. DK made the greatest gains, showing improvement in
   range of motion and strength of the thumb, velocity of the thumb and
   fingers, and fractionation. Two of the 3 patients improved on the Jebsen
   Test of Fland Function. Discussion. The outcomes suggest that VR may be
   useful to augment rehabilitation of the upper limb in patients in the
   chronic phase following stroke. {[}Merians AS,Jack D, Boian R, et al.
   Virtual reality-augmented reliabilitation for patients following stroke.}},
ISSN = {{0031-9023}},
ResearcherID-Numbers = {{Winstein, Carolee/A-8375-2008}},
Unique-ID = {{ISI:000177711500006}},
}

@article{ ISI:000175272600008,
Author = {Macintyre, B and Lohse, M and Bolter, JD and Moreno, E},
Title = {{Integrating 2-D video actors into 3-D augmented-reality systems}},
Journal = {{PRESENCE-TELEOPERATORS AND VIRTUAL ENVIRONMENTS}},
Year = {{2002}},
Volume = {{11}},
Number = {{2}},
Pages = {{189-202}},
Month = {{APR}},
Abstract = {{In this paper, we discuss the integration of 2-D video actors into 3-D
   augmented-reality (AR) systems. In the context of our research on
   narrative forms for AR we have found ourselves needing highly expressive
   content that is most easily created by human actors. We discuss the
   feasibility and utility of using video actors in an AR situation and
   then present our Video Actor Framework (including the VideoActor editor
   and the Video3D Java package) for easily integrating 2-D videos of
   actors into Java 3D, an object-oriented 3-D graphics programming
   environment. The framework is based on the idea of supporting tight
   spatial and temporal synchronization between the content of the video
   and the rest of the 3-D world. We present a number of illustrative
   examples that demonstrate the utility of the toolkit and editor. We
   close with a discussion and example of our recent work implementing
   these ideas in Macromedia Director, a popular multimedia production
   tool.}},
DOI = {{10.1162/1054746021470621}},
ISSN = {{1054-7460}},
EISSN = {{1531-3263}},
ResearcherID-Numbers = {{MacIntyre, Blair/A-7207-2012}},
ORCID-Numbers = {{MacIntyre, Blair/0000-0002-5357-2366}},
Unique-ID = {{ISI:000175272600008}},
}

@inproceedings{ ISI:000175725500035,
Author = {Park, CH and Ko, H and Kim, IJ and Ahn, SC and Kwon, YM and Kim, HG},
Editor = {{Loftin, B and Chen, JX and Rizzo, S and Goebel, M and Hirose, M}},
Title = {{The making of Kyongju VR theatre}},
Booktitle = {{IEEE VIRTUAL REALITY 2002, PROCEEDINGS}},
Series = {{PROCEEDINGS OF THE IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM}},
Year = {{2002}},
Pages = {{269-270}},
Note = {{Virtual Reality 2002 Conference, ORLANDO, FL, MAR 24-28, 2002}},
Organization = {{IEEE Comp Soc; IEEE}},
Abstract = {{Recently we have built the largest Virtual Reality (VR) theatre in the
   world for the Kyongju World Culture EXPO 2000. Unlike single user VR
   systems, the VR theatre is characterized by a single shared screen and
   controlled by a kind of tightly coupled user inputs from several
   hundreds of people in the audience. The large computer-generated stereo
   images by the huge cylindrical screen provide the immersive feeling
   augmenting the physical audience space with of 3D virtual space. In
   addition to the visual immersion, the theatre provides 3D audio,
   vibration and olfactory display as well as keypads for the audience in
   their seats interactively controlling the virtual environment. This
   paper introduces the issues raised and addressed during the design of
   making such a versatile VR theatre, production and presentation of the
   virtual heritage at Kyongju, one thousand years ago.}},
DOI = {{10.1109/VR.2002.996532}},
ISSN = {{1087-8270}},
ISBN = {{0-7695-1492-8}},
Unique-ID = {{ISI:000175725500035}},
}

@inproceedings{ ISI:000178662400001,
Author = {Friedrich, W},
Book-Group-Author = {{IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY}},
Title = {{ARVIKA - Augmented reality for development, production and service}},
Booktitle = {{INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS}},
Year = {{2002}},
Pages = {{3-4}},
Note = {{International Symposium on Mixed and Augmented Reality, DARMSTADT,
   GERMANY, SEP 30-OCT 01, 2002}},
Organization = {{IEEE Comp Soc, TC Wearable Informat Syst; IEEE Comp Soc, Task Force
   Human Centered Informat Syst; Fraunhofer IGD; ACM; SIGGRAPH; SIGCHI;
   Eurographics}},
DOI = {{10.1109/ISMAR.2002.1115059}},
ISBN = {{0-7695-1781-1}},
Unique-ID = {{ISI:000178662400001}},
}

@inproceedings{ ISI:000178662400010,
Author = {Fiorentino, M and de Amicis, R and Monno, G and Stork, A},
Book-Group-Author = {{IEEE COMPUTER SOCIETY
   IEEE COMPUTER SOCIETY}},
Title = {{Spacedesign: A mixed reality workspace for aesthetic industrial design}},
Booktitle = {{INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS}},
Year = {{2002}},
Pages = {{86+}},
Note = {{International Symposium on Mixed and Augmented Reality, DARMSTADT,
   GERMANY, SEP 30-OCT 01, 2002}},
Organization = {{IEEE Comp Soc, TC Wearable Informat Syst; IEEE Comp Soc, Task Force
   Human Centered Informat Syst; Fraunhofer IGD; ACM; SIGGRAPH; SIGCHI;
   Eurographics}},
Abstract = {{Spacedesign is an innovative Mixed Reality (MR) application addressed to
   aesthetic design of free form curves and surfaces. It is a unique and
   comprehensive approach which uses task-specific configurations to
   support the design workflow from concept to mock-up evaluation and
   review. The first-phase conceptual design benefits from a workbench-like
   3-D display for free hand sketching, surfacing and engineering
   visualization. Semitransparent stereo glasses augment the pre-production
   physical prototype by additional shapes, textures and annotations. Both
   workspaces share a common interface and allow collaboration and
   cooperation between different experts, who can configure the system for
   the specific task. A faster design workflow and CAD data consistency can
   be thus naturally achieved. Tests and collaborations with designers,
   mainly from automotive industry, are providing systematic feedback for
   this ongoing research. As far as the authors are concerned, there is no
   known similar approach that integrates the creation and editing phase of
   3D curves and surfaces in Virtual and Augmented Reality (VR/AR). Herein
   we see the major contribution of our new application.}},
DOI = {{10.1109/ISMAR.2002.1115077}},
ISBN = {{0-7695-1781-1}},
ResearcherID-Numbers = {{Monno, Giuseppe/I-5811-2015
   Fiorentino, Michele/A-5952-2011}},
ORCID-Numbers = {{Monno, Giuseppe/0000-0003-4120-4096
   }},
Unique-ID = {{ISI:000178662400010}},
}

@inproceedings{ ISI:000180551000003,
Author = {Oehme, O and Wiedenmaier, S and Schmidt, L},
Book-Group-Author = {{VDI
   VDI}},
Title = {{Evaluation of an Augmented Reality user interface for a binocular video
   see through head mounted display}},
Booktitle = {{USEWARE 2002}},
Series = {{VDI BERICHTE}},
Year = {{2002}},
Volume = {{1678}},
Pages = {{35-40}},
Note = {{Conference on Man-Machine-Communication/Design, DARMSTADT, GERMANY, JUN
   11-12, 2002}},
Organization = {{VDI, VDE Gesell}},
Abstract = {{Nowadays Augmented Reality (AR) is one of the most promising
   technologies for the human-machine-interaction. Augmented reality merges
   virtual reality with the real environment and it is already used in
   industrial applications (a. g. for product or process information). In a
   production environment the evaluation of a prototype by usability
   testing was conducted to investigate the AR user interface concept. By
   involving potential users important suggestions to improve the system
   for industrial use were established and can be used for the future
   development of the system.}},
ISSN = {{0083-5560}},
ISBN = {{3-18-091678-8}},
Unique-ID = {{ISI:000180551000003}},
}

@article{ ISI:000173772800004,
Author = {Wenzel, S and Jessen, U},
Title = {{The integration of 3-D visualization into the simulation-based planning
   process of logistics systems}},
Journal = {{SIMULATION}},
Year = {{2001}},
Volume = {{77}},
Number = {{3-4}},
Pages = {{114-127}},
Month = {{SEP-OCT}},
Abstract = {{The integration of information and communication technology into
   existing business processes effects all areas of a company including
   factory planning. The structure of the process of change is based on
   model-supported processes as well as tools and techniques that are
   already in use. These include established discrete event simulation
   tools that have been used in the area of production and logistics
   planning for several years, and innovative visualization techniques such
   as 3-D animation, Virtual Reality (VR) and Augmented Reality (AR).
   Visualization has become very necessary in the planning, realization and
   operation of a factory because the data for the different target groups
   within a company, from the operating staff up to management, has to be
   processed into realizable information. The authors, motivated by this
   initial situation, have placed the conceptual universality of the use of
   methods in the foreground, using distributed architecture and the
   targeted use of 3-D modeling in logistics planning as an add-on to
   discrete event simulation. This article introduces a generally
   applicable concept for the user- defined mapping of discrete event
   simulation models onto animation models, describes the aspects of
   realization, and considers into an animation pipeline.}},
DOI = {{10.1177/003754970107700304}},
ISSN = {{0037-5497}},
Unique-ID = {{ISI:000173772800004}},
}

@inproceedings{ ISI:000168019800014,
Author = {Sequeira, V and Wolfart, E and Bovisio, E and Biotti, E and Goncalves,
   JGM},
Editor = {{ELHakim, SFF and Gruen, A}},
Title = {{Hybrid 3D reconstruction and image based rendering techniques for
   reality modelling}},
Booktitle = {{VIDEOMETRICS AND OPTICAL METHODS FOR 3D SHAPE MEASUREMENT}},
Series = {{Proceedings of SPIE}},
Year = {{2001}},
Volume = {{4309}},
Pages = {{126-136}},
Note = {{Conference on Videometrics and Optical Methods for 3D Shape Measurement,
   SAN JOSE, CA, JAN 22-23, 2001}},
Organization = {{Soc Imaging Sci \& Technol; SPIE}},
Abstract = {{This paper presents a component approach that combines in a seamless way
   the strong features of laser range acquisition with the visual quality
   of purely photographic approaches. The relevant components of the system
   are: i) Panoramic images for distant background scenery where parallax
   is insignificant; ii) Photogrammetry for background buildings and iii)
   High detailed laser based models for the primary environment, structure
   of exteriors of buildings and interiors of rooms. These techniques have
   a wide range of applications in visualization, virtual reality, cost
   effective as-built analysis of architectural and industrial
   environments, building facilities management, real-estate, E-commerce
   (Tourism and Cultural Heritage), remote inspection of hazardous
   environments, TV production and many others.}},
ISSN = {{0277-786X}},
ISBN = {{0-8194-3987-8}},
Unique-ID = {{ISI:000168019800014}},
}

@article{ ISI:000087857000009,
Author = {Haase, H and Bock, M and Hergenrother, E and Knopfle, C and Koppert, HJ
   and Schroder, F and Trembilski, A and Weidenhausen, J},
Title = {{Meteorology meets computer graphics - a look at a wide range of weather
   visualisations for diverse audiences}},
Journal = {{COMPUTERS \& GRAPHICS-UK}},
Year = {{2000}},
Volume = {{24}},
Number = {{3}},
Pages = {{391-397}},
Month = {{JUN}},
Abstract = {{Sophisticated scientific visualisation allows experts as well as lay
   persons to extract knowledge from complex data. This is particularly
   true for visualising the massive amounts of data involved in
   meteorological observations and simulations. These are of special
   interest to scientists, to forecasters, and to the general public. The
   paper presents and discusses a range of solutions for meteorological
   visualisation. Topics covered include systems for the production of TV
   weather forecasts, for the analysis of simulation output by experts, for
   weather information in the Web, and for meteorological visualisation
   using Virtual Studio, Augmented Reality and Augmented Video technology.
   (C) 2000 Elsevier Science Ltd. All rights reserved.}},
DOI = {{10.1016/S0097-8493(00)00035-2}},
ISSN = {{0097-8493}},
EISSN = {{1873-7684}},
Unique-ID = {{ISI:000087857000009}},
}

@article{ ISI:000207088400002,
Author = {Stauder, Juergen},
Title = {{Augmented Reality with Automatic Illumination Control Incorporating
   Ellipsoidal Models}},
Journal = {{IEEE TRANSACTIONS ON MULTIMEDIA}},
Year = {{1999}},
Volume = {{1}},
Number = {{2}},
Pages = {{136-143}},
Month = {{JUN}},
Abstract = {{In applications of augmented reality like virtual studio TV production,
   multisite video conference applications using a virtual meeting room and
   synthetic/natural hybrid coding according to the new ISO/MPEG-4
   standard, a synthetic scene is mixed into a natural scene to generate a
   synthetic/natural hybrid image sequence. For realism, the illumination
   in both scenes should be identical. In this paper, the illumination of
   the natural scene is estimated automatically and applied to the
   synthetic scene. The natural scenes are restricted to scenes with
   nonoccluding, simple, moving, mainly rigid objects. For illumination
   estimation, these natural objects are automatically segmented in the
   natural image sequence and three-dimensionally (3-D) modeled using
   ellipsoid-like models. The 3-D shape, 3-D motion, and the displaced
   frame difference between two succeeding images are evaluated to estimate
   three illumination parameters. The parameters describe a distant point
   light source and ambient light. Using the estimated illumination
   parameters, the synthetic scene is rendered and mixed to the natural
   image sequence. Experimental results with a moving virtual object mixed
   into real video telephone sequences show that the virtual object appears
   naturally having the same shading and shadows as the real objects.
   Further, shading and shadow allows the viewer to understand the motion
   trajectory of the objects much better. Demos are available at
   http://www.irisa.fr/prive/Jurgen.Stauder or
   http://www.tnt-uni-hannover.de/(similar to)stauder.}},
DOI = {{10.1109/6046.766735}},
ISSN = {{1520-9210}},
Unique-ID = {{ISI:000207088400002}},
}

@article{ ISI:000073280100004,
Author = {Faugeras, O and Robert, L and Laveau, S and Csurka, G and Zeller, C and
   Gauclin, C and Zoghlami, I},
Title = {{3-D reconstruction of urban scenes from image sequences}},
Journal = {{COMPUTER VISION AND IMAGE UNDERSTANDING}},
Year = {{1998}},
Volume = {{69}},
Number = {{3}},
Pages = {{292-309}},
Month = {{MAR}},
Abstract = {{In this paper, we address the problem of the recovery of a realistic
   textured model of a scene from a sequence of images, without any prior
   knowledge either about the parameters of the cameras or about their
   motion. We do not require any knowledge of the absolute coordinates of
   some control points in the scene to achieve this goal, First, using
   various computer vision tools, we establish correspondences between the
   images and recover the epipolar geometry, from which we show how to
   compute the complete set of perspective projection matrices for all
   camera positions. Then, we proceed to reconstruct the geometry of the
   scene. We show how to rely on information of the scene such as parallel
   lines or known angles in order to reconstruct the geometry of the scene
   up to, respectively, an unknown affine transformation or an unknown
   similitude. Alternatively, if this information is not available, we can
   still recover the Euclidean structure of the scene through the
   techniques of self-calibration. The scene geometry is modeled as a set
   of polyhedra Textures to be mapped on the scene polygons are extracted
   automatically from the images. We show how several images can be
   combined through mosaicing in order to automatically remove visual
   artifacts such as pedestrians or trees from the textures.
   This vision system has been implemented as a vision server, which
   provides to a CAD-CAM modeler geometry or texture information extracted
   from the set of images. The whole system allows efficient and fast
   production of scene models of high quality for such applications as
   simulation, virtual, or augmented reality. (C) 1998 Academic Press.}},
DOI = {{10.1006/cviu.1998.0665}},
ISSN = {{1077-3142}},
EISSN = {{1090-235X}},
Unique-ID = {{ISI:000073280100004}},
}

@inproceedings{ ISI:000082616100004,
Author = {Wilke, FL},
Editor = {{Zemann, J}},
Title = {{Coal deposits - Their utilisation today and tomorrow}},
Booktitle = {{ENERGY SUPPLY AND MINERAL RESOURCES: HOW MUCH LONGER}},
Series = {{OSTERREICHISCHE AKADEMIE DER WISSENSCHAFTEN SCHRIFTENREIHE DER
   ERDWISSENSCHAFTLICHEN KOMMISSIONEN}},
Year = {{1998}},
Volume = {{12}},
Pages = {{127-147}},
Note = {{Symposium on Energy Resources and Mineral Raw Materials - How Much
   Longer, VIENNA, AUSTRIA, SEP   25, 1997}},
Organization = {{Austrian Acad Sci}},
Abstract = {{Coal is literally consumed by any type of its utilisation, as there is
   no possibility of recycling the solid carbon except for natural
   photosynthesis. Hence, one should expect a very careful and considerate
   exploitation of the resources, which are principally Limited and not
   renewable. In reality, however, in many countries especially in
   (Central) Europe coal mines both underground and open pit are closed
   before complete exhaustion of the deposits, whereas in some other
   countries new mining operations are attacking new deposits. The reason
   for this somewhat contradictory situation lies in the economic and
   ecological situation: As a fungible commodity in the world market, the
   coal from any gis en deposit competes with any other coal and any other
   energy supply, and - given the ample availability (not to say:
   abundance) of energy, which is very Likely to last - the proceeds are
   low and cannot be influenced by a single producer or a group of
   producers. Furthermore, the most recent developments in many countries,
   including the former socialist ones, demonstrate that even comparatively
   strong national economies cannot shoulder the financial burden of
   artificially interfering in the free market, e.g. by subsidising
   domestic production. As a consequence, there is strong pressure to
   minimise the costs of production. This is even augmented by the need to
   meet increasing environmental requirements, the justifications given for
   some of which, however, are at least doubtful. This pressure of costs
   resulted in the need for methods of utilising the coal deposits which
   are as cheap and effective as possible. To achieve this goal, the
   ``economy of scale{''} was aimed at by increasing the capacity for both
   the mines as a whole and the single mining units and machinery, and all
   operations were mechanised and automated to the utmost extent possible.
   In addition, production was and is still concentrated on the ``best{''}
   part of the deposits by abandoning those parts with unfavourable (e.g.
   geological) conditions. Also, especially good deposit conditions are
   necessary to ensure economical use of those high-capacity and largely
   mechanised/automated systems.
   There have been many remarkable attempts to replace conventional mining
   methods with new and alternative ones, all of which, however, do again
   only partially utilise the deposit; such as coal-leed methane mining, in
   situ-gasification of coal, hydraulic coal getting, and fully automated
   mechanical moles. However, though many of these methods have proven
   their technical applicability on an industrial scale under certain
   conditions, none of them resulted in a real (economic) success and is
   likely to become generally applicable. Hence, the future trends in
   utilising the coal deposits are most likely to be an evolutionary
   further development of the conventional mining methods rather than a
   revolutionary breakthrough of new ones. Especially: automation of
   machines and systems with new developments in remote sensing and
   controlling, including satellite GPS, seems promising in offering
   chances to increase effectiveness.
   In ally case, however, the utilisation of the coal deposits will be only
   partial in future as well, and will concentrate on the best deposits or
   best parts of deposits - which means that the closing down of mines
   especially in Europe will continue. Yet this is on no account an
   unacceptable plundering of the natural resources, nor does it
   deteriorate, let alone destroy, the material basis for future
   generations. The technically and economically mineable coal reserves
   known at present will last for over 230 years, and despite their current
   exploitation, they are still increasing due to ongoing exploration. One
   can be confident that alternative sources of energy such as nuclear
   fusion or photo voltaic will be available long before coal resources are
   exhausted, and uneconomic and forced complete extraction of these coal
   resources would not contribute to,but counteract sustainable
   development, as it would consume other resources such as manpower,
   money, machinery, and of course raw materials, which therefore could not
   be used for other necessary objectives. With regard to the future supply
   of cod, it is not a possible shortage of usable resources that poses a
   problem, but man-made obstacles to their exploitation due to
   misunderstanding of the situation and of the goal of sustainability.}},
ISSN = {{0171-2225}},
ISBN = {{3-7001-2731-6}},
Unique-ID = {{ISI:000082616100004}},
}

@article{ ISI:A1997XN76900001,
Author = {Wang, FS and Shyu, CH},
Title = {{Optimal feed policy for fed-batch fermentation of ethanol production by
   Zymomous mobilis}},
Journal = {{BIOPROCESS ENGINEERING}},
Year = {{1997}},
Volume = {{17}},
Number = {{2}},
Pages = {{63-68}},
Month = {{JUL}},
Abstract = {{Optimal feed control for the fed-batch fermentation process of ethanol
   production is studied. Additional inequality constraints are introduced
   in this optimization problem to assure the optimal solution in a reality
   region. Introducing an updating rule of augmented Lagrange multipliers
   to handle these inequality constraints, iterative dynamic programming
   can be used in a straightforward manner for the optimization of
   fed-batch fermenters. To obtain more accurate solution a method of
   sequential quadratic programming can be used to solve this problem
   again. As a result of this optimal control, the maximum production at
   final time is very close to the theoretical yield. Although sequential
   quadratic programming can be rapid convergence to the optimal solution,
   but very good initial starting points has to be used to ensure obtaining
   the global optimum. Experimental works were used to validate this study.
   The simulated results could fit the experiments satisfactorily.}},
DOI = {{10.1007/PL00008957}},
ISSN = {{0178-515X}},
Unique-ID = {{ISI:A1997XN76900001}},
}

@inproceedings{ ISI:A1997BJ67V00028,
Author = {Bassingthwaighte, JB},
Editor = {{Sideman, S and Beyar, R}},
Title = {{Design and strategy for the Cardionome Project}},
Booktitle = {{ANALYTICAL AND QUANTITATIVE CARDIOLOGY}},
Series = {{Advances in Experimental Medicine and Biology}},
Year = {{1997}},
Volume = {{430}},
Pages = {{325-339}},
Note = {{10th Goldberg Workshop on Analytical and Quantitative Cardiology - From
   Genetics to Function, HAIFA, ISRAEL, DEC 02-05, 1996}},
Organization = {{Technion Israel Inst Technol; Julius Silver; Henry \& Viola Goldberg;
   Israel Cardiol Soc}},
Abstract = {{The Physiome Project has the goal of providing the quantitative
   description of the integrated functions of the living organism. This is
   too large an undertaking to be begun all at once. What needs to be
   developed first are large comprehensive databases containing genomic,
   biochemical, anatomical and physiological information that can be
   searched and retrieved via the Internet. A more modest and achievable
   goal is the Cardiome Project, whose goal is to describe the functioning
   heart. Since it is impractical to develop this from the genetic and
   molecular level, we begin it as a multicenter collaborative effort at
   the level of the functioning organ. The work of Hunter, Noble, and
   others provides a central scheme, a description of the spread of
   excitation and contraction through an anatomically detailed cardiac
   model with fiber directions. This will be augmented by the additions of
   regional blood flows, substrate uptake and metabolism, and energy
   production and utilization in serving contraction and ionic balances.
   Later stages will involve cellular regulation and responses to
   interventions. The organization of such projects is by the assembling of
   components whose linkages one to another are first minimized and then
   augmented to improve the approximation to reality.}},
ISSN = {{0065-2598}},
ISBN = {{0-306-45762-8}},
Unique-ID = {{ISI:A1997BJ67V00028}},
}

@article{ ISI:A1992HT64500003,
Author = {MCCOWN, RL and KEATING, BA and PROBERT, ME and JONES, RK},
Title = {{STRATEGIES FOR SUSTAINABLE CROP PRODUCTION IN SEMIARID AFRICA}},
Journal = {{OUTLOOK ON AGRICULTURE}},
Year = {{1992}},
Volume = {{21}},
Number = {{1}},
Pages = {{21-31}},
Month = {{MAR}},
Abstract = {{This is a record of the experience of a research team attempting to
   identify a development path for a farming system in semi-arid Africa.
   The farming system is the largely-subsistence production of crops and
   livestock by smallholders in the Machakos and Kitui Districts in Eastern
   Kenya. The region is known locally as Ukambani- ``the place where the
   Kamba people live{''}. This region has a long history in which the food
   demands of rapidly growing populations have periodically outstripped the
   productive capacity of the land and current technology. Today, the
   population pressure on land and its rate of growth are among the highest
   in the world, and emigration is no longer a feasible solution. But
   numerous other areas of Africa are not far behind in population
   pressures and a more sustainable agriculture in this region is important
   not only for Kenya. Almost certainly, the problems of agriculture in
   Machakos-Kitui today represent a future scenario for much of semi-arid
   Africa.
   This article is also concerned with methodology for conducting research
   on farming systems. While the project was designed according to the
   concepts of Farming Systems Research (FSR) (Collinson, 1982), the
   realities of development assistance projects created challenges in
   implementation. The research also departed from the conventional FSR
   plan as new possibilities were realized, and with great benefit.
   The outcome is a well-founded hypothesis: contrary to much contemporary
   wisdom, a strategy of augmenting traditional soil enrichment practices
   with modest amounts of fertilizer is economically feasible for many
   farmers and provides the best prospects for food security and
   sustainable agriculture in this climatic zone.}},
DOI = {{10.1177/003072709202100105}},
ISSN = {{0030-7270}},
ResearcherID-Numbers = {{Keating, Brian/C-9817-2012}},
Unique-ID = {{ISI:A1992HT64500003}},
}
