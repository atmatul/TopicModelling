{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Micro Trainning: Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have 1000 documents without a catelog to classify them into any catgories or interesting categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Grab my Tools\n",
    "import os\n",
    "from . import utils\n",
    "import json\n",
    "from collections import Counter\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore, TfidfModel\n",
    "import pyLDAvis.gensim\n",
    "import pandas as pd\n",
    "\n",
    "# Data Path\n",
    "path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Enable visualization\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to Model topics\n",
    "* Reading Data into Machine Understandable Format\n",
    "* Cleaning\n",
    "* Building a Word Frequency Dictonary \n",
    "* Fitting a [LDA](https://ai.stanford.edu/~ang/papers/jair03-lda.pdf) ([for dummies](https://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation))\n",
    "* Visualizing Results\n",
    "* Building on Top of Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1485 files\n",
      "Sample Entry:\n",
      " {\n",
      "  \"ENTRYTYPE\": \"inproceedings\",\n",
      "  \"ID\": \"ISI:000432607700002\",\n",
      "  \"abstract\": \"{Motion capture acting is a challenging task, it requires trained and\\nexperienced actors who can highly rely on their acting and imagination\\nskills to deliver believable performances. This is especially the case\\nwhen preparation times are short and scenery needs to be imagined, as it\\nis commonly the case for shoots in the gaming industry. To support\\nactors in such cases, we developed a mixed reality application that\\nallows showing digital scenery and triggering emotions while performing.\\nIn this paper we tested our hypothesis that a mixed reality head-mounted\\nprojection display can support motion capture acting through the help of\\nexperienced motion capture actors performing short acting scenes common\\nfor game productions. We evaluated our prototype with four motion\\ncapture actors and four motion capture experts. Both groups considered\\nour application as helpful, especially as a rehearsal tool to prepare\\nperformances before capturing the motions in a studio. Actors and\\nexperts indicated that our application could reduce the time to prepare\\nperformances and supports the set up of physical acting scenery.}\",\n",
      "  \"author\": \"Kade, Daniel and Lindell, Rikard and Urey, Hakan and Ozcan, Oguzhan\",\n",
      "  \"booktitle\": \"{ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY, ACE 2017}\",\n",
      "  \"doi\": \"{10.1007/978-3-319-76270-8\\\\_2}\",\n",
      "  \"editor\": \"{Cheok, AD and Inami, M and Romao, T}\",\n",
      "  \"eissn\": \"{1611-3349}\",\n",
      "  \"isbn\": \"{978-3-319-76270-8; 978-3-319-76269-2}\",\n",
      "  \"issn\": \"{0302-9743}\",\n",
      "  \"note\": \"{14th International Conference on Advances in Computer Entertainment\\nTechnology (ACE), London, ENGLAND, DEC 14-16, 2017}\",\n",
      "  \"organization\": \"{Multimodal Technologies \\\\& Interact Journal}\",\n",
      "  \"pages\": \"{14-31}\",\n",
      "  \"series\": \"{Lecture Notes in Computer Science}\",\n",
      "  \"title\": \"{Evaluation of a Mixed Reality Head-Mounted Projection Display to Support\\nMotion Capture Acting}\",\n",
      "  \"unique-id\": \"{ISI:000432607700002}\",\n",
      "  \"volume\": \"{10714}\",\n",
      "  \"year\": \"{2018}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "files = utils.readfiles(path)\n",
    "lst_files = utils.parsebibfiles(files)\n",
    "\n",
    "# Sample\n",
    "print(\"Read {0} files\\nSample Entry:\\n {1}\".format(len(lst_files), json.dumps(lst_files[1], indent=2, sort_keys=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text\n",
      "Sample\n",
      "Top 10 Words in Document\n",
      "[('biosecur', 15), ('catcher', 6), ('catch', 5), ('awar', 5), ('threat', 4), ('practic', 4), ('thin', 3), ('good', 3), ('studi', 3), ('high', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Clean Data\n",
    "lst_clean_bow = [utils.clean_abstract(file) for file in lst_files]\n",
    "\n",
    "# Sample\n",
    "print(\"Cleaned Text\\nSample\\nTop 10 Words in Document\\n{0}\".format(Counter(lst_clean_bow[2]).most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# build gensim dict\n",
    "corpus_dict = Dictionary(lst_clean_bow)\n",
    "\n",
    "# filter low freq words threshold > 15 Abstracts\n",
    "corpus_dict.filter_extremes(no_below=2)\n",
    "\n",
    "# gensim doc2bow\n",
    "bow_corpus = [corpus_dict.doc2bow(doc) for doc in lst_clean_bow]\n",
    "\n",
    "# tf-idf model over bow\n",
    "tfidf_model = TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf_model[bow_corpus]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bigram & Trigram Analysis\n",
    "#### 1.Corpus \n",
    "#### 2.Bigram Model\n",
    "#### 3.Trigram Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a08bca5c50e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpds_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpds_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigram_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpds_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "pds_corpus = pd.Series([item.get('abstract') for item in lst_files])\n",
    "df_bigram = utils.bigrams(pds_corpus, 10)\n",
    "df_trigram = utils.trigram_analysis(pds_corpus, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# gensim LDA model over tf-idf\n",
    "lda_tfidf_model = LdaMulticore(corpus_tfidf, num_topics=10, id2word=corpus_dict, passes=2, workers=4)\n",
    "\n",
    "# preview\n",
    "for idx, topic in lda_tfidf_model.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n",
    "\n",
    "for index, score in sorted(lda_tfidf_model[bow_corpus[12]], key=lambda tup: -1 * tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_tfidf_model.print_topic(index, 10)))\n",
    "\n",
    "# visualization\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_tfidf_model, corpus=bow_corpus, dictionary=corpus_dict)\n",
    "vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualize\n",
    "# var = utils.visualize_lda_model(model=lda_tfidf_model, corpus=bow_corpus, corpus_dict=corpus_dict)\n",
    "# print(var)\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_tfidf_model, corpus=bow_corpus,dictionary=corpus_dict)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
